 -- Loading model...
 -- Warming up...
 -- Generating 32 tokens, 32 in context...
 ** Speed (Prefill): 49.01 tokens/second
 ** Speed (Decode): 3.21 tokens/second
 ** Max Memory (device: 0): 4.87 GB (12.37%)
 -- Loading model...
 -- Warming up...
 -- Generating 64 tokens, 64 in context...
 ** Speed (Prefill): 162.79 tokens/second
 ** Speed (Decode): 3.21 tokens/second
 ** Max Memory (device: 0): 4.88 GB (12.39%)
 -- Loading model...
 -- Warming up...
 -- Generating 128 tokens, 128 in context...
 ** Speed (Prefill): 332.86 tokens/second
 ** Speed (Decode): 3.21 tokens/second
 ** Max Memory (device: 0): 4.90 GB (12.43%)
 -- Loading model...
 -- Warming up...
 -- Generating 256 tokens, 256 in context...
 ** Speed (Prefill): 657.87 tokens/second
 ** Speed (Decode): 3.20 tokens/second
 ** Max Memory (device: 0): 4.93 GB (12.51%)
 -- Loading model...
 -- Warming up...
 -- Generating 512 tokens, 512 in context...
 ** Speed (Prefill): 1203.27 tokens/second
 ** Speed (Decode): 3.19 tokens/second
 ** Max Memory (device: 0): 4.99 GB (12.67%)
 -- Loading model...
 -- Warming up...
 -- Generating 1024 tokens, 1024 in context...
 ** Speed (Prefill): 2134.52 tokens/second
 ** Speed (Decode): 3.19 tokens/second
 ** Max Memory (device: 0): 5.11 GB (12.98%)
 -- Loading model...
 -- Warming up...
 -- Generating 2048 tokens, 2048 in context...
 ** Speed (Prefill): 3848.54 tokens/second
 ** Speed (Decode): 2.51 tokens/second
 ** Max Memory (device: 0): 5.36 GB (13.61%)
 -- Loading model...
 -- Warming up...
 -- Generating 4096 tokens, 4096 in context...
 ** Speed (Prefill): 5621.68 tokens/second
 ** Speed (Decode): 3.19 tokens/second
 ** Max Memory (device: 0): 5.85 GB (14.86%)
GPU: NVIDIA A100-PCIE-40GB
Model: /scratch/user/siweicui/mix_precision/mistralai-7B-awq
Version: FP16
