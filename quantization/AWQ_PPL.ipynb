{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6f8f4f-a789-49c6-8905-7bd8692be636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba21ab3fa8b0444fbb77e02f146c3798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a7f22e6-0f80-44a5-a309-7ba9bc09bce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05:09:22:47,080 WARNING  [huggingface.py:118] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-04-05:09:22:47,218 WARNING  [huggingface.py:337] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
     ]
    }
   ],
   "source": [
    "#from lm_eval import evaluator\n",
    "from lm_eval.models.huggingface import HFLM as eval_wrapper\n",
    "from lm_eval.tasks import get_task_dict\n",
    "from typing import Optional\n",
    "import torch\n",
    "\n",
    "moe =eval_wrapper(pretrained=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58be3969-db8b-449f-bafd-dca3dae08d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iwslt2017-ar-en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/iwslt2017_ar-en.yaml'},\n",
       " 'generate_until': {'type': 'group',\n",
       "  'task': ['iwslt2017-ar-en',\n",
       "   'wmt14-fr-en',\n",
       "   'wmt14-en-fr',\n",
       "   'wmt16-de-en',\n",
       "   'wmt16-en-de',\n",
       "   'wmt16-en-ro',\n",
       "   'wmt16-ro-en',\n",
       "   'iwslt2017-en-ar'],\n",
       "  'yaml_path': -1},\n",
       " 'translation': {'type': 'group',\n",
       "  'task': ['iwslt2017-ar-en',\n",
       "   'wmt14-fr-en',\n",
       "   'wmt14-en-fr',\n",
       "   'wmt16-de-en',\n",
       "   'wmt16-en-de',\n",
       "   'wmt16-en-ro',\n",
       "   'wmt16-ro-en',\n",
       "   'iwslt2017-en-ar'],\n",
       "  'yaml_path': -1},\n",
       " 'iwslt2017': {'type': 'group',\n",
       "  'task': ['iwslt2017-ar-en', 'iwslt2017-en-ar'],\n",
       "  'yaml_path': -1},\n",
       " 'wmt14-fr-en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt14_fr-en.yaml'},\n",
       " 'wmt14': {'type': 'group',\n",
       "  'task': ['wmt14-fr-en', 'wmt14-en-fr'],\n",
       "  'yaml_path': -1},\n",
       " 'gpt3_translation_benchmarks': {'type': 'group',\n",
       "  'task': ['wmt14-fr-en',\n",
       "   'wmt14-en-fr',\n",
       "   'wmt16-de-en',\n",
       "   'wmt16-en-de',\n",
       "   'wmt16-en-ro',\n",
       "   'wmt16-ro-en'],\n",
       "  'yaml_path': -1},\n",
       " 'wmt14-en-fr': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt14_en-fr.yaml'},\n",
       " 'wmt16-de-en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt16_de-en.yaml'},\n",
       " 'wmt16': {'type': 'group',\n",
       "  'task': ['wmt16-de-en', 'wmt16-en-de', 'wmt16-en-ro', 'wmt16-ro-en'],\n",
       "  'yaml_path': -1},\n",
       " 'wmt16-en-de': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt16_en-de.yaml'},\n",
       " 'wmt16-en-ro': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt16_en-ro.yaml'},\n",
       " 'wmt16-ro-en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/wmt16_ro-en.yaml'},\n",
       " 'iwslt2017-en-ar': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/translation/iwslt2017_en-ar.yaml'},\n",
       " 'xstorycloze_ar': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_ar.yaml'},\n",
       " 'xstorycloze': {'type': 'group',\n",
       "  'task': ['xstorycloze_ar',\n",
       "   'xstorycloze_hi',\n",
       "   'xstorycloze_my',\n",
       "   'xstorycloze_id',\n",
       "   'xstorycloze_sw',\n",
       "   'xstorycloze_es',\n",
       "   'xstorycloze_eu',\n",
       "   'xstorycloze_te',\n",
       "   'xstorycloze_zh',\n",
       "   'xstorycloze_en',\n",
       "   'xstorycloze_ru'],\n",
       "  'yaml_path': -1},\n",
       " 'xstorycloze_hi': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_hi.yaml'},\n",
       " 'xstorycloze_my': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_my.yaml'},\n",
       " 'xstorycloze_id': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_id.yaml'},\n",
       " 'xstorycloze_sw': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_sw.yaml'},\n",
       " 'xstorycloze_es': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_es.yaml'},\n",
       " 'xstorycloze_eu': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_eu.yaml'},\n",
       " 'xstorycloze_te': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_te.yaml'},\n",
       " 'xstorycloze_zh': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_zh.yaml'},\n",
       " 'xstorycloze_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_en.yaml'},\n",
       " 'xstorycloze_ru': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xstorycloze/default_ru.yaml'},\n",
       " 'kmmlu_hard_gas_technology_and_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_gas_technology_and_engineering.yaml'},\n",
       " 'kmmlu': {'type': 'group',\n",
       "  'task': ['kmmlu_hard_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_civil_engineering',\n",
       "   'kmmlu_hard_political_science_and_sociology',\n",
       "   'kmmlu_hard_taxation',\n",
       "   'kmmlu_hard_chemistry',\n",
       "   'kmmlu_hard_biology',\n",
       "   'kmmlu_hard_korean_history',\n",
       "   'kmmlu_hard_law',\n",
       "   'kmmlu_hard_economics',\n",
       "   'kmmlu_hard_public_safety',\n",
       "   'kmmlu_hard_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_agricultural_sciences',\n",
       "   'kmmlu_hard_mechanical_engineering',\n",
       "   'kmmlu_hard_social_welfare',\n",
       "   'kmmlu_hard_ecology',\n",
       "   'kmmlu_hard_interior_architecture_and_design',\n",
       "   'kmmlu_hard_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_management',\n",
       "   'kmmlu_hard_environmental_science',\n",
       "   'kmmlu_hard_energy_management',\n",
       "   'kmmlu_hard_chemical_engineering',\n",
       "   'kmmlu_hard_accounting',\n",
       "   'kmmlu_hard_real_estate',\n",
       "   'kmmlu_hard_materials_engineering',\n",
       "   'kmmlu_hard_education',\n",
       "   'kmmlu_hard_marketing',\n",
       "   'kmmlu_hard_electronics_engineering',\n",
       "   'kmmlu_hard_criminal_law',\n",
       "   'kmmlu_hard_information_technology',\n",
       "   'kmmlu_hard_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_computer_science',\n",
       "   'kmmlu_hard_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_food_processing',\n",
       "   'kmmlu_hard_psychology',\n",
       "   'kmmlu_hard_patent',\n",
       "   'kmmlu_hard_health',\n",
       "   'kmmlu_hard_construction',\n",
       "   'kmmlu_hard_geomatics',\n",
       "   'kmmlu_hard_refrigerating_machinery',\n",
       "   'kmmlu_hard_maritime_engineering',\n",
       "   'kmmlu_hard_electrical_engineering',\n",
       "   'kmmlu_hard_nondestructive_testing',\n",
       "   'kmmlu_hard_industrial_engineer',\n",
       "   'kmmlu_hard_fashion',\n",
       "   'kmmlu_hard_math',\n",
       "   'kmmlu_hard_cot_interior_architecture_and_design',\n",
       "   'kmmlu_hard_cot_real_estate',\n",
       "   'kmmlu_hard_cot_criminal_law',\n",
       "   'kmmlu_hard_cot_geomatics',\n",
       "   'kmmlu_hard_cot_law',\n",
       "   'kmmlu_hard_cot_environmental_science',\n",
       "   'kmmlu_hard_cot_political_science_and_sociology',\n",
       "   'kmmlu_hard_cot_refrigerating_machinery',\n",
       "   'kmmlu_hard_cot_accounting',\n",
       "   'kmmlu_hard_cot_nondestructive_testing',\n",
       "   'kmmlu_hard_cot_civil_engineering',\n",
       "   'kmmlu_hard_cot_psychology',\n",
       "   'kmmlu_hard_cot_patent',\n",
       "   'kmmlu_hard_cot_maritime_engineering',\n",
       "   'kmmlu_hard_cot_management',\n",
       "   'kmmlu_hard_cot_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_cot_economics',\n",
       "   'kmmlu_hard_cot_agricultural_sciences',\n",
       "   'kmmlu_hard_cot_chemistry',\n",
       "   'kmmlu_hard_cot_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_cot_biology',\n",
       "   'kmmlu_hard_cot_korean_history',\n",
       "   'kmmlu_hard_cot_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_cot_public_safety',\n",
       "   'kmmlu_hard_cot_computer_science',\n",
       "   'kmmlu_hard_cot_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_cot_chemical_engineering',\n",
       "   'kmmlu_hard_cot_electrical_engineering',\n",
       "   'kmmlu_hard_cot_social_welfare',\n",
       "   'kmmlu_hard_cot_marketing',\n",
       "   'kmmlu_hard_cot_health',\n",
       "   'kmmlu_hard_cot_electronics_engineering',\n",
       "   'kmmlu_hard_cot_ecology',\n",
       "   'kmmlu_hard_cot_education',\n",
       "   'kmmlu_hard_cot_construction',\n",
       "   'kmmlu_hard_cot_information_technology',\n",
       "   'kmmlu_hard_cot_industrial_engineer',\n",
       "   'kmmlu_hard_cot_mechanical_engineering',\n",
       "   'kmmlu_hard_cot_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_cot_food_processing',\n",
       "   'kmmlu_hard_cot_fashion',\n",
       "   'kmmlu_hard_cot_taxation',\n",
       "   'kmmlu_hard_cot_energy_management',\n",
       "   'kmmlu_hard_cot_math',\n",
       "   'kmmlu_hard_cot_materials_engineering',\n",
       "   'kmmlu_direct_computer_science',\n",
       "   'kmmlu_direct_energy_management',\n",
       "   'kmmlu_direct_ecology',\n",
       "   'kmmlu_direct_taxation',\n",
       "   'kmmlu_direct_machine_design_and_manufacturing',\n",
       "   'kmmlu_direct_political_science_and_sociology',\n",
       "   'kmmlu_direct_civil_engineering',\n",
       "   'kmmlu_direct_real_estate',\n",
       "   'kmmlu_direct_maritime_engineering',\n",
       "   'kmmlu_direct_refrigerating_machinery',\n",
       "   'kmmlu_direct_nondestructive_testing',\n",
       "   'kmmlu_direct_environmental_science',\n",
       "   'kmmlu_direct_education',\n",
       "   'kmmlu_direct_fashion',\n",
       "   'kmmlu_direct_electronics_engineering',\n",
       "   'kmmlu_direct_economics',\n",
       "   'kmmlu_direct_materials_engineering',\n",
       "   'kmmlu_direct_marketing',\n",
       "   'kmmlu_direct_psychology',\n",
       "   'kmmlu_direct_law',\n",
       "   'kmmlu_direct_food_processing',\n",
       "   'kmmlu_direct_geomatics',\n",
       "   'kmmlu_direct_patent',\n",
       "   'kmmlu_direct_math',\n",
       "   'kmmlu_direct_chemical_engineering',\n",
       "   'kmmlu_direct_chemistry',\n",
       "   'kmmlu_direct_industrial_engineer',\n",
       "   'kmmlu_direct_gas_technology_and_engineering',\n",
       "   'kmmlu_direct_biology',\n",
       "   'kmmlu_direct_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_direct_health',\n",
       "   'kmmlu_direct_mechanical_engineering',\n",
       "   'kmmlu_direct_agricultural_sciences',\n",
       "   'kmmlu_direct_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_direct_railway_and_automotive_engineering',\n",
       "   'kmmlu_direct_electrical_engineering',\n",
       "   'kmmlu_direct_interior_architecture_and_design',\n",
       "   'kmmlu_direct_information_technology',\n",
       "   'kmmlu_direct_korean_history',\n",
       "   'kmmlu_direct_criminal_law',\n",
       "   'kmmlu_direct_construction',\n",
       "   'kmmlu_direct_accounting',\n",
       "   'kmmlu_direct_management',\n",
       "   'kmmlu_direct_public_safety',\n",
       "   'kmmlu_direct_social_welfare',\n",
       "   'kmmlu_hard_direct_electronics_engineering',\n",
       "   'kmmlu_hard_direct_electrical_engineering',\n",
       "   'kmmlu_hard_direct_accounting',\n",
       "   'kmmlu_hard_direct_social_welfare',\n",
       "   'kmmlu_hard_direct_maritime_engineering',\n",
       "   'kmmlu_hard_direct_agricultural_sciences',\n",
       "   'kmmlu_hard_direct_law',\n",
       "   'kmmlu_hard_direct_korean_history',\n",
       "   'kmmlu_hard_direct_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_direct_information_technology',\n",
       "   'kmmlu_hard_direct_environmental_science',\n",
       "   'kmmlu_hard_direct_mechanical_engineering',\n",
       "   'kmmlu_hard_direct_education',\n",
       "   'kmmlu_hard_direct_computer_science',\n",
       "   'kmmlu_hard_direct_real_estate',\n",
       "   'kmmlu_hard_direct_civil_engineering',\n",
       "   'kmmlu_hard_direct_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_direct_ecology',\n",
       "   'kmmlu_hard_direct_political_science_and_sociology',\n",
       "   'kmmlu_hard_direct_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_direct_public_safety',\n",
       "   'kmmlu_hard_direct_economics',\n",
       "   'kmmlu_hard_direct_energy_management',\n",
       "   'kmmlu_hard_direct_math',\n",
       "   'kmmlu_hard_direct_psychology',\n",
       "   'kmmlu_hard_direct_fashion',\n",
       "   'kmmlu_hard_direct_biology',\n",
       "   'kmmlu_hard_direct_industrial_engineer',\n",
       "   'kmmlu_hard_direct_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_direct_criminal_law',\n",
       "   'kmmlu_hard_direct_health',\n",
       "   'kmmlu_hard_direct_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_direct_chemistry',\n",
       "   'kmmlu_hard_direct_refrigerating_machinery',\n",
       "   'kmmlu_hard_direct_materials_engineering',\n",
       "   'kmmlu_hard_direct_interior_architecture_and_design',\n",
       "   'kmmlu_hard_direct_food_processing',\n",
       "   'kmmlu_hard_direct_nondestructive_testing',\n",
       "   'kmmlu_hard_direct_taxation',\n",
       "   'kmmlu_hard_direct_construction',\n",
       "   'kmmlu_hard_direct_marketing',\n",
       "   'kmmlu_hard_direct_geomatics',\n",
       "   'kmmlu_hard_direct_chemical_engineering',\n",
       "   'kmmlu_hard_direct_patent',\n",
       "   'kmmlu_hard_direct_management'],\n",
       "  'yaml_path': -1},\n",
       " 'kmmlu_hard': {'type': 'group',\n",
       "  'task': ['kmmlu_hard_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_civil_engineering',\n",
       "   'kmmlu_hard_political_science_and_sociology',\n",
       "   'kmmlu_hard_taxation',\n",
       "   'kmmlu_hard_chemistry',\n",
       "   'kmmlu_hard_biology',\n",
       "   'kmmlu_hard_korean_history',\n",
       "   'kmmlu_hard_law',\n",
       "   'kmmlu_hard_economics',\n",
       "   'kmmlu_hard_public_safety',\n",
       "   'kmmlu_hard_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_agricultural_sciences',\n",
       "   'kmmlu_hard_mechanical_engineering',\n",
       "   'kmmlu_hard_social_welfare',\n",
       "   'kmmlu_hard_ecology',\n",
       "   'kmmlu_hard_interior_architecture_and_design',\n",
       "   'kmmlu_hard_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_management',\n",
       "   'kmmlu_hard_environmental_science',\n",
       "   'kmmlu_hard_energy_management',\n",
       "   'kmmlu_hard_chemical_engineering',\n",
       "   'kmmlu_hard_accounting',\n",
       "   'kmmlu_hard_real_estate',\n",
       "   'kmmlu_hard_materials_engineering',\n",
       "   'kmmlu_hard_education',\n",
       "   'kmmlu_hard_marketing',\n",
       "   'kmmlu_hard_electronics_engineering',\n",
       "   'kmmlu_hard_criminal_law',\n",
       "   'kmmlu_hard_information_technology',\n",
       "   'kmmlu_hard_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_computer_science',\n",
       "   'kmmlu_hard_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_food_processing',\n",
       "   'kmmlu_hard_psychology',\n",
       "   'kmmlu_hard_patent',\n",
       "   'kmmlu_hard_health',\n",
       "   'kmmlu_hard_construction',\n",
       "   'kmmlu_hard_geomatics',\n",
       "   'kmmlu_hard_refrigerating_machinery',\n",
       "   'kmmlu_hard_maritime_engineering',\n",
       "   'kmmlu_hard_electrical_engineering',\n",
       "   'kmmlu_hard_nondestructive_testing',\n",
       "   'kmmlu_hard_industrial_engineer',\n",
       "   'kmmlu_hard_fashion',\n",
       "   'kmmlu_hard_math'],\n",
       "  'yaml_path': -1},\n",
       " 'kmmlu_hard_civil_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_civil_engineering.yaml'},\n",
       " 'kmmlu_hard_political_science_and_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_political_science_and_sociology.yaml'},\n",
       " 'kmmlu_hard_taxation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_taxation.yaml'},\n",
       " 'kmmlu_hard_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_chemistry.yaml'},\n",
       " 'kmmlu_hard_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_biology.yaml'},\n",
       " 'kmmlu_hard_korean_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_korean_history.yaml'},\n",
       " 'kmmlu_hard_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_law.yaml'},\n",
       " 'kmmlu_hard_economics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_economics.yaml'},\n",
       " 'kmmlu_hard_public_safety': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_public_safety.yaml'},\n",
       " 'kmmlu_hard_telecommunications_and_wireless_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_telecommunications_and_wireless_technology.yaml'},\n",
       " 'kmmlu_hard_agricultural_sciences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_agricultural_sciences.yaml'},\n",
       " 'kmmlu_hard_mechanical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_mechanical_engineering.yaml'},\n",
       " 'kmmlu_hard_social_welfare': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_social_welfare.yaml'},\n",
       " 'kmmlu_hard_ecology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_ecology.yaml'},\n",
       " 'kmmlu_hard_interior_architecture_and_design': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_interior_architecture_and_design.yaml'},\n",
       " 'kmmlu_hard_railway_and_automotive_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_railway_and_automotive_engineering.yaml'},\n",
       " 'kmmlu_hard_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_management.yaml'},\n",
       " 'kmmlu_hard_environmental_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_environmental_science.yaml'},\n",
       " 'kmmlu_hard_energy_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_energy_management.yaml'},\n",
       " 'kmmlu_hard_chemical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_chemical_engineering.yaml'},\n",
       " 'kmmlu_hard_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_accounting.yaml'},\n",
       " 'kmmlu_hard_real_estate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_real_estate.yaml'},\n",
       " 'kmmlu_hard_materials_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_materials_engineering.yaml'},\n",
       " 'kmmlu_hard_education': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_education.yaml'},\n",
       " 'kmmlu_hard_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_marketing.yaml'},\n",
       " 'kmmlu_hard_electronics_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_electronics_engineering.yaml'},\n",
       " 'kmmlu_hard_criminal_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_criminal_law.yaml'},\n",
       " 'kmmlu_hard_information_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_information_technology.yaml'},\n",
       " 'kmmlu_hard_aviation_engineering_and_maintenance': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_aviation_engineering_and_maintenance.yaml'},\n",
       " 'kmmlu_hard_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_computer_science.yaml'},\n",
       " 'kmmlu_hard_machine_design_and_manufacturing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_machine_design_and_manufacturing.yaml'},\n",
       " 'kmmlu_hard_food_processing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_food_processing.yaml'},\n",
       " 'kmmlu_hard_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_psychology.yaml'},\n",
       " 'kmmlu_hard_patent': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_patent.yaml'},\n",
       " 'kmmlu_hard_health': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_health.yaml'},\n",
       " 'kmmlu_hard_construction': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_construction.yaml'},\n",
       " 'kmmlu_hard_geomatics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_geomatics.yaml'},\n",
       " 'kmmlu_hard_refrigerating_machinery': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_refrigerating_machinery.yaml'},\n",
       " 'kmmlu_hard_maritime_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_maritime_engineering.yaml'},\n",
       " 'kmmlu_hard_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_electrical_engineering.yaml'},\n",
       " 'kmmlu_hard_nondestructive_testing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_nondestructive_testing.yaml'},\n",
       " 'kmmlu_hard_industrial_engineer': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_industrial_engineer.yaml'},\n",
       " 'kmmlu_hard_fashion': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_fashion.yaml'},\n",
       " 'kmmlu_hard_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/hard/kmmlu_hard_math.yaml'},\n",
       " 'kmmlu_hard_cot_interior_architecture_and_design': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_interior_architecture_and_design.yaml'},\n",
       " 'kmmlu_hard_cot': {'type': 'group',\n",
       "  'task': ['kmmlu_hard_cot_interior_architecture_and_design',\n",
       "   'kmmlu_hard_cot_real_estate',\n",
       "   'kmmlu_hard_cot_criminal_law',\n",
       "   'kmmlu_hard_cot_geomatics',\n",
       "   'kmmlu_hard_cot_law',\n",
       "   'kmmlu_hard_cot_environmental_science',\n",
       "   'kmmlu_hard_cot_political_science_and_sociology',\n",
       "   'kmmlu_hard_cot_refrigerating_machinery',\n",
       "   'kmmlu_hard_cot_accounting',\n",
       "   'kmmlu_hard_cot_nondestructive_testing',\n",
       "   'kmmlu_hard_cot_civil_engineering',\n",
       "   'kmmlu_hard_cot_psychology',\n",
       "   'kmmlu_hard_cot_patent',\n",
       "   'kmmlu_hard_cot_maritime_engineering',\n",
       "   'kmmlu_hard_cot_management',\n",
       "   'kmmlu_hard_cot_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_cot_economics',\n",
       "   'kmmlu_hard_cot_agricultural_sciences',\n",
       "   'kmmlu_hard_cot_chemistry',\n",
       "   'kmmlu_hard_cot_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_cot_biology',\n",
       "   'kmmlu_hard_cot_korean_history',\n",
       "   'kmmlu_hard_cot_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_cot_public_safety',\n",
       "   'kmmlu_hard_cot_computer_science',\n",
       "   'kmmlu_hard_cot_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_cot_chemical_engineering',\n",
       "   'kmmlu_hard_cot_electrical_engineering',\n",
       "   'kmmlu_hard_cot_social_welfare',\n",
       "   'kmmlu_hard_cot_marketing',\n",
       "   'kmmlu_hard_cot_health',\n",
       "   'kmmlu_hard_cot_electronics_engineering',\n",
       "   'kmmlu_hard_cot_ecology',\n",
       "   'kmmlu_hard_cot_education',\n",
       "   'kmmlu_hard_cot_construction',\n",
       "   'kmmlu_hard_cot_information_technology',\n",
       "   'kmmlu_hard_cot_industrial_engineer',\n",
       "   'kmmlu_hard_cot_mechanical_engineering',\n",
       "   'kmmlu_hard_cot_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_cot_food_processing',\n",
       "   'kmmlu_hard_cot_fashion',\n",
       "   'kmmlu_hard_cot_taxation',\n",
       "   'kmmlu_hard_cot_energy_management',\n",
       "   'kmmlu_hard_cot_math',\n",
       "   'kmmlu_hard_cot_materials_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'kmmlu_hard_cot_real_estate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_real_estate.yaml'},\n",
       " 'kmmlu_hard_cot_criminal_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_criminal_law.yaml'},\n",
       " 'kmmlu_hard_cot_geomatics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_geomatics.yaml'},\n",
       " 'kmmlu_hard_cot_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_law.yaml'},\n",
       " 'kmmlu_hard_cot_environmental_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_environmental_science.yaml'},\n",
       " 'kmmlu_hard_cot_political_science_and_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_political_science_and_sociology.yaml'},\n",
       " 'kmmlu_hard_cot_refrigerating_machinery': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_refrigerating_machinery.yaml'},\n",
       " 'kmmlu_hard_cot_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_accounting.yaml'},\n",
       " 'kmmlu_hard_cot_nondestructive_testing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_nondestructive_testing.yaml'},\n",
       " 'kmmlu_hard_cot_civil_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_civil_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_psychology.yaml'},\n",
       " 'kmmlu_hard_cot_patent': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_patent.yaml'},\n",
       " 'kmmlu_hard_cot_maritime_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_maritime_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_management.yaml'},\n",
       " 'kmmlu_hard_cot_railway_and_automotive_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_railway_and_automotive_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_economics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_economics.yaml'},\n",
       " 'kmmlu_hard_cot_agricultural_sciences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_agricultural_sciences.yaml'},\n",
       " 'kmmlu_hard_cot_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_chemistry.yaml'},\n",
       " 'kmmlu_hard_cot_aviation_engineering_and_maintenance': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_aviation_engineering_and_maintenance.yaml'},\n",
       " 'kmmlu_hard_cot_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_biology.yaml'},\n",
       " 'kmmlu_hard_cot_korean_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_korean_history.yaml'},\n",
       " 'kmmlu_hard_cot_telecommunications_and_wireless_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_telecommunications_and_wireless_technology.yaml'},\n",
       " 'kmmlu_hard_cot_public_safety': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_public_safety.yaml'},\n",
       " 'kmmlu_hard_cot_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_computer_science.yaml'},\n",
       " 'kmmlu_hard_cot_machine_design_and_manufacturing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_machine_design_and_manufacturing.yaml'},\n",
       " 'kmmlu_hard_cot_chemical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_chemical_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_electrical_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_social_welfare': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_social_welfare.yaml'},\n",
       " 'kmmlu_hard_cot_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_marketing.yaml'},\n",
       " 'kmmlu_hard_cot_health': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_health.yaml'},\n",
       " 'kmmlu_hard_cot_electronics_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_electronics_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_ecology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_ecology.yaml'},\n",
       " 'kmmlu_hard_cot_education': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_education.yaml'},\n",
       " 'kmmlu_hard_cot_construction': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_construction.yaml'},\n",
       " 'kmmlu_hard_cot_information_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_information_technology.yaml'},\n",
       " 'kmmlu_hard_cot_industrial_engineer': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_industrial_engineer.yaml'},\n",
       " 'kmmlu_hard_cot_mechanical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_mechanical_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_gas_technology_and_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_gas_technology_and_engineering.yaml'},\n",
       " 'kmmlu_hard_cot_food_processing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_food_processing.yaml'},\n",
       " 'kmmlu_hard_cot_fashion': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_fashion.yaml'},\n",
       " 'kmmlu_hard_cot_taxation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_taxation.yaml'},\n",
       " 'kmmlu_hard_cot_energy_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_energy_management.yaml'},\n",
       " 'kmmlu_hard_cot_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_math.yaml'},\n",
       " 'kmmlu_hard_cot_materials_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/cot_hard/kmmlu_cot_hard_materials_engineering.yaml'},\n",
       " 'kmmlu_direct_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_computer_science.yaml'},\n",
       " 'kmmlu_direct': {'type': 'group',\n",
       "  'task': ['kmmlu_direct_computer_science',\n",
       "   'kmmlu_direct_energy_management',\n",
       "   'kmmlu_direct_ecology',\n",
       "   'kmmlu_direct_taxation',\n",
       "   'kmmlu_direct_machine_design_and_manufacturing',\n",
       "   'kmmlu_direct_political_science_and_sociology',\n",
       "   'kmmlu_direct_civil_engineering',\n",
       "   'kmmlu_direct_real_estate',\n",
       "   'kmmlu_direct_maritime_engineering',\n",
       "   'kmmlu_direct_refrigerating_machinery',\n",
       "   'kmmlu_direct_nondestructive_testing',\n",
       "   'kmmlu_direct_environmental_science',\n",
       "   'kmmlu_direct_education',\n",
       "   'kmmlu_direct_fashion',\n",
       "   'kmmlu_direct_electronics_engineering',\n",
       "   'kmmlu_direct_economics',\n",
       "   'kmmlu_direct_materials_engineering',\n",
       "   'kmmlu_direct_marketing',\n",
       "   'kmmlu_direct_psychology',\n",
       "   'kmmlu_direct_law',\n",
       "   'kmmlu_direct_food_processing',\n",
       "   'kmmlu_direct_geomatics',\n",
       "   'kmmlu_direct_patent',\n",
       "   'kmmlu_direct_math',\n",
       "   'kmmlu_direct_chemical_engineering',\n",
       "   'kmmlu_direct_chemistry',\n",
       "   'kmmlu_direct_industrial_engineer',\n",
       "   'kmmlu_direct_gas_technology_and_engineering',\n",
       "   'kmmlu_direct_biology',\n",
       "   'kmmlu_direct_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_direct_health',\n",
       "   'kmmlu_direct_mechanical_engineering',\n",
       "   'kmmlu_direct_agricultural_sciences',\n",
       "   'kmmlu_direct_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_direct_railway_and_automotive_engineering',\n",
       "   'kmmlu_direct_electrical_engineering',\n",
       "   'kmmlu_direct_interior_architecture_and_design',\n",
       "   'kmmlu_direct_information_technology',\n",
       "   'kmmlu_direct_korean_history',\n",
       "   'kmmlu_direct_criminal_law',\n",
       "   'kmmlu_direct_construction',\n",
       "   'kmmlu_direct_accounting',\n",
       "   'kmmlu_direct_management',\n",
       "   'kmmlu_direct_public_safety',\n",
       "   'kmmlu_direct_social_welfare'],\n",
       "  'yaml_path': -1},\n",
       " 'kmmlu_direct_energy_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_energy_management.yaml'},\n",
       " 'kmmlu_direct_ecology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_ecology.yaml'},\n",
       " 'kmmlu_direct_taxation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_taxation.yaml'},\n",
       " 'kmmlu_direct_machine_design_and_manufacturing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_machine_design_and_manufacturing.yaml'},\n",
       " 'kmmlu_direct_political_science_and_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_political_science_and_sociology.yaml'},\n",
       " 'kmmlu_direct_civil_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_civil_engineering.yaml'},\n",
       " 'kmmlu_direct_real_estate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_real_estate.yaml'},\n",
       " 'kmmlu_direct_maritime_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_maritime_engineering.yaml'},\n",
       " 'kmmlu_direct_refrigerating_machinery': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_refrigerating_machinery.yaml'},\n",
       " 'kmmlu_direct_nondestructive_testing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_nondestructive_testing.yaml'},\n",
       " 'kmmlu_direct_environmental_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_environmental_science.yaml'},\n",
       " 'kmmlu_direct_education': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_education.yaml'},\n",
       " 'kmmlu_direct_fashion': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_fashion.yaml'},\n",
       " 'kmmlu_direct_electronics_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_electronics_engineering.yaml'},\n",
       " 'kmmlu_direct_economics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_economics.yaml'},\n",
       " 'kmmlu_direct_materials_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_materials_engineering.yaml'},\n",
       " 'kmmlu_direct_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_marketing.yaml'},\n",
       " 'kmmlu_direct_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_psychology.yaml'},\n",
       " 'kmmlu_direct_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_law.yaml'},\n",
       " 'kmmlu_direct_food_processing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_food_processing.yaml'},\n",
       " 'kmmlu_direct_geomatics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_geomatics.yaml'},\n",
       " 'kmmlu_direct_patent': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_patent.yaml'},\n",
       " 'kmmlu_direct_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_math.yaml'},\n",
       " 'kmmlu_direct_chemical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_chemical_engineering.yaml'},\n",
       " 'kmmlu_direct_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_chemistry.yaml'},\n",
       " 'kmmlu_direct_industrial_engineer': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_industrial_engineer.yaml'},\n",
       " 'kmmlu_direct_gas_technology_and_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_gas_technology_and_engineering.yaml'},\n",
       " 'kmmlu_direct_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_biology.yaml'},\n",
       " 'kmmlu_direct_aviation_engineering_and_maintenance': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_aviation_engineering_and_maintenance.yaml'},\n",
       " 'kmmlu_direct_health': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_health.yaml'},\n",
       " 'kmmlu_direct_mechanical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_mechanical_engineering.yaml'},\n",
       " 'kmmlu_direct_agricultural_sciences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_agricultural_sciences.yaml'},\n",
       " 'kmmlu_direct_telecommunications_and_wireless_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_telecommunications_and_wireless_technology.yaml'},\n",
       " 'kmmlu_direct_railway_and_automotive_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_railway_and_automotive_engineering.yaml'},\n",
       " 'kmmlu_direct_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_electrical_engineering.yaml'},\n",
       " 'kmmlu_direct_interior_architecture_and_design': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_interior_architecture_and_design.yaml'},\n",
       " 'kmmlu_direct_information_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_information_technology.yaml'},\n",
       " 'kmmlu_direct_korean_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_korean_history.yaml'},\n",
       " 'kmmlu_direct_criminal_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_criminal_law.yaml'},\n",
       " 'kmmlu_direct_construction': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_construction.yaml'},\n",
       " 'kmmlu_direct_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_accounting.yaml'},\n",
       " 'kmmlu_direct_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_management.yaml'},\n",
       " 'kmmlu_direct_public_safety': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_public_safety.yaml'},\n",
       " 'kmmlu_direct_social_welfare': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct/kmmlu_direct_social_welfare.yaml'},\n",
       " 'kmmlu_hard_direct_electronics_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_electronics_engineering.yaml'},\n",
       " 'kmmlu_hard_direct': {'type': 'group',\n",
       "  'task': ['kmmlu_hard_direct_electronics_engineering',\n",
       "   'kmmlu_hard_direct_electrical_engineering',\n",
       "   'kmmlu_hard_direct_accounting',\n",
       "   'kmmlu_hard_direct_social_welfare',\n",
       "   'kmmlu_hard_direct_maritime_engineering',\n",
       "   'kmmlu_hard_direct_agricultural_sciences',\n",
       "   'kmmlu_hard_direct_law',\n",
       "   'kmmlu_hard_direct_korean_history',\n",
       "   'kmmlu_hard_direct_machine_design_and_manufacturing',\n",
       "   'kmmlu_hard_direct_information_technology',\n",
       "   'kmmlu_hard_direct_environmental_science',\n",
       "   'kmmlu_hard_direct_mechanical_engineering',\n",
       "   'kmmlu_hard_direct_education',\n",
       "   'kmmlu_hard_direct_computer_science',\n",
       "   'kmmlu_hard_direct_real_estate',\n",
       "   'kmmlu_hard_direct_civil_engineering',\n",
       "   'kmmlu_hard_direct_gas_technology_and_engineering',\n",
       "   'kmmlu_hard_direct_ecology',\n",
       "   'kmmlu_hard_direct_political_science_and_sociology',\n",
       "   'kmmlu_hard_direct_aviation_engineering_and_maintenance',\n",
       "   'kmmlu_hard_direct_public_safety',\n",
       "   'kmmlu_hard_direct_economics',\n",
       "   'kmmlu_hard_direct_energy_management',\n",
       "   'kmmlu_hard_direct_math',\n",
       "   'kmmlu_hard_direct_psychology',\n",
       "   'kmmlu_hard_direct_fashion',\n",
       "   'kmmlu_hard_direct_biology',\n",
       "   'kmmlu_hard_direct_industrial_engineer',\n",
       "   'kmmlu_hard_direct_telecommunications_and_wireless_technology',\n",
       "   'kmmlu_hard_direct_criminal_law',\n",
       "   'kmmlu_hard_direct_health',\n",
       "   'kmmlu_hard_direct_railway_and_automotive_engineering',\n",
       "   'kmmlu_hard_direct_chemistry',\n",
       "   'kmmlu_hard_direct_refrigerating_machinery',\n",
       "   'kmmlu_hard_direct_materials_engineering',\n",
       "   'kmmlu_hard_direct_interior_architecture_and_design',\n",
       "   'kmmlu_hard_direct_food_processing',\n",
       "   'kmmlu_hard_direct_nondestructive_testing',\n",
       "   'kmmlu_hard_direct_taxation',\n",
       "   'kmmlu_hard_direct_construction',\n",
       "   'kmmlu_hard_direct_marketing',\n",
       "   'kmmlu_hard_direct_geomatics',\n",
       "   'kmmlu_hard_direct_chemical_engineering',\n",
       "   'kmmlu_hard_direct_patent',\n",
       "   'kmmlu_hard_direct_management'],\n",
       "  'yaml_path': -1},\n",
       " 'kmmlu_hard_direct_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_electrical_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_accounting.yaml'},\n",
       " 'kmmlu_hard_direct_social_welfare': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_social_welfare.yaml'},\n",
       " 'kmmlu_hard_direct_maritime_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_maritime_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_agricultural_sciences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_agricultural_sciences.yaml'},\n",
       " 'kmmlu_hard_direct_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_law.yaml'},\n",
       " 'kmmlu_hard_direct_korean_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_korean_history.yaml'},\n",
       " 'kmmlu_hard_direct_machine_design_and_manufacturing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_machine_design_and_manufacturing.yaml'},\n",
       " 'kmmlu_hard_direct_information_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_information_technology.yaml'},\n",
       " 'kmmlu_hard_direct_environmental_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_environmental_science.yaml'},\n",
       " 'kmmlu_hard_direct_mechanical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_mechanical_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_education': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_education.yaml'},\n",
       " 'kmmlu_hard_direct_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_computer_science.yaml'},\n",
       " 'kmmlu_hard_direct_real_estate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_real_estate.yaml'},\n",
       " 'kmmlu_hard_direct_civil_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_civil_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_gas_technology_and_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_gas_technology_and_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_ecology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_ecology.yaml'},\n",
       " 'kmmlu_hard_direct_political_science_and_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_political_science_and_sociology.yaml'},\n",
       " 'kmmlu_hard_direct_aviation_engineering_and_maintenance': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_aviation_engineering_and_maintenance.yaml'},\n",
       " 'kmmlu_hard_direct_public_safety': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_public_safety.yaml'},\n",
       " 'kmmlu_hard_direct_economics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_economics.yaml'},\n",
       " 'kmmlu_hard_direct_energy_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_energy_management.yaml'},\n",
       " 'kmmlu_hard_direct_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_math.yaml'},\n",
       " 'kmmlu_hard_direct_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_psychology.yaml'},\n",
       " 'kmmlu_hard_direct_fashion': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_fashion.yaml'},\n",
       " 'kmmlu_hard_direct_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_biology.yaml'},\n",
       " 'kmmlu_hard_direct_industrial_engineer': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_industrial_engineer.yaml'},\n",
       " 'kmmlu_hard_direct_telecommunications_and_wireless_technology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_telecommunications_and_wireless_technology.yaml'},\n",
       " 'kmmlu_hard_direct_criminal_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_criminal_law.yaml'},\n",
       " 'kmmlu_hard_direct_health': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_health.yaml'},\n",
       " 'kmmlu_hard_direct_railway_and_automotive_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_railway_and_automotive_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_chemistry.yaml'},\n",
       " 'kmmlu_hard_direct_refrigerating_machinery': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_refrigerating_machinery.yaml'},\n",
       " 'kmmlu_hard_direct_materials_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_materials_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_interior_architecture_and_design': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_interior_architecture_and_design.yaml'},\n",
       " 'kmmlu_hard_direct_food_processing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_food_processing.yaml'},\n",
       " 'kmmlu_hard_direct_nondestructive_testing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_nondestructive_testing.yaml'},\n",
       " 'kmmlu_hard_direct_taxation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_taxation.yaml'},\n",
       " 'kmmlu_hard_direct_construction': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_construction.yaml'},\n",
       " 'kmmlu_hard_direct_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_marketing.yaml'},\n",
       " 'kmmlu_hard_direct_geomatics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_geomatics.yaml'},\n",
       " 'kmmlu_hard_direct_chemical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_chemical_engineering.yaml'},\n",
       " 'kmmlu_hard_direct_patent': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_patent.yaml'},\n",
       " 'kmmlu_hard_direct_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kmmlu/direct_hard/kmmlu_direct_hard_management.yaml'},\n",
       " 'minerva_math_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_algebra.yaml'},\n",
       " 'math_word_problems': {'type': 'group',\n",
       "  'task': ['minerva_math_algebra',\n",
       "   'minerva_math_geometry',\n",
       "   'minerva_math_prealgebra',\n",
       "   'minerva_math_precalc',\n",
       "   'minerva_math_counting_and_prob',\n",
       "   'minerva_math_intermediate_algebra',\n",
       "   'minerva_math_num_theory',\n",
       "   'gsm8k',\n",
       "   'gsm8k_cot_zeroshot',\n",
       "   'mathqa'],\n",
       "  'yaml_path': -1},\n",
       " 'minerva_math_geometry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_geometry.yaml'},\n",
       " 'minerva_math_prealgebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_prealgebra.yaml'},\n",
       " 'minerva_math_precalc': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_precalc.yaml'},\n",
       " 'minerva_math_counting_and_prob': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_counting_and_prob.yaml'},\n",
       " 'minerva_math_intermediate_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_intermediate_algebra.yaml'},\n",
       " 'minerva_math_num_theory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/minerva_math/minerva_math_num_theory.yaml'},\n",
       " 'gsm8k_cot_self_consistency': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/gsm8k/gsm8k-cot-self-consistency.yaml'},\n",
       " 'chain_of_thought': {'type': 'group',\n",
       "  'task': ['gsm8k_cot_self_consistency', 'gsm8k_cot'],\n",
       "  'yaml_path': -1},\n",
       " 'self_consistency': {'type': 'group',\n",
       "  'task': ['gsm8k_cot_self_consistency'],\n",
       "  'yaml_path': -1},\n",
       " 'gsm8k_cot': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/gsm8k/gsm8k-cot.yaml'},\n",
       " 'gsm8k': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/gsm8k/gsm8k.yaml'},\n",
       " 'gsm8k_cot_zeroshot': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/gsm8k/gsm8k-cot-zeroshot.yaml'},\n",
       " 'drop': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/drop/default.yaml'},\n",
       " 'social_iqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/siqa/siqa.yaml'},\n",
       " 'bbh_fewshot_logical_deduction_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/logical_deduction_five_objects.yaml'},\n",
       " 'bbh_fewshot': {'type': 'group',\n",
       "  'task': ['bbh_fewshot_logical_deduction_five_objects',\n",
       "   'bbh_fewshot_reasoning_about_colored_objects',\n",
       "   'bbh_fewshot_boolean_expressions',\n",
       "   'bbh_fewshot_word_sorting',\n",
       "   'bbh_fewshot_logical_deduction_three_objects',\n",
       "   'bbh_fewshot_formal_fallacies',\n",
       "   'bbh_fewshot_sports_understanding',\n",
       "   'bbh_fewshot_ruin_names',\n",
       "   'bbh_fewshot_temporal_sequences',\n",
       "   'bbh_fewshot_disambiguation_qa',\n",
       "   'bbh_fewshot_date_understanding',\n",
       "   'bbh_fewshot_snarks',\n",
       "   'bbh_fewshot_tracking_shuffled_objects_seven_objects',\n",
       "   'bbh_fewshot_object_counting',\n",
       "   'bbh_fewshot_causal_judgement',\n",
       "   'bbh_fewshot_navigate',\n",
       "   'bbh_fewshot_logical_deduction_seven_objects',\n",
       "   'bbh_fewshot_dyck_languages',\n",
       "   'bbh_fewshot_multistep_arithmetic_two',\n",
       "   'bbh_fewshot_tracking_shuffled_objects_three_objects',\n",
       "   'bbh_fewshot_hyperbaton',\n",
       "   'bbh_fewshot_movie_recommendation',\n",
       "   'bbh_fewshot_penguins_in_a_table',\n",
       "   'bbh_fewshot_tracking_shuffled_objects_five_objects',\n",
       "   'bbh_fewshot_web_of_lies',\n",
       "   'bbh_fewshot_geometric_shapes',\n",
       "   'bbh_fewshot_salient_translation_error_detection'],\n",
       "  'yaml_path': -1},\n",
       " 'bbh_fewshot_reasoning_about_colored_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/reasoning_about_colored_objects.yaml'},\n",
       " 'bbh_fewshot_boolean_expressions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/boolean_expressions.yaml'},\n",
       " 'bbh_fewshot_word_sorting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/word_sorting.yaml'},\n",
       " 'bbh_fewshot_logical_deduction_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/logical_deduction_three_objects.yaml'},\n",
       " 'bbh_fewshot_formal_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/formal_fallacies.yaml'},\n",
       " 'bbh_fewshot_sports_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/sports_understanding.yaml'},\n",
       " 'bbh_fewshot_ruin_names': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/ruin_names.yaml'},\n",
       " 'bbh_fewshot_temporal_sequences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/temporal_sequences.yaml'},\n",
       " 'bbh_fewshot_disambiguation_qa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/disambiguation_qa.yaml'},\n",
       " 'bbh_fewshot_date_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/date_understanding.yaml'},\n",
       " 'bbh_fewshot_snarks': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/snarks.yaml'},\n",
       " 'bbh_fewshot_tracking_shuffled_objects_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/tracking_shuffled_objects_seven_objects.yaml'},\n",
       " 'bbh_fewshot_object_counting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/object_counting.yaml'},\n",
       " 'bbh_fewshot_causal_judgement': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/causal_judgement.yaml'},\n",
       " 'bbh_fewshot_navigate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/navigate.yaml'},\n",
       " 'bbh_fewshot_logical_deduction_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/logical_deduction_seven_objects.yaml'},\n",
       " 'bbh_fewshot_dyck_languages': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/dyck_languages.yaml'},\n",
       " 'bbh_fewshot_multistep_arithmetic_two': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/multistep_arithmetic_two.yaml'},\n",
       " 'bbh_fewshot_tracking_shuffled_objects_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/tracking_shuffled_objects_three_objects.yaml'},\n",
       " 'bbh_fewshot_hyperbaton': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/hyperbaton.yaml'},\n",
       " 'bbh_fewshot_movie_recommendation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/movie_recommendation.yaml'},\n",
       " 'bbh_fewshot_penguins_in_a_table': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/penguins_in_a_table.yaml'},\n",
       " 'bbh_fewshot_tracking_shuffled_objects_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/tracking_shuffled_objects_five_objects.yaml'},\n",
       " 'bbh_fewshot_web_of_lies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/web_of_lies.yaml'},\n",
       " 'bbh_fewshot_geometric_shapes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/geometric_shapes.yaml'},\n",
       " 'bbh_fewshot_salient_translation_error_detection': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/fewshot/salient_translation_error_detection.yaml'},\n",
       " 'bbh_cot_zeroshot_logical_deduction_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/logical_deduction_five_objects.yaml'},\n",
       " 'bbh_cot_zeroshot': {'type': 'group',\n",
       "  'task': ['bbh_cot_zeroshot_logical_deduction_five_objects',\n",
       "   'bbh_cot_zeroshot_reasoning_about_colored_objects',\n",
       "   'bbh_cot_zeroshot_boolean_expressions',\n",
       "   'bbh_cot_zeroshot_word_sorting',\n",
       "   'bbh_cot_zeroshot_logical_deduction_three_objects',\n",
       "   'bbh_cot_zeroshot_formal_fallacies',\n",
       "   'bbh_cot_zeroshot_sports_understanding',\n",
       "   'bbh_cot_zeroshot_ruin_names',\n",
       "   'bbh_cot_zeroshot_temporal_sequences',\n",
       "   'bbh_cot_zeroshot_disambiguation_qa',\n",
       "   'bbh_cot_zeroshot_date_understanding',\n",
       "   'bbh_cot_zeroshot_snarks',\n",
       "   'bbh_cot_zeroshot_tracking_shuffled_objects_seven_objects',\n",
       "   'bbh_cot_zeroshot_object_counting',\n",
       "   'bbh_cot_zeroshot_causal_judgement',\n",
       "   'bbh_cot_zeroshot_navigate',\n",
       "   'bbh_cot_zeroshot_logical_deduction_seven_objects',\n",
       "   'bbh_cot_zeroshot_dyck_languages',\n",
       "   'bbh_cot_zeroshot_multistep_arithmetic_two',\n",
       "   'bbh_cot_zeroshot_tracking_shuffled_objects_three_objects',\n",
       "   'bbh_cot_zeroshot_hyperbaton',\n",
       "   'bbh_cot_zeroshot_movie_recommendation',\n",
       "   'bbh_cot_zeroshot_penguins_in_a_table',\n",
       "   'bbh_cot_zeroshot_tracking_shuffled_objects_five_objects',\n",
       "   'bbh_cot_zeroshot_web_of_lies',\n",
       "   'bbh_cot_zeroshot_geometric_shapes',\n",
       "   'bbh_cot_zeroshot_salient_translation_error_detection'],\n",
       "  'yaml_path': -1},\n",
       " 'bbh_cot_zeroshot_reasoning_about_colored_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/reasoning_about_colored_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_boolean_expressions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/boolean_expressions.yaml'},\n",
       " 'bbh_cot_zeroshot_word_sorting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/word_sorting.yaml'},\n",
       " 'bbh_cot_zeroshot_logical_deduction_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/logical_deduction_three_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_formal_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/formal_fallacies.yaml'},\n",
       " 'bbh_cot_zeroshot_sports_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/sports_understanding.yaml'},\n",
       " 'bbh_cot_zeroshot_ruin_names': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/ruin_names.yaml'},\n",
       " 'bbh_cot_zeroshot_temporal_sequences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/temporal_sequences.yaml'},\n",
       " 'bbh_cot_zeroshot_disambiguation_qa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/disambiguation_qa.yaml'},\n",
       " 'bbh_cot_zeroshot_date_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/date_understanding.yaml'},\n",
       " 'bbh_cot_zeroshot_snarks': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/snarks.yaml'},\n",
       " 'bbh_cot_zeroshot_tracking_shuffled_objects_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/tracking_shuffled_objects_seven_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_object_counting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/object_counting.yaml'},\n",
       " 'bbh_cot_zeroshot_causal_judgement': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/causal_judgement.yaml'},\n",
       " 'bbh_cot_zeroshot_navigate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/navigate.yaml'},\n",
       " 'bbh_cot_zeroshot_logical_deduction_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/logical_deduction_seven_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_dyck_languages': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/dyck_languages.yaml'},\n",
       " 'bbh_cot_zeroshot_multistep_arithmetic_two': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/multistep_arithmetic_two.yaml'},\n",
       " 'bbh_cot_zeroshot_tracking_shuffled_objects_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/tracking_shuffled_objects_three_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_hyperbaton': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/hyperbaton.yaml'},\n",
       " 'bbh_cot_zeroshot_movie_recommendation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/movie_recommendation.yaml'},\n",
       " 'bbh_cot_zeroshot_penguins_in_a_table': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/penguins_in_a_table.yaml'},\n",
       " 'bbh_cot_zeroshot_tracking_shuffled_objects_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/tracking_shuffled_objects_five_objects.yaml'},\n",
       " 'bbh_cot_zeroshot_web_of_lies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/web_of_lies.yaml'},\n",
       " 'bbh_cot_zeroshot_geometric_shapes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/geometric_shapes.yaml'},\n",
       " 'bbh_cot_zeroshot_salient_translation_error_detection': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_zeroshot/salient_translation_error_detection.yaml'},\n",
       " 'bbh_cot_fewshot_logical_deduction_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/logical_deduction_five_objects.yaml'},\n",
       " 'bbh': {'type': 'group',\n",
       "  'task': ['bbh_cot_fewshot_logical_deduction_five_objects',\n",
       "   'bbh_cot_fewshot_reasoning_about_colored_objects',\n",
       "   'bbh_cot_fewshot_boolean_expressions',\n",
       "   'bbh_cot_fewshot_word_sorting',\n",
       "   'bbh_cot_fewshot_logical_deduction_three_objects',\n",
       "   'bbh_cot_fewshot_formal_fallacies',\n",
       "   'bbh_cot_fewshot_sports_understanding',\n",
       "   'bbh_cot_fewshot_ruin_names',\n",
       "   'bbh_cot_fewshot_temporal_sequences',\n",
       "   'bbh_cot_fewshot_disambiguation_qa',\n",
       "   'bbh_cot_fewshot_date_understanding',\n",
       "   'bbh_cot_fewshot_snarks',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_seven_objects',\n",
       "   'bbh_cot_fewshot_object_counting',\n",
       "   'bbh_cot_fewshot_causal_judgement',\n",
       "   'bbh_cot_fewshot_navigate',\n",
       "   'bbh_cot_fewshot_logical_deduction_seven_objects',\n",
       "   'bbh_cot_fewshot_dyck_languages',\n",
       "   'bbh_cot_fewshot_multistep_arithmetic_two',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_three_objects',\n",
       "   'bbh_cot_fewshot_hyperbaton',\n",
       "   'bbh_cot_fewshot_movie_recommendation',\n",
       "   'bbh_cot_fewshot_penguins_in_a_table',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_five_objects',\n",
       "   'bbh_cot_fewshot_web_of_lies',\n",
       "   'bbh_cot_fewshot_geometric_shapes',\n",
       "   'bbh_cot_fewshot_salient_translation_error_detection'],\n",
       "  'yaml_path': -1},\n",
       " 'bbh_cot_fewshot': {'type': 'group',\n",
       "  'task': ['bbh_cot_fewshot_logical_deduction_five_objects',\n",
       "   'bbh_cot_fewshot_reasoning_about_colored_objects',\n",
       "   'bbh_cot_fewshot_boolean_expressions',\n",
       "   'bbh_cot_fewshot_word_sorting',\n",
       "   'bbh_cot_fewshot_logical_deduction_three_objects',\n",
       "   'bbh_cot_fewshot_formal_fallacies',\n",
       "   'bbh_cot_fewshot_sports_understanding',\n",
       "   'bbh_cot_fewshot_ruin_names',\n",
       "   'bbh_cot_fewshot_temporal_sequences',\n",
       "   'bbh_cot_fewshot_disambiguation_qa',\n",
       "   'bbh_cot_fewshot_date_understanding',\n",
       "   'bbh_cot_fewshot_snarks',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_seven_objects',\n",
       "   'bbh_cot_fewshot_object_counting',\n",
       "   'bbh_cot_fewshot_causal_judgement',\n",
       "   'bbh_cot_fewshot_navigate',\n",
       "   'bbh_cot_fewshot_logical_deduction_seven_objects',\n",
       "   'bbh_cot_fewshot_dyck_languages',\n",
       "   'bbh_cot_fewshot_multistep_arithmetic_two',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_three_objects',\n",
       "   'bbh_cot_fewshot_hyperbaton',\n",
       "   'bbh_cot_fewshot_movie_recommendation',\n",
       "   'bbh_cot_fewshot_penguins_in_a_table',\n",
       "   'bbh_cot_fewshot_tracking_shuffled_objects_five_objects',\n",
       "   'bbh_cot_fewshot_web_of_lies',\n",
       "   'bbh_cot_fewshot_geometric_shapes',\n",
       "   'bbh_cot_fewshot_salient_translation_error_detection'],\n",
       "  'yaml_path': -1},\n",
       " 'bbh_cot_fewshot_reasoning_about_colored_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/reasoning_about_colored_objects.yaml'},\n",
       " 'bbh_cot_fewshot_boolean_expressions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/boolean_expressions.yaml'},\n",
       " 'bbh_cot_fewshot_word_sorting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/word_sorting.yaml'},\n",
       " 'bbh_cot_fewshot_logical_deduction_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/logical_deduction_three_objects.yaml'},\n",
       " 'bbh_cot_fewshot_formal_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/formal_fallacies.yaml'},\n",
       " 'bbh_cot_fewshot_sports_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/sports_understanding.yaml'},\n",
       " 'bbh_cot_fewshot_ruin_names': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/ruin_names.yaml'},\n",
       " 'bbh_cot_fewshot_temporal_sequences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/temporal_sequences.yaml'},\n",
       " 'bbh_cot_fewshot_disambiguation_qa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/disambiguation_qa.yaml'},\n",
       " 'bbh_cot_fewshot_date_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/date_understanding.yaml'},\n",
       " 'bbh_cot_fewshot_snarks': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/snarks.yaml'},\n",
       " 'bbh_cot_fewshot_tracking_shuffled_objects_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/tracking_shuffled_objects_seven_objects.yaml'},\n",
       " 'bbh_cot_fewshot_object_counting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/object_counting.yaml'},\n",
       " 'bbh_cot_fewshot_causal_judgement': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/causal_judgement.yaml'},\n",
       " 'bbh_cot_fewshot_navigate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/navigate.yaml'},\n",
       " 'bbh_cot_fewshot_logical_deduction_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/logical_deduction_seven_objects.yaml'},\n",
       " 'bbh_cot_fewshot_dyck_languages': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/dyck_languages.yaml'},\n",
       " 'bbh_cot_fewshot_multistep_arithmetic_two': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/multistep_arithmetic_two.yaml'},\n",
       " 'bbh_cot_fewshot_tracking_shuffled_objects_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/tracking_shuffled_objects_three_objects.yaml'},\n",
       " 'bbh_cot_fewshot_hyperbaton': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/hyperbaton.yaml'},\n",
       " 'bbh_cot_fewshot_movie_recommendation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/movie_recommendation.yaml'},\n",
       " 'bbh_cot_fewshot_penguins_in_a_table': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/penguins_in_a_table.yaml'},\n",
       " 'bbh_cot_fewshot_tracking_shuffled_objects_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/tracking_shuffled_objects_five_objects.yaml'},\n",
       " 'bbh_cot_fewshot_web_of_lies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/web_of_lies.yaml'},\n",
       " 'bbh_cot_fewshot_geometric_shapes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/geometric_shapes.yaml'},\n",
       " 'bbh_cot_fewshot_salient_translation_error_detection': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/cot_fewshot/salient_translation_error_detection.yaml'},\n",
       " 'bbh_zeroshot_logical_deduction_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/logical_deduction_five_objects.yaml'},\n",
       " 'bbh_zeroshot': {'type': 'group',\n",
       "  'task': ['bbh_zeroshot_logical_deduction_five_objects',\n",
       "   'bbh_zeroshot_reasoning_about_colored_objects',\n",
       "   'bbh_zeroshot_boolean_expressions',\n",
       "   'bbh_zeroshot_word_sorting',\n",
       "   'bbh_zeroshot_logical_deduction_three_objects',\n",
       "   'bbh_zeroshot_formal_fallacies',\n",
       "   'bbh_zeroshot_sports_understanding',\n",
       "   'bbh_zeroshot_ruin_names',\n",
       "   'bbh_zeroshot_temporal_sequences',\n",
       "   'bbh_zeroshot_disambiguation_qa',\n",
       "   'bbh_zeroshot_date_understanding',\n",
       "   'bbh_zeroshot_snarks',\n",
       "   'bbh_zeroshot_tracking_shuffled_objects_seven_objects',\n",
       "   'bbh_zeroshot_object_counting',\n",
       "   'bbh_zeroshot_causal_judgement',\n",
       "   'bbh_zeroshot_navigate',\n",
       "   'bbh_zeroshot_logical_deduction_seven_objects',\n",
       "   'bbh_zeroshot_dyck_languages',\n",
       "   'bbh_zeroshot_multistep_arithmetic_two',\n",
       "   'bbh_zeroshot_tracking_shuffled_objects_three_objects',\n",
       "   'bbh_zeroshot_hyperbaton',\n",
       "   'bbh_zeroshot_movie_recommendation',\n",
       "   'bbh_zeroshot_penguins_in_a_table',\n",
       "   'bbh_zeroshot_tracking_shuffled_objects_five_objects',\n",
       "   'bbh_zeroshot_web_of_lies',\n",
       "   'bbh_zeroshot_geometric_shapes',\n",
       "   'bbh_zeroshot_salient_translation_error_detection'],\n",
       "  'yaml_path': -1},\n",
       " 'bbh_zeroshot_reasoning_about_colored_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/reasoning_about_colored_objects.yaml'},\n",
       " 'bbh_zeroshot_boolean_expressions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/boolean_expressions.yaml'},\n",
       " 'bbh_zeroshot_word_sorting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/word_sorting.yaml'},\n",
       " 'bbh_zeroshot_logical_deduction_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/logical_deduction_three_objects.yaml'},\n",
       " 'bbh_zeroshot_formal_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/formal_fallacies.yaml'},\n",
       " 'bbh_zeroshot_sports_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/sports_understanding.yaml'},\n",
       " 'bbh_zeroshot_ruin_names': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/ruin_names.yaml'},\n",
       " 'bbh_zeroshot_temporal_sequences': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/temporal_sequences.yaml'},\n",
       " 'bbh_zeroshot_disambiguation_qa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/disambiguation_qa.yaml'},\n",
       " 'bbh_zeroshot_date_understanding': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/date_understanding.yaml'},\n",
       " 'bbh_zeroshot_snarks': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/snarks.yaml'},\n",
       " 'bbh_zeroshot_tracking_shuffled_objects_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/tracking_shuffled_objects_seven_objects.yaml'},\n",
       " 'bbh_zeroshot_object_counting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/object_counting.yaml'},\n",
       " 'bbh_zeroshot_causal_judgement': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/causal_judgement.yaml'},\n",
       " 'bbh_zeroshot_navigate': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/navigate.yaml'},\n",
       " 'bbh_zeroshot_logical_deduction_seven_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/logical_deduction_seven_objects.yaml'},\n",
       " 'bbh_zeroshot_dyck_languages': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/dyck_languages.yaml'},\n",
       " 'bbh_zeroshot_multistep_arithmetic_two': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/multistep_arithmetic_two.yaml'},\n",
       " 'bbh_zeroshot_tracking_shuffled_objects_three_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/tracking_shuffled_objects_three_objects.yaml'},\n",
       " 'bbh_zeroshot_hyperbaton': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/hyperbaton.yaml'},\n",
       " 'bbh_zeroshot_movie_recommendation': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/movie_recommendation.yaml'},\n",
       " 'bbh_zeroshot_penguins_in_a_table': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/penguins_in_a_table.yaml'},\n",
       " 'bbh_zeroshot_tracking_shuffled_objects_five_objects': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/tracking_shuffled_objects_five_objects.yaml'},\n",
       " 'bbh_zeroshot_web_of_lies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/web_of_lies.yaml'},\n",
       " 'bbh_zeroshot_geometric_shapes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/geometric_shapes.yaml'},\n",
       " 'bbh_zeroshot_salient_translation_error_detection': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bbh/zeroshot/salient_translation_error_detection.yaml'},\n",
       " 'polemo2_out': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/polemo2/polemo2_out.yaml'},\n",
       " 'polemo2': {'type': 'group',\n",
       "  'task': ['polemo2_out', 'polemo2_in'],\n",
       "  'yaml_path': -1},\n",
       " 'polemo2_in': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/polemo2/polemo2_in.yaml'},\n",
       " 'xwinograd_fr': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_fr.yaml'},\n",
       " 'xwinograd': {'type': 'group',\n",
       "  'task': ['xwinograd_fr',\n",
       "   'xwinograd_zh',\n",
       "   'xwinograd_ru',\n",
       "   'xwinograd_pt',\n",
       "   'xwinograd_jp',\n",
       "   'xwinograd_en'],\n",
       "  'yaml_path': -1},\n",
       " 'xwinograd_zh': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_zh.yaml'},\n",
       " 'xwinograd_ru': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_ru.yaml'},\n",
       " 'xwinograd_pt': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_pt.yaml'},\n",
       " 'xwinograd_jp': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_jp.yaml'},\n",
       " 'xwinograd_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xwinograd/xwinograd_en.yaml'},\n",
       " 'squadv2': {'type': 'python_task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/squadv2/squadv2.yaml'},\n",
       " 'wikitext': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/wikitext/wikitext.yaml'},\n",
       " 'hellaswag': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/hellaswag/hellaswag.yaml'},\n",
       " 'multiple_choice': {'type': 'group', 'task': ['hellaswag'], 'yaml_path': -1},\n",
       " 'qasper_freeform': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/qasper/freeform.yaml'},\n",
       " 'qasper': {'type': 'group',\n",
       "  'task': ['qasper_freeform', 'qasper_bool'],\n",
       "  'yaml_path': -1},\n",
       " 'qasper_bool': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/qasper/bool.yaml'},\n",
       " 'piqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/piqa/piqa.yaml'},\n",
       " 'mathqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mathqa/mathqa.yaml'},\n",
       " 'realtoxicityprompts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/realtoxicityprompts/realtoxicityprompts.yaml'},\n",
       " 'agieval_sat_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/sat-en.yaml'},\n",
       " 'agieval': {'type': 'group',\n",
       "  'task': ['agieval_sat_en',\n",
       "   'agieval_aqua_rat',\n",
       "   'agieval_math',\n",
       "   'agieval_sat_math',\n",
       "   'agieval_lsat_ar',\n",
       "   'agieval_logiqa_en',\n",
       "   'agieval_gaokao_history',\n",
       "   'agieval_gaokao_english',\n",
       "   'agieval_gaokao_geography',\n",
       "   'agieval_lsat_lr',\n",
       "   'agieval_lsat_rc',\n",
       "   'agieval_jec_qa_ca',\n",
       "   'agieval_gaokao_physics',\n",
       "   'agieval_gaokao_biology',\n",
       "   'agieval_gaokao_chemistry',\n",
       "   'agieval_sat_en_without_passage',\n",
       "   'agieval_gaokao_chinese',\n",
       "   'agieval_jec_qa_kd',\n",
       "   'agieval_logiqa_zh',\n",
       "   'agieval_gaokao_mathcloze',\n",
       "   'agieval_gaokao_mathqa'],\n",
       "  'yaml_path': -1},\n",
       " 'agieval_nous': {'type': 'group',\n",
       "  'task': ['agieval_sat_en',\n",
       "   'agieval_aqua_rat',\n",
       "   'agieval_sat_math',\n",
       "   'agieval_lsat_ar',\n",
       "   'agieval_logiqa_en',\n",
       "   'agieval_lsat_lr',\n",
       "   'agieval_lsat_rc',\n",
       "   'agieval_sat_en_without_passage'],\n",
       "  'yaml_path': -1},\n",
       " 'agieval_en': {'type': 'group',\n",
       "  'task': ['agieval_sat_en',\n",
       "   'agieval_aqua_rat',\n",
       "   'agieval_math',\n",
       "   'agieval_sat_math',\n",
       "   'agieval_lsat_ar',\n",
       "   'agieval_logiqa_en',\n",
       "   'agieval_gaokao_english',\n",
       "   'agieval_lsat_lr',\n",
       "   'agieval_lsat_rc',\n",
       "   'agieval_sat_en_without_passage'],\n",
       "  'yaml_path': -1},\n",
       " 'agieval_aqua_rat': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/aqua-rat.yaml'},\n",
       " 'agieval_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/math.yaml'},\n",
       " 'agieval_sat_math': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/sat-math.yaml'},\n",
       " 'agieval_lsat_ar': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/lsat-ar.yaml'},\n",
       " 'agieval_logiqa_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/logiqa-en.yaml'},\n",
       " 'agieval_gaokao_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-history.yaml'},\n",
       " 'agieval_cn': {'type': 'group',\n",
       "  'task': ['agieval_gaokao_history',\n",
       "   'agieval_gaokao_geography',\n",
       "   'agieval_jec_qa_ca',\n",
       "   'agieval_gaokao_physics',\n",
       "   'agieval_gaokao_biology',\n",
       "   'agieval_gaokao_chemistry',\n",
       "   'agieval_gaokao_chinese',\n",
       "   'agieval_jec_qa_kd',\n",
       "   'agieval_logiqa_zh',\n",
       "   'agieval_gaokao_mathcloze',\n",
       "   'agieval_gaokao_mathqa'],\n",
       "  'yaml_path': -1},\n",
       " 'agieval_gaokao_english': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-english.yaml'},\n",
       " 'agieval_gaokao_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-geography.yaml'},\n",
       " 'agieval_lsat_lr': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/lsat-lr.yaml'},\n",
       " 'agieval_lsat_rc': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/lsat-rc.yaml'},\n",
       " 'agieval_jec_qa_ca': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/jec-qa-ca.yaml'},\n",
       " 'agieval_gaokao_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-physics.yaml'},\n",
       " 'agieval_gaokao_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-biology.yaml'},\n",
       " 'agieval_gaokao_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-chemistry.yaml'},\n",
       " 'agieval_sat_en_without_passage': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/sat-en-without-passage.yaml'},\n",
       " 'agieval_gaokao_chinese': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-chinese.yaml'},\n",
       " 'agieval_jec_qa_kd': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/jec-qa-kd.yaml'},\n",
       " 'agieval_logiqa_zh': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/logiqa-zh.yaml'},\n",
       " 'agieval_gaokao_mathcloze': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-mathcloze.yaml'},\n",
       " 'agieval_gaokao_mathqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/agieval/gaokao-mathqa.yaml'},\n",
       " 'truthfulqa_mc2': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/truthfulqa/truthfulqa_mc2.yaml'},\n",
       " 'truthfulqa': {'type': 'group',\n",
       "  'task': ['truthfulqa_mc2', 'truthfulqa_gen', 'truthfulqa_mc1'],\n",
       "  'yaml_path': -1},\n",
       " 'truthfulqa_gen': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/truthfulqa/truthfulqa_gen.yaml'},\n",
       " 'truthfulqa_mc1': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/truthfulqa/truthfulqa_mc1.yaml'},\n",
       " 'medmcqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/medmcqa/medmcqa.yaml'},\n",
       " 'openllm': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/openllm.yaml'},\n",
       " 'pythia': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/pythia.yaml'},\n",
       " 'minerva_math': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/minerva_math.yaml'},\n",
       " 't0_eval': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/t0_eval.yaml'},\n",
       " 'multimedqa': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/multimedqa/multimedqa.yaml'},\n",
       " 'flan_held_in': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/flan/flan_held_in.yaml'},\n",
       " 'flan_held_out': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/benchmarks/flan/flan_held_out.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_public_relations': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_public_relations.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_social_sciences': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_loglikelihood_public_relations',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_psychology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_microeconomics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_econometrics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_government_and_politics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_professional_psychology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_human_sexuality',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_macroeconomics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_sociology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_us_foreign_policy',\n",
       "   'mmlu_flan_n_shot_loglikelihood_security_studies',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_geography'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_european_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_european_history.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_humanities': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_loglikelihood_high_school_european_history',\n",
       "   'mmlu_flan_n_shot_loglikelihood_prehistory',\n",
       "   'mmlu_flan_n_shot_loglikelihood_formal_logic',\n",
       "   'mmlu_flan_n_shot_loglikelihood_international_law',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_us_history',\n",
       "   'mmlu_flan_n_shot_loglikelihood_moral_disputes',\n",
       "   'mmlu_flan_n_shot_loglikelihood_jurisprudence',\n",
       "   'mmlu_flan_n_shot_loglikelihood_professional_law',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_world_history',\n",
       "   'mmlu_flan_n_shot_loglikelihood_philosophy',\n",
       "   'mmlu_flan_n_shot_loglikelihood_moral_scenarios',\n",
       "   'mmlu_flan_n_shot_loglikelihood_logical_fallacies',\n",
       "   'mmlu_flan_n_shot_loglikelihood_world_religions'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_psychology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_microeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_microeconomics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_astronomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_astronomy.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_stem': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_loglikelihood_astronomy',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_biology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_computer_science',\n",
       "   'mmlu_flan_n_shot_loglikelihood_elementary_mathematics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_biology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_mathematics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_machine_learning',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_mathematics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_chemistry',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_physics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_computer_science',\n",
       "   'mmlu_flan_n_shot_loglikelihood_abstract_algebra',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_physics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_computer_security',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_statistics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_conceptual_physics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_high_school_chemistry',\n",
       "   'mmlu_flan_n_shot_loglikelihood_anatomy',\n",
       "   'mmlu_flan_n_shot_loglikelihood_electrical_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_loglikelihood_prehistory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_prehistory.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_econometrics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_econometrics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_professional_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_professional_medicine.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_other': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_loglikelihood_professional_medicine',\n",
       "   'mmlu_flan_n_shot_loglikelihood_medical_genetics',\n",
       "   'mmlu_flan_n_shot_loglikelihood_human_aging',\n",
       "   'mmlu_flan_n_shot_loglikelihood_marketing',\n",
       "   'mmlu_flan_n_shot_loglikelihood_miscellaneous',\n",
       "   'mmlu_flan_n_shot_loglikelihood_global_facts',\n",
       "   'mmlu_flan_n_shot_loglikelihood_virology',\n",
       "   'mmlu_flan_n_shot_loglikelihood_clinical_knowledge',\n",
       "   'mmlu_flan_n_shot_loglikelihood_nutrition',\n",
       "   'mmlu_flan_n_shot_loglikelihood_professional_accounting',\n",
       "   'mmlu_flan_n_shot_loglikelihood_college_medicine',\n",
       "   'mmlu_flan_n_shot_loglikelihood_management',\n",
       "   'mmlu_flan_n_shot_loglikelihood_business_ethics'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_government_and_politics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_government_and_politics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_medical_genetics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_medical_genetics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_human_aging': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_human_aging.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_formal_logic': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_formal_logic.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_biology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_marketing.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_computer_science.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_elementary_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_elementary_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_international_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_international_law.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_us_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_us_history.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_miscellaneous': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_miscellaneous.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/_mmlu.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_global_facts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_global_facts.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_moral_disputes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_moral_disputes.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_virology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_virology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_professional_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_professional_psychology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_biology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_human_sexuality': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_human_sexuality.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_clinical_knowledge': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_clinical_knowledge.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_jurisprudence': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_jurisprudence.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_professional_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_professional_law.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_nutrition': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_nutrition.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_machine_learning': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_machine_learning.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_professional_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_professional_accounting.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_macroeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_macroeconomics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_sociology.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_us_foreign_policy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_us_foreign_policy.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_chemistry.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_security_studies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_security_studies.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_computer_science.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_world_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_world_history.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_college_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_college_medicine.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_abstract_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_abstract_algebra.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_management.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_philosophy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_philosophy.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_geography.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_moral_scenarios': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_moral_scenarios.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_business_ethics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_business_ethics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_computer_security': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_computer_security.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_logical_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_logical_fallacies.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_statistics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_statistics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_conceptual_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_conceptual_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_high_school_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_high_school_chemistry.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_anatomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_anatomy.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_electrical_engineering.yaml'},\n",
       " 'mmlu_flan_n_shot_loglikelihood_world_religions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/loglikelihood/mmlu_world_religions.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_public_relations': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_public_relations.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_social_sciences': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_generative_public_relations',\n",
       "   'mmlu_flan_n_shot_generative_high_school_psychology',\n",
       "   'mmlu_flan_n_shot_generative_high_school_microeconomics',\n",
       "   'mmlu_flan_n_shot_generative_econometrics',\n",
       "   'mmlu_flan_n_shot_generative_high_school_government_and_politics',\n",
       "   'mmlu_flan_n_shot_generative_professional_psychology',\n",
       "   'mmlu_flan_n_shot_generative_human_sexuality',\n",
       "   'mmlu_flan_n_shot_generative_high_school_macroeconomics',\n",
       "   'mmlu_flan_n_shot_generative_sociology',\n",
       "   'mmlu_flan_n_shot_generative_us_foreign_policy',\n",
       "   'mmlu_flan_n_shot_generative_security_studies',\n",
       "   'mmlu_flan_n_shot_generative_high_school_geography'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_generative_high_school_european_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_european_history.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_humanities': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_generative_high_school_european_history',\n",
       "   'mmlu_flan_n_shot_generative_prehistory',\n",
       "   'mmlu_flan_n_shot_generative_formal_logic',\n",
       "   'mmlu_flan_n_shot_generative_international_law',\n",
       "   'mmlu_flan_n_shot_generative_high_school_us_history',\n",
       "   'mmlu_flan_n_shot_generative_moral_disputes',\n",
       "   'mmlu_flan_n_shot_generative_jurisprudence',\n",
       "   'mmlu_flan_n_shot_generative_professional_law',\n",
       "   'mmlu_flan_n_shot_generative_high_school_world_history',\n",
       "   'mmlu_flan_n_shot_generative_philosophy',\n",
       "   'mmlu_flan_n_shot_generative_moral_scenarios',\n",
       "   'mmlu_flan_n_shot_generative_logical_fallacies',\n",
       "   'mmlu_flan_n_shot_generative_world_religions'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_generative_high_school_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_psychology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_microeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_microeconomics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_astronomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_astronomy.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_stem': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_generative_astronomy',\n",
       "   'mmlu_flan_n_shot_generative_college_biology',\n",
       "   'mmlu_flan_n_shot_generative_high_school_computer_science',\n",
       "   'mmlu_flan_n_shot_generative_elementary_mathematics',\n",
       "   'mmlu_flan_n_shot_generative_high_school_biology',\n",
       "   'mmlu_flan_n_shot_generative_high_school_mathematics',\n",
       "   'mmlu_flan_n_shot_generative_machine_learning',\n",
       "   'mmlu_flan_n_shot_generative_college_mathematics',\n",
       "   'mmlu_flan_n_shot_generative_college_chemistry',\n",
       "   'mmlu_flan_n_shot_generative_college_physics',\n",
       "   'mmlu_flan_n_shot_generative_college_computer_science',\n",
       "   'mmlu_flan_n_shot_generative_abstract_algebra',\n",
       "   'mmlu_flan_n_shot_generative_high_school_physics',\n",
       "   'mmlu_flan_n_shot_generative_computer_security',\n",
       "   'mmlu_flan_n_shot_generative_high_school_statistics',\n",
       "   'mmlu_flan_n_shot_generative_conceptual_physics',\n",
       "   'mmlu_flan_n_shot_generative_high_school_chemistry',\n",
       "   'mmlu_flan_n_shot_generative_anatomy',\n",
       "   'mmlu_flan_n_shot_generative_electrical_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_generative_prehistory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_prehistory.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_econometrics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_econometrics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_professional_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_professional_medicine.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_other': {'type': 'group',\n",
       "  'task': ['mmlu_flan_n_shot_generative_professional_medicine',\n",
       "   'mmlu_flan_n_shot_generative_medical_genetics',\n",
       "   'mmlu_flan_n_shot_generative_human_aging',\n",
       "   'mmlu_flan_n_shot_generative_marketing',\n",
       "   'mmlu_flan_n_shot_generative_miscellaneous',\n",
       "   'mmlu_flan_n_shot_generative_global_facts',\n",
       "   'mmlu_flan_n_shot_generative_virology',\n",
       "   'mmlu_flan_n_shot_generative_clinical_knowledge',\n",
       "   'mmlu_flan_n_shot_generative_nutrition',\n",
       "   'mmlu_flan_n_shot_generative_professional_accounting',\n",
       "   'mmlu_flan_n_shot_generative_college_medicine',\n",
       "   'mmlu_flan_n_shot_generative_management',\n",
       "   'mmlu_flan_n_shot_generative_business_ethics'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_n_shot_generative_high_school_government_and_politics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_government_and_politics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_medical_genetics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_medical_genetics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_human_aging': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_human_aging.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_formal_logic': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_formal_logic.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_biology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_marketing.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_computer_science.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_elementary_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_elementary_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_international_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_international_law.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_us_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_us_history.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_miscellaneous': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_miscellaneous.yaml'},\n",
       " 'mmlu_flan_n_shot_generative': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/_mmlu.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_global_facts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_global_facts.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_moral_disputes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_moral_disputes.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_virology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_virology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_professional_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_professional_psychology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_biology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_human_sexuality': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_human_sexuality.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_clinical_knowledge': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_clinical_knowledge.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_jurisprudence': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_jurisprudence.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_professional_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_professional_law.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_nutrition': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_nutrition.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_machine_learning': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_machine_learning.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_professional_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_professional_accounting.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_macroeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_macroeconomics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_sociology.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_us_foreign_policy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_us_foreign_policy.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_mathematics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_chemistry.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_security_studies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_security_studies.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_computer_science.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_world_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_world_history.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_college_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_college_medicine.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_abstract_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_abstract_algebra.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_management.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_philosophy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_philosophy.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_geography.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_moral_scenarios': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_moral_scenarios.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_business_ethics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_business_ethics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_computer_security': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_computer_security.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_logical_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_logical_fallacies.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_statistics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_statistics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_conceptual_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_conceptual_physics.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_high_school_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_high_school_chemistry.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_anatomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_anatomy.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_electrical_engineering.yaml'},\n",
       " 'mmlu_flan_n_shot_generative_world_religions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_n_shot/generative/mmlu_world_religions.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_public_relations': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_public_relations.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_social_sciences': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_zeroshot_public_relations',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_psychology',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_microeconomics',\n",
       "   'mmlu_flan_cot_zeroshot_econometrics',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_government_and_politics',\n",
       "   'mmlu_flan_cot_zeroshot_professional_psychology',\n",
       "   'mmlu_flan_cot_zeroshot_human_sexuality',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_macroeconomics',\n",
       "   'mmlu_flan_cot_zeroshot_sociology',\n",
       "   'mmlu_flan_cot_zeroshot_us_foreign_policy',\n",
       "   'mmlu_flan_cot_zeroshot_security_studies',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_geography'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_european_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_european_history.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_humanities': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_zeroshot_high_school_european_history',\n",
       "   'mmlu_flan_cot_zeroshot_prehistory',\n",
       "   'mmlu_flan_cot_zeroshot_formal_logic',\n",
       "   'mmlu_flan_cot_zeroshot_international_law',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_us_history',\n",
       "   'mmlu_flan_cot_zeroshot_moral_disputes',\n",
       "   'mmlu_flan_cot_zeroshot_jurisprudence',\n",
       "   'mmlu_flan_cot_zeroshot_professional_law',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_world_history',\n",
       "   'mmlu_flan_cot_zeroshot_philosophy',\n",
       "   'mmlu_flan_cot_zeroshot_moral_scenarios',\n",
       "   'mmlu_flan_cot_zeroshot_logical_fallacies',\n",
       "   'mmlu_flan_cot_zeroshot_world_religions'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_psychology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_microeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_microeconomics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_astronomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_astronomy.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_stem': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_zeroshot_astronomy',\n",
       "   'mmlu_flan_cot_zeroshot_college_biology',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_computer_science',\n",
       "   'mmlu_flan_cot_zeroshot_elementary_mathematics',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_biology',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_mathematics',\n",
       "   'mmlu_flan_cot_zeroshot_machine_learning',\n",
       "   'mmlu_flan_cot_zeroshot_college_mathematics',\n",
       "   'mmlu_flan_cot_zeroshot_college_chemistry',\n",
       "   'mmlu_flan_cot_zeroshot_college_physics',\n",
       "   'mmlu_flan_cot_zeroshot_college_computer_science',\n",
       "   'mmlu_flan_cot_zeroshot_abstract_algebra',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_physics',\n",
       "   'mmlu_flan_cot_zeroshot_computer_security',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_statistics',\n",
       "   'mmlu_flan_cot_zeroshot_conceptual_physics',\n",
       "   'mmlu_flan_cot_zeroshot_high_school_chemistry',\n",
       "   'mmlu_flan_cot_zeroshot_anatomy',\n",
       "   'mmlu_flan_cot_zeroshot_electrical_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_zeroshot_prehistory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_prehistory.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_econometrics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_econometrics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_professional_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_professional_medicine.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_other': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_zeroshot_professional_medicine',\n",
       "   'mmlu_flan_cot_zeroshot_medical_genetics',\n",
       "   'mmlu_flan_cot_zeroshot_human_aging',\n",
       "   'mmlu_flan_cot_zeroshot_marketing',\n",
       "   'mmlu_flan_cot_zeroshot_miscellaneous',\n",
       "   'mmlu_flan_cot_zeroshot_global_facts',\n",
       "   'mmlu_flan_cot_zeroshot_virology',\n",
       "   'mmlu_flan_cot_zeroshot_clinical_knowledge',\n",
       "   'mmlu_flan_cot_zeroshot_nutrition',\n",
       "   'mmlu_flan_cot_zeroshot_professional_accounting',\n",
       "   'mmlu_flan_cot_zeroshot_college_medicine',\n",
       "   'mmlu_flan_cot_zeroshot_management',\n",
       "   'mmlu_flan_cot_zeroshot_business_ethics'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_government_and_politics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_government_and_politics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_medical_genetics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_medical_genetics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_human_aging': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_human_aging.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_formal_logic': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_formal_logic.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_biology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_marketing.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_computer_science.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_elementary_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_elementary_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_international_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_international_law.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_us_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_us_history.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_miscellaneous': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_miscellaneous.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/_mmlu.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_global_facts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_global_facts.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_moral_disputes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_moral_disputes.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_virology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_virology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_professional_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_professional_psychology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_biology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_human_sexuality': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_human_sexuality.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_clinical_knowledge': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_clinical_knowledge.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_jurisprudence': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_jurisprudence.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_professional_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_professional_law.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_nutrition': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_nutrition.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_machine_learning': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_machine_learning.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_professional_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_professional_accounting.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_macroeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_macroeconomics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_sociology.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_us_foreign_policy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_us_foreign_policy.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_chemistry.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_security_studies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_security_studies.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_physics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_computer_science.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_world_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_world_history.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_college_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_college_medicine.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_abstract_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_abstract_algebra.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_management.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_philosophy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_philosophy.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_geography.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_moral_scenarios': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_moral_scenarios.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_business_ethics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_business_ethics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_physics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_computer_security': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_computer_security.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_logical_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_logical_fallacies.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_statistics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_statistics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_conceptual_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_conceptual_physics.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_high_school_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_high_school_chemistry.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_anatomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_anatomy.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_electrical_engineering.yaml'},\n",
       " 'mmlu_flan_cot_zeroshot_world_religions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_zeroshot/mmlu_world_religions.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_public_relations': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_public_relations.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_social_sciences': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_fewshot_public_relations',\n",
       "   'mmlu_flan_cot_fewshot_high_school_psychology',\n",
       "   'mmlu_flan_cot_fewshot_high_school_microeconomics',\n",
       "   'mmlu_flan_cot_fewshot_econometrics',\n",
       "   'mmlu_flan_cot_fewshot_high_school_government_and_politics',\n",
       "   'mmlu_flan_cot_fewshot_professional_psychology',\n",
       "   'mmlu_flan_cot_fewshot_human_sexuality',\n",
       "   'mmlu_flan_cot_fewshot_high_school_macroeconomics',\n",
       "   'mmlu_flan_cot_fewshot_sociology',\n",
       "   'mmlu_flan_cot_fewshot_us_foreign_policy',\n",
       "   'mmlu_flan_cot_fewshot_security_studies',\n",
       "   'mmlu_flan_cot_fewshot_high_school_geography'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_fewshot_high_school_european_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_european_history.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_humanities': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_fewshot_high_school_european_history',\n",
       "   'mmlu_flan_cot_fewshot_prehistory',\n",
       "   'mmlu_flan_cot_fewshot_formal_logic',\n",
       "   'mmlu_flan_cot_fewshot_international_law',\n",
       "   'mmlu_flan_cot_fewshot_high_school_us_history',\n",
       "   'mmlu_flan_cot_fewshot_moral_disputes',\n",
       "   'mmlu_flan_cot_fewshot_jurisprudence',\n",
       "   'mmlu_flan_cot_fewshot_professional_law',\n",
       "   'mmlu_flan_cot_fewshot_high_school_world_history',\n",
       "   'mmlu_flan_cot_fewshot_philosophy',\n",
       "   'mmlu_flan_cot_fewshot_moral_scenarios',\n",
       "   'mmlu_flan_cot_fewshot_logical_fallacies',\n",
       "   'mmlu_flan_cot_fewshot_world_religions'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_fewshot_high_school_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_psychology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_microeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_microeconomics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_astronomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_astronomy.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_stem': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_fewshot_astronomy',\n",
       "   'mmlu_flan_cot_fewshot_college_biology',\n",
       "   'mmlu_flan_cot_fewshot_high_school_computer_science',\n",
       "   'mmlu_flan_cot_fewshot_elementary_mathematics',\n",
       "   'mmlu_flan_cot_fewshot_high_school_biology',\n",
       "   'mmlu_flan_cot_fewshot_high_school_mathematics',\n",
       "   'mmlu_flan_cot_fewshot_machine_learning',\n",
       "   'mmlu_flan_cot_fewshot_college_mathematics',\n",
       "   'mmlu_flan_cot_fewshot_college_chemistry',\n",
       "   'mmlu_flan_cot_fewshot_college_physics',\n",
       "   'mmlu_flan_cot_fewshot_college_computer_science',\n",
       "   'mmlu_flan_cot_fewshot_abstract_algebra',\n",
       "   'mmlu_flan_cot_fewshot_high_school_physics',\n",
       "   'mmlu_flan_cot_fewshot_computer_security',\n",
       "   'mmlu_flan_cot_fewshot_high_school_statistics',\n",
       "   'mmlu_flan_cot_fewshot_conceptual_physics',\n",
       "   'mmlu_flan_cot_fewshot_high_school_chemistry',\n",
       "   'mmlu_flan_cot_fewshot_anatomy',\n",
       "   'mmlu_flan_cot_fewshot_electrical_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_fewshot_prehistory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_prehistory.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_econometrics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_econometrics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_professional_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_professional_medicine.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_other': {'type': 'group',\n",
       "  'task': ['mmlu_flan_cot_fewshot_professional_medicine',\n",
       "   'mmlu_flan_cot_fewshot_medical_genetics',\n",
       "   'mmlu_flan_cot_fewshot_human_aging',\n",
       "   'mmlu_flan_cot_fewshot_marketing',\n",
       "   'mmlu_flan_cot_fewshot_miscellaneous',\n",
       "   'mmlu_flan_cot_fewshot_global_facts',\n",
       "   'mmlu_flan_cot_fewshot_virology',\n",
       "   'mmlu_flan_cot_fewshot_clinical_knowledge',\n",
       "   'mmlu_flan_cot_fewshot_nutrition',\n",
       "   'mmlu_flan_cot_fewshot_professional_accounting',\n",
       "   'mmlu_flan_cot_fewshot_college_medicine',\n",
       "   'mmlu_flan_cot_fewshot_management',\n",
       "   'mmlu_flan_cot_fewshot_business_ethics'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_flan_cot_fewshot_high_school_government_and_politics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_government_and_politics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_medical_genetics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_medical_genetics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_human_aging': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_human_aging.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_formal_logic': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_formal_logic.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_biology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_marketing.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_computer_science.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_elementary_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_elementary_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_international_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_international_law.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_us_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_us_history.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_miscellaneous': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_miscellaneous.yaml'},\n",
       " 'mmlu_flan_cot_fewshot': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/_mmlu.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_global_facts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_global_facts.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_moral_disputes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_moral_disputes.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_virology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_virology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_professional_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_professional_psychology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_biology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_human_sexuality': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_human_sexuality.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_clinical_knowledge': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_clinical_knowledge.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_jurisprudence': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_jurisprudence.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_professional_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_professional_law.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_nutrition': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_nutrition.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_machine_learning': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_machine_learning.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_professional_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_professional_accounting.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_macroeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_macroeconomics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_sociology.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_us_foreign_policy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_us_foreign_policy.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_mathematics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_chemistry.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_security_studies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_security_studies.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_physics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_computer_science.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_world_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_world_history.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_college_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_college_medicine.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_abstract_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_abstract_algebra.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_management.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_philosophy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_philosophy.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_geography.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_moral_scenarios': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_moral_scenarios.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_business_ethics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_business_ethics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_physics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_computer_security': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_computer_security.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_logical_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_logical_fallacies.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_statistics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_statistics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_conceptual_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_conceptual_physics.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_high_school_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_high_school_chemistry.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_anatomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_anatomy.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_electrical_engineering.yaml'},\n",
       " 'mmlu_flan_cot_fewshot_world_religions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/flan_cot_fewshot/mmlu_world_religions.yaml'},\n",
       " 'mmlu_public_relations': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_public_relations.yaml'},\n",
       " 'mmlu_social_sciences': {'type': 'group',\n",
       "  'task': ['mmlu_public_relations',\n",
       "   'mmlu_high_school_psychology',\n",
       "   'mmlu_high_school_microeconomics',\n",
       "   'mmlu_econometrics',\n",
       "   'mmlu_high_school_government_and_politics',\n",
       "   'mmlu_professional_psychology',\n",
       "   'mmlu_human_sexuality',\n",
       "   'mmlu_high_school_macroeconomics',\n",
       "   'mmlu_sociology',\n",
       "   'mmlu_us_foreign_policy',\n",
       "   'mmlu_security_studies',\n",
       "   'mmlu_high_school_geography'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_high_school_european_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_european_history.yaml'},\n",
       " 'mmlu_humanities': {'type': 'group',\n",
       "  'task': ['mmlu_high_school_european_history',\n",
       "   'mmlu_prehistory',\n",
       "   'mmlu_formal_logic',\n",
       "   'mmlu_international_law',\n",
       "   'mmlu_high_school_us_history',\n",
       "   'mmlu_moral_disputes',\n",
       "   'mmlu_jurisprudence',\n",
       "   'mmlu_professional_law',\n",
       "   'mmlu_high_school_world_history',\n",
       "   'mmlu_philosophy',\n",
       "   'mmlu_moral_scenarios',\n",
       "   'mmlu_logical_fallacies',\n",
       "   'mmlu_world_religions'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_high_school_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_psychology.yaml'},\n",
       " 'mmlu_high_school_microeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_microeconomics.yaml'},\n",
       " 'mmlu_astronomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_astronomy.yaml'},\n",
       " 'mmlu_stem': {'type': 'group',\n",
       "  'task': ['mmlu_astronomy',\n",
       "   'mmlu_college_biology',\n",
       "   'mmlu_high_school_computer_science',\n",
       "   'mmlu_elementary_mathematics',\n",
       "   'mmlu_high_school_biology',\n",
       "   'mmlu_high_school_mathematics',\n",
       "   'mmlu_machine_learning',\n",
       "   'mmlu_college_mathematics',\n",
       "   'mmlu_college_chemistry',\n",
       "   'mmlu_college_physics',\n",
       "   'mmlu_college_computer_science',\n",
       "   'mmlu_abstract_algebra',\n",
       "   'mmlu_high_school_physics',\n",
       "   'mmlu_computer_security',\n",
       "   'mmlu_high_school_statistics',\n",
       "   'mmlu_conceptual_physics',\n",
       "   'mmlu_high_school_chemistry',\n",
       "   'mmlu_anatomy',\n",
       "   'mmlu_electrical_engineering'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_prehistory': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_prehistory.yaml'},\n",
       " 'mmlu_econometrics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_econometrics.yaml'},\n",
       " 'mmlu_professional_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_professional_medicine.yaml'},\n",
       " 'mmlu_other': {'type': 'group',\n",
       "  'task': ['mmlu_professional_medicine',\n",
       "   'mmlu_medical_genetics',\n",
       "   'mmlu_human_aging',\n",
       "   'mmlu_marketing',\n",
       "   'mmlu_miscellaneous',\n",
       "   'mmlu_global_facts',\n",
       "   'mmlu_virology',\n",
       "   'mmlu_clinical_knowledge',\n",
       "   'mmlu_nutrition',\n",
       "   'mmlu_professional_accounting',\n",
       "   'mmlu_college_medicine',\n",
       "   'mmlu_management',\n",
       "   'mmlu_business_ethics'],\n",
       "  'yaml_path': -1},\n",
       " 'mmlu_high_school_government_and_politics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_government_and_politics.yaml'},\n",
       " 'mmlu_medical_genetics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_medical_genetics.yaml'},\n",
       " 'mmlu_human_aging': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_human_aging.yaml'},\n",
       " 'mmlu_formal_logic': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_formal_logic.yaml'},\n",
       " 'mmlu_college_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_biology.yaml'},\n",
       " 'mmlu_marketing': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_marketing.yaml'},\n",
       " 'mmlu_high_school_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_computer_science.yaml'},\n",
       " 'mmlu_elementary_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_elementary_mathematics.yaml'},\n",
       " 'mmlu_international_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_international_law.yaml'},\n",
       " 'mmlu_high_school_us_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_us_history.yaml'},\n",
       " 'mmlu_miscellaneous': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_miscellaneous.yaml'},\n",
       " 'mmlu': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/_mmlu.yaml'},\n",
       " 'mmlu_global_facts': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_global_facts.yaml'},\n",
       " 'mmlu_moral_disputes': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_moral_disputes.yaml'},\n",
       " 'mmlu_virology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_virology.yaml'},\n",
       " 'mmlu_professional_psychology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_professional_psychology.yaml'},\n",
       " 'mmlu_high_school_biology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_biology.yaml'},\n",
       " 'mmlu_high_school_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_mathematics.yaml'},\n",
       " 'mmlu_human_sexuality': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_human_sexuality.yaml'},\n",
       " 'mmlu_clinical_knowledge': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_clinical_knowledge.yaml'},\n",
       " 'mmlu_jurisprudence': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_jurisprudence.yaml'},\n",
       " 'mmlu_professional_law': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_professional_law.yaml'},\n",
       " 'mmlu_nutrition': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_nutrition.yaml'},\n",
       " 'mmlu_machine_learning': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_machine_learning.yaml'},\n",
       " 'mmlu_professional_accounting': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_professional_accounting.yaml'},\n",
       " 'mmlu_high_school_macroeconomics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_macroeconomics.yaml'},\n",
       " 'mmlu_sociology': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_sociology.yaml'},\n",
       " 'mmlu_us_foreign_policy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_us_foreign_policy.yaml'},\n",
       " 'mmlu_college_mathematics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_mathematics.yaml'},\n",
       " 'mmlu_college_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_chemistry.yaml'},\n",
       " 'mmlu_security_studies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_security_studies.yaml'},\n",
       " 'mmlu_college_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_physics.yaml'},\n",
       " 'mmlu_college_computer_science': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_computer_science.yaml'},\n",
       " 'mmlu_high_school_world_history': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_world_history.yaml'},\n",
       " 'mmlu_college_medicine': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_college_medicine.yaml'},\n",
       " 'mmlu_abstract_algebra': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_abstract_algebra.yaml'},\n",
       " 'mmlu_management': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_management.yaml'},\n",
       " 'mmlu_philosophy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_philosophy.yaml'},\n",
       " 'mmlu_high_school_geography': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_geography.yaml'},\n",
       " 'mmlu_moral_scenarios': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_moral_scenarios.yaml'},\n",
       " 'mmlu_business_ethics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_business_ethics.yaml'},\n",
       " 'mmlu_high_school_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_physics.yaml'},\n",
       " 'mmlu_computer_security': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_computer_security.yaml'},\n",
       " 'mmlu_logical_fallacies': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_logical_fallacies.yaml'},\n",
       " 'mmlu_high_school_statistics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_statistics.yaml'},\n",
       " 'mmlu_conceptual_physics': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_conceptual_physics.yaml'},\n",
       " 'mmlu_high_school_chemistry': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_high_school_chemistry.yaml'},\n",
       " 'mmlu_anatomy': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_anatomy.yaml'},\n",
       " 'mmlu_electrical_engineering': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_electrical_engineering.yaml'},\n",
       " 'mmlu_world_religions': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mmlu/default/mmlu_world_religions.yaml'},\n",
       " 'ifeval': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/ifeval/ifeval.yaml'},\n",
       " 'xnli_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_en.yaml'},\n",
       " 'xnli': {'type': 'group',\n",
       "  'task': ['xnli_en',\n",
       "   'xnli_vi',\n",
       "   'xnli_hi',\n",
       "   'xnli_fr',\n",
       "   'xnli_tr',\n",
       "   'xnli_el',\n",
       "   'xnli_sw',\n",
       "   'xnli_ar',\n",
       "   'xnli_de',\n",
       "   'xnli_bg',\n",
       "   'xnli_es',\n",
       "   'xnli_ur',\n",
       "   'xnli_zh',\n",
       "   'xnli_th',\n",
       "   'xnli_ru'],\n",
       "  'yaml_path': -1},\n",
       " 'xnli_vi': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_vi.yaml'},\n",
       " 'xnli_hi': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_hi.yaml'},\n",
       " 'xnli_fr': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_fr.yaml'},\n",
       " 'xnli_tr': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_tr.yaml'},\n",
       " 'xnli_el': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_el.yaml'},\n",
       " 'xnli_sw': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_sw.yaml'},\n",
       " 'xnli_ar': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_ar.yaml'},\n",
       " 'xnli_de': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_de.yaml'},\n",
       " 'xnli_bg': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_bg.yaml'},\n",
       " 'xnli_es': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_es.yaml'},\n",
       " 'xnli_ur': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_ur.yaml'},\n",
       " 'xnli_zh': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_zh.yaml'},\n",
       " 'xnli_th': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_th.yaml'},\n",
       " 'xnli_ru': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/xnli/xnli_ru.yaml'},\n",
       " 'triviaqa': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/triviaqa/default.yaml'},\n",
       " 'medqa_4options': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/medqa/medqa.yaml'},\n",
       " 'scrolls': {'type': 'group',\n",
       "  'task': -1,\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/scrolls/scrolls.yaml'},\n",
       " 'kormedmcqa_pharm': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kormedmcqa/kormedmcqa_pharm.yaml'},\n",
       " 'kormedmcqa': {'type': 'group',\n",
       "  'task': ['kormedmcqa_pharm', 'kormedmcqa_nurse', 'kormedmcqa_doctor'],\n",
       "  'yaml_path': -1},\n",
       " 'kormedmcqa_nurse': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kormedmcqa/kormedmcqa_nurse.yaml'},\n",
       " 'kormedmcqa_doctor': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/kormedmcqa/kormedmcqa_doctor.yaml'},\n",
       " 'lambada_standard': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/lambada/lambada_standard.yaml'},\n",
       " 'lambada': {'type': 'group',\n",
       "  'task': ['lambada_standard', 'lambada_openai'],\n",
       "  'yaml_path': -1},\n",
       " 'lambada_openai': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/lambada/lambada_openai.yaml'},\n",
       " 'race': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/race/race.yaml'},\n",
       " 'wmt-ro-en-t5-prompt': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/wmt2016/ro_en-t5_prompt.yaml'},\n",
       " 'wmt-t5-prompt': {'type': 'group',\n",
       "  'task': ['wmt-ro-en-t5-prompt'],\n",
       "  'yaml_path': -1},\n",
       " 'mutual_plus': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mutual/multual_plus.yaml'},\n",
       " 'mutual': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/mutual/mutual.yaml'},\n",
       " 'headqa_en': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/headqa/headqa_en.yaml'},\n",
       " 'headqa': {'type': 'group',\n",
       "  'task': ['headqa_en', 'headqa_es'],\n",
       "  'yaml_path': -1},\n",
       " 'headqa_es': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/headqa/headqa_es.yaml'},\n",
       " 'nq_open': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/nq_open/nq_open.yaml'},\n",
       " 'storycloze_2016': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/storycloze/storycloze_2016.yaml'},\n",
       " 'storycloze': {'type': 'group',\n",
       "  'task': ['storycloze_2016', 'storycloze_2018'],\n",
       "  'yaml_path': -1},\n",
       " 'storycloze_2018': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/storycloze/storycloze_2018.yaml'},\n",
       " 'asdiv': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/asdiv/default.yaml'},\n",
       " 'bigbench_analytic_entailment_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/analytic_entailment.yaml'},\n",
       " 'bigbench_multiple_choice': {'type': 'group',\n",
       "  'task': ['bigbench_analytic_entailment_multiple_choice',\n",
       "   'bigbench_physics_questions_multiple_choice',\n",
       "   'bigbench_nonsense_words_grammar_multiple_choice',\n",
       "   'bigbench_modified_arithmetic_multiple_choice',\n",
       "   'bigbench_evaluating_information_essentiality_multiple_choice',\n",
       "   'bigbench_english_russian_proverbs_multiple_choice',\n",
       "   'bigbench_reasoning_about_colored_objects_multiple_choice',\n",
       "   'bigbench_implicit_relations_multiple_choice',\n",
       "   'bigbench_polish_sequence_labeling_multiple_choice',\n",
       "   'bigbench_word_sorting_multiple_choice',\n",
       "   'bigbench_chinese_remainder_theorem_multiple_choice',\n",
       "   'bigbench_sports_understanding_multiple_choice',\n",
       "   'bigbench_simple_arithmetic_json_subtasks_multiple_choice',\n",
       "   'bigbench_ruin_names_multiple_choice',\n",
       "   'bigbench_entailed_polarity_multiple_choice',\n",
       "   'bigbench_physical_intuition_multiple_choice',\n",
       "   'bigbench_hhh_alignment_multiple_choice',\n",
       "   'bigbench_semantic_parsing_spider_multiple_choice',\n",
       "   'bigbench_strategyqa_multiple_choice',\n",
       "   'bigbench_intent_recognition_multiple_choice',\n",
       "   'bigbench_bbq_lite_json_multiple_choice',\n",
       "   'bigbench_word_unscrambling_multiple_choice',\n",
       "   'bigbench_simple_arithmetic_json_multiple_choice_multiple_choice',\n",
       "   'bigbench_implicatures_multiple_choice',\n",
       "   'bigbench_sufficient_information_multiple_choice',\n",
       "   'bigbench_emoji_movie_multiple_choice',\n",
       "   'bigbench_tracking_shuffled_objects_multiple_choice',\n",
       "   'bigbench_unnatural_in_context_learning_multiple_choice',\n",
       "   'bigbench_temporal_sequences_multiple_choice',\n",
       "   'bigbench_kanji_ascii_multiple_choice',\n",
       "   'bigbench_disambiguation_qa_multiple_choice',\n",
       "   'bigbench_timedial_multiple_choice',\n",
       "   'bigbench_empirical_judgments_multiple_choice',\n",
       "   'bigbench_simple_ethical_questions_multiple_choice',\n",
       "   'bigbench_formal_fallacies_syllogisms_negation_multiple_choice',\n",
       "   'bigbench_arithmetic_multiple_choice',\n",
       "   'bigbench_unit_conversion_multiple_choice',\n",
       "   'bigbench_analogical_similarity_multiple_choice',\n",
       "   'bigbench_simple_text_editing_multiple_choice',\n",
       "   'bigbench_play_dialog_same_or_different_multiple_choice',\n",
       "   'bigbench_cause_and_effect_multiple_choice',\n",
       "   'bigbench_entailed_polarity_hindi_multiple_choice',\n",
       "   'bigbench_simple_arithmetic_multiple_targets_json_multiple_choice',\n",
       "   'bigbench_general_knowledge_multiple_choice',\n",
       "   'bigbench_simp_turing_concept_multiple_choice',\n",
       "   'bigbench_scientific_press_release_multiple_choice',\n",
       "   'bigbench_tense_multiple_choice',\n",
       "   'bigbench_operators_multiple_choice',\n",
       "   'bigbench_periodic_elements_multiple_choice',\n",
       "   'bigbench_international_phonetic_alphabet_transliterate_multiple_choice',\n",
       "   'bigbench_strange_stories_multiple_choice',\n",
       "   'bigbench_unit_interpretation_multiple_choice',\n",
       "   'bigbench_auto_debugging_multiple_choice',\n",
       "   'bigbench_question_selection_multiple_choice',\n",
       "   'bigbench_known_unknowns_multiple_choice',\n",
       "   'bigbench_matrixshapes_multiple_choice',\n",
       "   'bigbench_understanding_fables_multiple_choice',\n",
       "   'bigbench_dark_humor_detection_multiple_choice',\n",
       "   'bigbench_emojis_emotion_prediction_multiple_choice',\n",
       "   'bigbench_phrase_relatedness_multiple_choice',\n",
       "   'bigbench_undo_permutation_multiple_choice',\n",
       "   'bigbench_code_line_description_multiple_choice',\n",
       "   'bigbench_date_understanding_multiple_choice',\n",
       "   'bigbench_simple_arithmetic_json_multiple_choice',\n",
       "   'bigbench_persian_idioms_multiple_choice',\n",
       "   'bigbench_checkmate_in_one_multiple_choice',\n",
       "   'bigbench_misconceptions_multiple_choice',\n",
       "   'bigbench_language_games_multiple_choice',\n",
       "   'bigbench_conlang_translation_multiple_choice',\n",
       "   'bigbench_novel_concepts_multiple_choice',\n",
       "   'bigbench_english_proverbs_multiple_choice',\n",
       "   'bigbench_riddle_sense_multiple_choice',\n",
       "   'bigbench_winowhy_multiple_choice',\n",
       "   'bigbench_semantic_parsing_in_context_sparc_multiple_choice',\n",
       "   'bigbench_physics_multiple_choice',\n",
       "   'bigbench_fact_checker_multiple_choice',\n",
       "   'bigbench_discourse_marker_prediction_multiple_choice',\n",
       "   'bigbench_identify_odd_metaphor_multiple_choice',\n",
       "   'bigbench_snarks_multiple_choice',\n",
       "   'bigbench_swedish_to_german_proverbs_multiple_choice',\n",
       "   'bigbench_hindi_question_answering_multiple_choice',\n",
       "   'bigbench_symbol_interpretation_multiple_choice',\n",
       "   'bigbench_codenames_multiple_choice',\n",
       "   'bigbench_object_counting_multiple_choice',\n",
       "   'bigbench_intersect_geometry_multiple_choice',\n",
       "   'bigbench_causal_judgement_multiple_choice',\n",
       "   'bigbench_natural_instructions_multiple_choice',\n",
       "   'bigbench_minute_mysteries_qa_multiple_choice',\n",
       "   'bigbench_navigate_multiple_choice',\n",
       "   'bigbench_gem_multiple_choice',\n",
       "   'bigbench_fantasy_reasoning_multiple_choice',\n",
       "   'bigbench_misconceptions_russian_multiple_choice',\n",
       "   'bigbench_abstract_narrative_understanding_multiple_choice',\n",
       "   'bigbench_mnist_ascii_multiple_choice',\n",
       "   'bigbench_which_wiki_edit_multiple_choice',\n",
       "   'bigbench_causal_judgment_multiple_choice',\n",
       "   'bigbench_dyck_languages_multiple_choice',\n",
       "   'bigbench_cryptonite_multiple_choice',\n",
       "   'bigbench_hyperbaton_multiple_choice',\n",
       "   'bigbench_moral_permissibility_multiple_choice',\n",
       "   'bigbench_cryobiology_spanish_multiple_choice',\n",
       "   'bigbench_qa_wikidata_multiple_choice',\n",
       "   'bigbench_odd_one_out_multiple_choice',\n",
       "   'bigbench_repeat_copy_logic_multiple_choice',\n",
       "   'bigbench_presuppositions_as_nli_multiple_choice',\n",
       "   'bigbench_goal_step_wikihow_multiple_choice',\n",
       "   'bigbench_suicide_risk_multiple_choice',\n",
       "   'bigbench_parsinlu_reading_comprehension_multiple_choice',\n",
       "   'bigbench_logical_sequence_multiple_choice',\n",
       "   'bigbench_rephrase_multiple_choice',\n",
       "   'bigbench_irony_identification_multiple_choice',\n",
       "   'bigbench_color_multiple_choice',\n",
       "   'bigbench_vitaminc_fact_verification_multiple_choice',\n",
       "   'bigbench_epistemic_reasoning_multiple_choice',\n",
       "   'bigbench_swahili_english_proverbs_multiple_choice',\n",
       "   'bigbench_movie_recommendation_multiple_choice',\n",
       "   'bigbench_cs_algorithms_multiple_choice',\n",
       "   'bigbench_penguins_in_a_table_multiple_choice',\n",
       "   'bigbench_multiemo_multiple_choice',\n",
       "   'bigbench_cifar10_classification_multiple_choice',\n",
       "   'bigbench_common_morpheme_multiple_choice',\n",
       "   'bigbench_parsinlu_qa_multiple_choice',\n",
       "   'bigbench_sentence_ambiguity_multiple_choice',\n",
       "   'bigbench_international_phonetic_alphabet_nli_multiple_choice',\n",
       "   'bigbench_gender_inclusive_sentences_german_multiple_choice',\n",
       "   'bigbench_list_functions_multiple_choice',\n",
       "   'bigbench_logical_args_multiple_choice',\n",
       "   'bigbench_few_shot_nlg_multiple_choice',\n",
       "   'bigbench_geometric_shapes_multiple_choice',\n",
       "   'bigbench_conceptual_combinations_multiple_choice',\n",
       "   'bigbench_gre_reading_comprehension_multiple_choice',\n",
       "   'bigbench_elementary_math_qa_multiple_choice',\n",
       "   'bigbench_metaphor_boolean_multiple_choice',\n",
       "   'bigbench_identify_math_theorems_multiple_choice',\n",
       "   'bigbench_mult_data_wrangling_multiple_choice',\n",
       "   'bigbench_logical_deduction_multiple_choice',\n",
       "   'bigbench_topical_chat_multiple_choice',\n",
       "   'bigbench_ascii_word_recognition_multiple_choice',\n",
       "   'bigbench_social_support_multiple_choice',\n",
       "   'bigbench_salient_translation_error_detection_multiple_choice',\n",
       "   'bigbench_disfl_qa_multiple_choice',\n",
       "   'bigbench_key_value_maps_multiple_choice',\n",
       "   'bigbench_linguistic_mappings_multiple_choice',\n",
       "   'bigbench_crass_ai_multiple_choice',\n",
       "   'bigbench_human_organs_senses_multiple_choice',\n",
       "   'bigbench_figure_of_speech_detection_multiple_choice',\n",
       "   'bigbench_authorship_verification_multiple_choice',\n",
       "   'bigbench_mathematical_induction_multiple_choice',\n",
       "   'bigbench_crash_blossom_multiple_choice',\n",
       "   'bigbench_chess_state_tracking_multiple_choice',\n",
       "   'bigbench_hinglish_toxicity_multiple_choice',\n",
       "   'bigbench_real_or_fake_text_multiple_choice',\n",
       "   'bigbench_metaphor_understanding_multiple_choice',\n",
       "   'bigbench_social_iqa_multiple_choice',\n",
       "   'bigbench_kannada_multiple_choice',\n",
       "   'bigbench_what_is_the_tao_multiple_choice',\n",
       "   'bigbench_bridging_anaphora_resolution_barqa_multiple_choice',\n",
       "   'bigbench_auto_categorization_multiple_choice',\n",
       "   'bigbench_logical_fallacy_detection_multiple_choice',\n",
       "   'bigbench_hindu_knowledge_multiple_choice',\n",
       "   'bigbench_language_identification_multiple_choice',\n",
       "   'bigbench_paragraph_segmentation_multiple_choice',\n",
       "   'bigbench_movie_dialog_same_or_different_multiple_choice',\n",
       "   'bigbench_logic_grid_puzzle_multiple_choice',\n",
       "   'bigbench_contextual_parametric_knowledge_conflicts_multiple_choice',\n",
       "   'bigbench_similarities_abstraction_multiple_choice',\n",
       "   'bigbench_linguistics_puzzles_multiple_choice',\n",
       "   'bigbench_anachronisms_multiple_choice'],\n",
       "  'yaml_path': -1},\n",
       " 'bigbench_physics_questions_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/physics_questions.yaml'},\n",
       " 'bigbench_nonsense_words_grammar_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/nonsense_words_grammar.yaml'},\n",
       " 'bigbench_modified_arithmetic_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/modified_arithmetic.yaml'},\n",
       " 'bigbench_evaluating_information_essentiality_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/evaluating_information_essentiality.yaml'},\n",
       " 'bigbench_english_russian_proverbs_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/english_russian_proverbs.yaml'},\n",
       " 'bigbench_reasoning_about_colored_objects_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/reasoning_about_colored_objects.yaml'},\n",
       " 'bigbench_implicit_relations_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/implicit_relations.yaml'},\n",
       " 'bigbench_polish_sequence_labeling_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/polish_sequence_labeling.yaml'},\n",
       " 'bigbench_word_sorting_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/word_sorting.yaml'},\n",
       " 'bigbench_chinese_remainder_theorem_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/chinese_remainder_theorem.yaml'},\n",
       " 'bigbench_sports_understanding_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/sports_understanding.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_subtasks_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_arithmetic_json_subtasks.yaml'},\n",
       " 'bigbench_ruin_names_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/ruin_names.yaml'},\n",
       " 'bigbench_entailed_polarity_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/entailed_polarity.yaml'},\n",
       " 'bigbench_physical_intuition_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/physical_intuition.yaml'},\n",
       " 'bigbench_hhh_alignment_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/hhh_alignment.yaml'},\n",
       " 'bigbench_semantic_parsing_spider_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/semantic_parsing_spider.yaml'},\n",
       " 'bigbench_strategyqa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/strategyqa.yaml'},\n",
       " 'bigbench_intent_recognition_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/intent_recognition.yaml'},\n",
       " 'bigbench_bbq_lite_json_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/bbq_lite_json.yaml'},\n",
       " 'bigbench_word_unscrambling_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/word_unscrambling.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_multiple_choice_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_arithmetic_json_multiple_choice.yaml'},\n",
       " 'bigbench_implicatures_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/implicatures.yaml'},\n",
       " 'bigbench_sufficient_information_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/sufficient_information.yaml'},\n",
       " 'bigbench_emoji_movie_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/emoji_movie.yaml'},\n",
       " 'bigbench_tracking_shuffled_objects_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/tracking_shuffled_objects.yaml'},\n",
       " 'bigbench_unnatural_in_context_learning_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/unnatural_in_context_learning.yaml'},\n",
       " 'bigbench_temporal_sequences_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/temporal_sequences.yaml'},\n",
       " 'bigbench_kanji_ascii_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/kanji_ascii.yaml'},\n",
       " 'bigbench_disambiguation_qa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/disambiguation_qa.yaml'},\n",
       " 'bigbench_timedial_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/timedial.yaml'},\n",
       " 'bigbench_empirical_judgments_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/empirical_judgments.yaml'},\n",
       " 'bigbench_simple_ethical_questions_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_ethical_questions.yaml'},\n",
       " 'bigbench_formal_fallacies_syllogisms_negation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/formal_fallacies_syllogisms_negation.yaml'},\n",
       " 'bigbench_arithmetic_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/arithmetic.yaml'},\n",
       " 'bigbench_unit_conversion_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/unit_conversion.yaml'},\n",
       " 'bigbench_analogical_similarity_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/analogical_similarity.yaml'},\n",
       " 'bigbench_simple_text_editing_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_text_editing.yaml'},\n",
       " 'bigbench_play_dialog_same_or_different_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/play_dialog_same_or_different.yaml'},\n",
       " 'bigbench_cause_and_effect_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/cause_and_effect.yaml'},\n",
       " 'bigbench_entailed_polarity_hindi_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/entailed_polarity_hindi.yaml'},\n",
       " 'bigbench_simple_arithmetic_multiple_targets_json_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_arithmetic_multiple_targets_json.yaml'},\n",
       " 'bigbench_general_knowledge_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/general_knowledge.yaml'},\n",
       " 'bigbench_simp_turing_concept_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simp_turing_concept.yaml'},\n",
       " 'bigbench_scientific_press_release_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/scientific_press_release.yaml'},\n",
       " 'bigbench_tense_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/tense.yaml'},\n",
       " 'bigbench_operators_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/operators.yaml'},\n",
       " 'bigbench_periodic_elements_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/periodic_elements.yaml'},\n",
       " 'bigbench_international_phonetic_alphabet_transliterate_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/international_phonetic_alphabet_transliterate.yaml'},\n",
       " 'bigbench_strange_stories_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/strange_stories.yaml'},\n",
       " 'bigbench_unit_interpretation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/unit_interpretation.yaml'},\n",
       " 'bigbench_auto_debugging_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/auto_debugging.yaml'},\n",
       " 'bigbench_question_selection_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/question_selection.yaml'},\n",
       " 'bigbench_known_unknowns_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/known_unknowns.yaml'},\n",
       " 'bigbench_matrixshapes_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/matrixshapes.yaml'},\n",
       " 'bigbench_understanding_fables_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/understanding_fables.yaml'},\n",
       " 'bigbench_dark_humor_detection_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/dark_humor_detection.yaml'},\n",
       " 'bigbench_emojis_emotion_prediction_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/emojis_emotion_prediction.yaml'},\n",
       " 'bigbench_phrase_relatedness_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/phrase_relatedness.yaml'},\n",
       " 'bigbench_undo_permutation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/undo_permutation.yaml'},\n",
       " 'bigbench_code_line_description_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/code_line_description.yaml'},\n",
       " 'bigbench_date_understanding_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/date_understanding.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/simple_arithmetic_json.yaml'},\n",
       " 'bigbench_persian_idioms_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/persian_idioms.yaml'},\n",
       " 'bigbench_checkmate_in_one_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/checkmate_in_one.yaml'},\n",
       " 'bigbench_misconceptions_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/misconceptions.yaml'},\n",
       " 'bigbench_language_games_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/language_games.yaml'},\n",
       " 'bigbench_conlang_translation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/conlang_translation.yaml'},\n",
       " 'bigbench_novel_concepts_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/novel_concepts.yaml'},\n",
       " 'bigbench_english_proverbs_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/english_proverbs.yaml'},\n",
       " 'bigbench_riddle_sense_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/riddle_sense.yaml'},\n",
       " 'bigbench_winowhy_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/winowhy.yaml'},\n",
       " 'bigbench_semantic_parsing_in_context_sparc_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/semantic_parsing_in_context_sparc.yaml'},\n",
       " 'bigbench_physics_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/physics.yaml'},\n",
       " 'bigbench_fact_checker_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/fact_checker.yaml'},\n",
       " 'bigbench_discourse_marker_prediction_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/discourse_marker_prediction.yaml'},\n",
       " 'bigbench_identify_odd_metaphor_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/identify_odd_metaphor.yaml'},\n",
       " 'bigbench_snarks_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/snarks.yaml'},\n",
       " 'bigbench_swedish_to_german_proverbs_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/swedish_to_german_proverbs.yaml'},\n",
       " 'bigbench_hindi_question_answering_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/hindi_question_answering.yaml'},\n",
       " 'bigbench_symbol_interpretation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/symbol_interpretation.yaml'},\n",
       " 'bigbench_codenames_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/codenames.yaml'},\n",
       " 'bigbench_object_counting_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/object_counting.yaml'},\n",
       " 'bigbench_intersect_geometry_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/intersect_geometry.yaml'},\n",
       " 'bigbench_causal_judgement_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/causal_judgement.yaml'},\n",
       " 'bigbench_natural_instructions_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/natural_instructions.yaml'},\n",
       " 'bigbench_minute_mysteries_qa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/minute_mysteries_qa.yaml'},\n",
       " 'bigbench_navigate_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/navigate.yaml'},\n",
       " 'bigbench_gem_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/gem.yaml'},\n",
       " 'bigbench_fantasy_reasoning_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/fantasy_reasoning.yaml'},\n",
       " 'bigbench_misconceptions_russian_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/misconceptions_russian.yaml'},\n",
       " 'bigbench_abstract_narrative_understanding_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/abstract_narrative_understanding.yaml'},\n",
       " 'bigbench_mnist_ascii_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/mnist_ascii.yaml'},\n",
       " 'bigbench_which_wiki_edit_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/which_wiki_edit.yaml'},\n",
       " 'bigbench_causal_judgment_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/causal_judgment.yaml'},\n",
       " 'bigbench_dyck_languages_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/dyck_languages.yaml'},\n",
       " 'bigbench_cryptonite_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/cryptonite.yaml'},\n",
       " 'bigbench_hyperbaton_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/hyperbaton.yaml'},\n",
       " 'bigbench_moral_permissibility_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/moral_permissibility.yaml'},\n",
       " 'bigbench_cryobiology_spanish_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/cryobiology_spanish.yaml'},\n",
       " 'bigbench_qa_wikidata_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/qa_wikidata.yaml'},\n",
       " 'bigbench_odd_one_out_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/odd_one_out.yaml'},\n",
       " 'bigbench_repeat_copy_logic_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/repeat_copy_logic.yaml'},\n",
       " 'bigbench_presuppositions_as_nli_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/presuppositions_as_nli.yaml'},\n",
       " 'bigbench_goal_step_wikihow_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/goal_step_wikihow.yaml'},\n",
       " 'bigbench_suicide_risk_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/suicide_risk.yaml'},\n",
       " 'bigbench_parsinlu_reading_comprehension_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/parsinlu_reading_comprehension.yaml'},\n",
       " 'bigbench_logical_sequence_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/logical_sequence.yaml'},\n",
       " 'bigbench_rephrase_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/rephrase.yaml'},\n",
       " 'bigbench_irony_identification_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/irony_identification.yaml'},\n",
       " 'bigbench_color_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/color.yaml'},\n",
       " 'bigbench_vitaminc_fact_verification_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/vitaminc_fact_verification.yaml'},\n",
       " 'bigbench_epistemic_reasoning_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/epistemic_reasoning.yaml'},\n",
       " 'bigbench_swahili_english_proverbs_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/swahili_english_proverbs.yaml'},\n",
       " 'bigbench_movie_recommendation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/movie_recommendation.yaml'},\n",
       " 'bigbench_cs_algorithms_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/cs_algorithms.yaml'},\n",
       " 'bigbench_penguins_in_a_table_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/penguins_in_a_table.yaml'},\n",
       " 'bigbench_multiemo_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/multiemo.yaml'},\n",
       " 'bigbench_cifar10_classification_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/cifar10_classification.yaml'},\n",
       " 'bigbench_common_morpheme_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/common_morpheme.yaml'},\n",
       " 'bigbench_parsinlu_qa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/parsinlu_qa.yaml'},\n",
       " 'bigbench_sentence_ambiguity_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/sentence_ambiguity.yaml'},\n",
       " 'bigbench_international_phonetic_alphabet_nli_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/international_phonetic_alphabet_nli.yaml'},\n",
       " 'bigbench_gender_inclusive_sentences_german_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/gender_inclusive_sentences_german.yaml'},\n",
       " 'bigbench_list_functions_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/list_functions.yaml'},\n",
       " 'bigbench_logical_args_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/logical_args.yaml'},\n",
       " 'bigbench_few_shot_nlg_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/few_shot_nlg.yaml'},\n",
       " 'bigbench_geometric_shapes_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/geometric_shapes.yaml'},\n",
       " 'bigbench_conceptual_combinations_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/conceptual_combinations.yaml'},\n",
       " 'bigbench_gre_reading_comprehension_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/gre_reading_comprehension.yaml'},\n",
       " 'bigbench_elementary_math_qa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/elementary_math_qa.yaml'},\n",
       " 'bigbench_metaphor_boolean_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/metaphor_boolean.yaml'},\n",
       " 'bigbench_identify_math_theorems_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/identify_math_theorems.yaml'},\n",
       " 'bigbench_mult_data_wrangling_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/mult_data_wrangling.yaml'},\n",
       " 'bigbench_logical_deduction_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/logical_deduction.yaml'},\n",
       " 'bigbench_topical_chat_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/topical_chat.yaml'},\n",
       " 'bigbench_ascii_word_recognition_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/ascii_word_recognition.yaml'},\n",
       " 'bigbench_social_support_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/social_support.yaml'},\n",
       " 'bigbench_salient_translation_error_detection_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/salient_translation_error_detection.yaml'},\n",
       " 'bigbench_disfl_qa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/disfl_qa.yaml'},\n",
       " 'bigbench_key_value_maps_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/key_value_maps.yaml'},\n",
       " 'bigbench_linguistic_mappings_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/linguistic_mappings.yaml'},\n",
       " 'bigbench_crass_ai_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/crass_ai.yaml'},\n",
       " 'bigbench_human_organs_senses_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/human_organs_senses.yaml'},\n",
       " 'bigbench_figure_of_speech_detection_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/figure_of_speech_detection.yaml'},\n",
       " 'bigbench_authorship_verification_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/authorship_verification.yaml'},\n",
       " 'bigbench_mathematical_induction_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/mathematical_induction.yaml'},\n",
       " 'bigbench_crash_blossom_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/crash_blossom.yaml'},\n",
       " 'bigbench_chess_state_tracking_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/chess_state_tracking.yaml'},\n",
       " 'bigbench_hinglish_toxicity_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/hinglish_toxicity.yaml'},\n",
       " 'bigbench_real_or_fake_text_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/real_or_fake_text.yaml'},\n",
       " 'bigbench_metaphor_understanding_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/metaphor_understanding.yaml'},\n",
       " 'bigbench_social_iqa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/social_iqa.yaml'},\n",
       " 'bigbench_kannada_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/kannada.yaml'},\n",
       " 'bigbench_what_is_the_tao_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/what_is_the_tao.yaml'},\n",
       " 'bigbench_bridging_anaphora_resolution_barqa_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/bridging_anaphora_resolution_barqa.yaml'},\n",
       " 'bigbench_auto_categorization_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/auto_categorization.yaml'},\n",
       " 'bigbench_logical_fallacy_detection_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/logical_fallacy_detection.yaml'},\n",
       " 'bigbench_hindu_knowledge_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/hindu_knowledge.yaml'},\n",
       " 'bigbench_language_identification_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/language_identification.yaml'},\n",
       " 'bigbench_paragraph_segmentation_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/paragraph_segmentation.yaml'},\n",
       " 'bigbench_movie_dialog_same_or_different_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/movie_dialog_same_or_different.yaml'},\n",
       " 'bigbench_logic_grid_puzzle_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/logic_grid_puzzle.yaml'},\n",
       " 'bigbench_contextual_parametric_knowledge_conflicts_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/contextual_parametric_knowledge_conflicts.yaml'},\n",
       " 'bigbench_similarities_abstraction_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/similarities_abstraction.yaml'},\n",
       " 'bigbench_linguistics_puzzles_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/linguistics_puzzles.yaml'},\n",
       " 'bigbench_anachronisms_multiple_choice': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/multiple_choice/anachronisms.yaml'},\n",
       " 'bigbench_analytic_entailment_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/analytic_entailment.yaml'},\n",
       " 'bigbench_generate_until': {'type': 'group',\n",
       "  'task': ['bigbench_analytic_entailment_generate_until',\n",
       "   'bigbench_physics_questions_generate_until',\n",
       "   'bigbench_nonsense_words_grammar_generate_until',\n",
       "   'bigbench_modified_arithmetic_generate_until',\n",
       "   'bigbench_evaluating_information_essentiality_generate_until',\n",
       "   'bigbench_english_russian_proverbs_generate_until',\n",
       "   'bigbench_reasoning_about_colored_objects_generate_until',\n",
       "   'bigbench_implicit_relations_generate_until',\n",
       "   'bigbench_polish_sequence_labeling_generate_until',\n",
       "   'bigbench_word_sorting_generate_until',\n",
       "   'bigbench_chinese_remainder_theorem_generate_until',\n",
       "   'bigbench_sports_understanding_generate_until',\n",
       "   'bigbench_simple_arithmetic_json_subtasks_generate_until',\n",
       "   'bigbench_ruin_names_generate_until',\n",
       "   'bigbench_entailed_polarity_generate_until',\n",
       "   'bigbench_physical_intuition_generate_until',\n",
       "   'bigbench_hhh_alignment_generate_until',\n",
       "   'bigbench_semantic_parsing_spider_generate_until',\n",
       "   'bigbench_strategyqa_generate_until',\n",
       "   'bigbench_intent_recognition_generate_until',\n",
       "   'bigbench_bbq_lite_json_generate_until',\n",
       "   'bigbench_word_unscrambling_generate_until',\n",
       "   'bigbench_simple_arithmetic_json_multiple_choice_generate_until',\n",
       "   'bigbench_implicatures_generate_until',\n",
       "   'bigbench_sufficient_information_generate_until',\n",
       "   'bigbench_emoji_movie_generate_until',\n",
       "   'bigbench_tracking_shuffled_objects_generate_until',\n",
       "   'bigbench_unnatural_in_context_learning_generate_until',\n",
       "   'bigbench_temporal_sequences_generate_until',\n",
       "   'bigbench_kanji_ascii_generate_until',\n",
       "   'bigbench_disambiguation_qa_generate_until',\n",
       "   'bigbench_timedial_generate_until',\n",
       "   'bigbench_empirical_judgments_generate_until',\n",
       "   'bigbench_simple_ethical_questions_generate_until',\n",
       "   'bigbench_formal_fallacies_syllogisms_negation_generate_until',\n",
       "   'bigbench_arithmetic_generate_until',\n",
       "   'bigbench_unit_conversion_generate_until',\n",
       "   'bigbench_analogical_similarity_generate_until',\n",
       "   'bigbench_simple_text_editing_generate_until',\n",
       "   'bigbench_play_dialog_same_or_different_generate_until',\n",
       "   'bigbench_cause_and_effect_generate_until',\n",
       "   'bigbench_entailed_polarity_hindi_generate_until',\n",
       "   'bigbench_simple_arithmetic_multiple_targets_json_generate_until',\n",
       "   'bigbench_general_knowledge_generate_until',\n",
       "   'bigbench_simp_turing_concept_generate_until',\n",
       "   'bigbench_scientific_press_release_generate_until',\n",
       "   'bigbench_tense_generate_until',\n",
       "   'bigbench_operators_generate_until',\n",
       "   'bigbench_periodic_elements_generate_until',\n",
       "   'bigbench_international_phonetic_alphabet_transliterate_generate_until',\n",
       "   'bigbench_strange_stories_generate_until',\n",
       "   'bigbench_unit_interpretation_generate_until',\n",
       "   'bigbench_auto_debugging_generate_until',\n",
       "   'bigbench_question_selection_generate_until',\n",
       "   'bigbench_known_unknowns_generate_until',\n",
       "   'bigbench_matrixshapes_generate_until',\n",
       "   'bigbench_understanding_fables_generate_until',\n",
       "   'bigbench_dark_humor_detection_generate_until',\n",
       "   'bigbench_emojis_emotion_prediction_generate_until',\n",
       "   'bigbench_phrase_relatedness_generate_until',\n",
       "   'bigbench_undo_permutation_generate_until',\n",
       "   'bigbench_code_line_description_generate_until',\n",
       "   'bigbench_date_understanding_generate_until',\n",
       "   'bigbench_simple_arithmetic_json_generate_until',\n",
       "   'bigbench_persian_idioms_generate_until',\n",
       "   'bigbench_checkmate_in_one_generate_until',\n",
       "   'bigbench_misconceptions_generate_until',\n",
       "   'bigbench_language_games_generate_until',\n",
       "   'bigbench_conlang_translation_generate_until',\n",
       "   'bigbench_novel_concepts_generate_until',\n",
       "   'bigbench_english_proverbs_generate_until',\n",
       "   'bigbench_riddle_sense_generate_until',\n",
       "   'bigbench_winowhy_generate_until',\n",
       "   'bigbench_semantic_parsing_in_context_sparc_generate_until',\n",
       "   'bigbench_physics_generate_until',\n",
       "   'bigbench_fact_checker_generate_until',\n",
       "   'bigbench_discourse_marker_prediction_generate_until',\n",
       "   'bigbench_identify_odd_metaphor_generate_until',\n",
       "   'bigbench_snarks_generate_until',\n",
       "   'bigbench_swedish_to_german_proverbs_generate_until',\n",
       "   'bigbench_hindi_question_answering_generate_until',\n",
       "   'bigbench_symbol_interpretation_generate_until',\n",
       "   'bigbench_codenames_generate_until',\n",
       "   'bigbench_object_counting_generate_until',\n",
       "   'bigbench_intersect_geometry_generate_until',\n",
       "   'bigbench_natural_instructions_generate_until',\n",
       "   'bigbench_minute_mysteries_qa_generate_until',\n",
       "   'bigbench_navigate_generate_until',\n",
       "   'bigbench_gem_generate_until',\n",
       "   'bigbench_fantasy_reasoning_generate_until',\n",
       "   'bigbench_misconceptions_russian_generate_until',\n",
       "   'bigbench_abstract_narrative_understanding_generate_until',\n",
       "   'bigbench_mnist_ascii_generate_until',\n",
       "   'bigbench_which_wiki_edit_generate_until',\n",
       "   'bigbench_causal_judgment_generate_until',\n",
       "   'bigbench_dyck_languages_generate_until',\n",
       "   'bigbench_cryptonite_generate_until',\n",
       "   'bigbench_hyperbaton_generate_until',\n",
       "   'bigbench_moral_permissibility_generate_until',\n",
       "   'bigbench_cryobiology_spanish_generate_until',\n",
       "   'bigbench_qa_wikidata_generate_until',\n",
       "   'bigbench_odd_one_out_generate_until',\n",
       "   'bigbench_repeat_copy_logic_generate_until',\n",
       "   'bigbench_presuppositions_as_nli_generate_until',\n",
       "   'bigbench_goal_step_wikihow_generate_until',\n",
       "   'bigbench_suicide_risk_generate_until',\n",
       "   'bigbench_parsinlu_reading_comprehension_generate_until',\n",
       "   'bigbench_logical_sequence_generate_until',\n",
       "   'bigbench_rephrase_generate_until',\n",
       "   'bigbench_irony_identification_generate_until',\n",
       "   'bigbench_color_generate_until',\n",
       "   'bigbench_vitaminc_fact_verification_generate_until',\n",
       "   'bigbench_epistemic_reasoning_generate_until',\n",
       "   'bigbench_swahili_english_proverbs_generate_until',\n",
       "   'bigbench_movie_recommendation_generate_until',\n",
       "   'bigbench_cs_algorithms_generate_until',\n",
       "   'bigbench_penguins_in_a_table_generate_until',\n",
       "   'bigbench_multiemo_generate_until',\n",
       "   'bigbench_cifar10_classification_generate_until',\n",
       "   'bigbench_common_morpheme_generate_until',\n",
       "   'bigbench_parsinlu_qa_generate_until',\n",
       "   'bigbench_sentence_ambiguity_generate_until',\n",
       "   'bigbench_international_phonetic_alphabet_nli_generate_until',\n",
       "   'bigbench_gender_inclusive_sentences_german_generate_until',\n",
       "   'bigbench_list_functions_generate_until',\n",
       "   'bigbench_logical_args_generate_until',\n",
       "   'bigbench_few_shot_nlg_generate_until',\n",
       "   'bigbench_geometric_shapes_generate_until',\n",
       "   'bigbench_conceptual_combinations_generate_until',\n",
       "   'bigbench_gre_reading_comprehension_generate_until',\n",
       "   'bigbench_elementary_math_qa_generate_until',\n",
       "   'bigbench_metaphor_boolean_generate_until',\n",
       "   'bigbench_identify_math_theorems_generate_until',\n",
       "   'bigbench_mult_data_wrangling_generate_until',\n",
       "   'bigbench_logical_deduction_generate_until',\n",
       "   'bigbench_topical_chat_generate_until',\n",
       "   'bigbench_ascii_word_recognition_generate_until',\n",
       "   'bigbench_social_support_generate_until',\n",
       "   'bigbench_salient_translation_error_detection_generate_until',\n",
       "   'bigbench_disfl_qa_generate_until',\n",
       "   'bigbench_key_value_maps_generate_until',\n",
       "   'bigbench_linguistic_mappings_generate_until',\n",
       "   'bigbench_crass_ai_generate_until',\n",
       "   'bigbench_human_organs_senses_generate_until',\n",
       "   'bigbench_figure_of_speech_detection_generate_until',\n",
       "   'bigbench_authorship_verification_generate_until',\n",
       "   'bigbench_mathematical_induction_generate_until',\n",
       "   'bigbench_crash_blossom_generate_until',\n",
       "   'bigbench_chess_state_tracking_generate_until',\n",
       "   'bigbench_hinglish_toxicity_generate_until',\n",
       "   'bigbench_real_or_fake_text_generate_until',\n",
       "   'bigbench_metaphor_understanding_generate_until',\n",
       "   'bigbench_social_iqa_generate_until',\n",
       "   'bigbench_kannada_generate_until',\n",
       "   'bigbench_what_is_the_tao_generate_until',\n",
       "   'bigbench_bridging_anaphora_resolution_barqa_generate_until',\n",
       "   'bigbench_auto_categorization_generate_until',\n",
       "   'bigbench_logical_fallacy_detection_generate_until',\n",
       "   'bigbench_hindu_knowledge_generate_until',\n",
       "   'bigbench_language_identification_generate_until',\n",
       "   'bigbench_paragraph_segmentation_generate_until',\n",
       "   'bigbench_movie_dialog_same_or_different_generate_until',\n",
       "   'bigbench_logic_grid_puzzle_generate_until',\n",
       "   'bigbench_contextual_parametric_knowledge_conflicts_generate_until',\n",
       "   'bigbench_similarities_abstraction_generate_until',\n",
       "   'bigbench_linguistics_puzzles_generate_until',\n",
       "   'bigbench_anachronisms_generate_until'],\n",
       "  'yaml_path': -1},\n",
       " 'bigbench_physics_questions_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/physics_questions.yaml'},\n",
       " 'bigbench_nonsense_words_grammar_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/nonsense_words_grammar.yaml'},\n",
       " 'bigbench_modified_arithmetic_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/modified_arithmetic.yaml'},\n",
       " 'bigbench_evaluating_information_essentiality_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/evaluating_information_essentiality.yaml'},\n",
       " 'bigbench_english_russian_proverbs_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/english_russian_proverbs.yaml'},\n",
       " 'bigbench_reasoning_about_colored_objects_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/reasoning_about_colored_objects.yaml'},\n",
       " 'bigbench_implicit_relations_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/implicit_relations.yaml'},\n",
       " 'bigbench_polish_sequence_labeling_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/polish_sequence_labeling.yaml'},\n",
       " 'bigbench_word_sorting_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/word_sorting.yaml'},\n",
       " 'bigbench_chinese_remainder_theorem_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/chinese_remainder_theorem.yaml'},\n",
       " 'bigbench_sports_understanding_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/sports_understanding.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_subtasks_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_arithmetic_json_subtasks.yaml'},\n",
       " 'bigbench_ruin_names_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/ruin_names.yaml'},\n",
       " 'bigbench_entailed_polarity_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/entailed_polarity.yaml'},\n",
       " 'bigbench_physical_intuition_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/physical_intuition.yaml'},\n",
       " 'bigbench_hhh_alignment_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/hhh_alignment.yaml'},\n",
       " 'bigbench_semantic_parsing_spider_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/semantic_parsing_spider.yaml'},\n",
       " 'bigbench_strategyqa_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/strategyqa.yaml'},\n",
       " 'bigbench_intent_recognition_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/intent_recognition.yaml'},\n",
       " 'bigbench_bbq_lite_json_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/bbq_lite_json.yaml'},\n",
       " 'bigbench_word_unscrambling_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/word_unscrambling.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_multiple_choice_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_arithmetic_json_multiple_choice.yaml'},\n",
       " 'bigbench_implicatures_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/implicatures.yaml'},\n",
       " 'bigbench_sufficient_information_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/sufficient_information.yaml'},\n",
       " 'bigbench_emoji_movie_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/emoji_movie.yaml'},\n",
       " 'bigbench_tracking_shuffled_objects_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/tracking_shuffled_objects.yaml'},\n",
       " 'bigbench_unnatural_in_context_learning_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/unnatural_in_context_learning.yaml'},\n",
       " 'bigbench_temporal_sequences_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/temporal_sequences.yaml'},\n",
       " 'bigbench_kanji_ascii_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/kanji_ascii.yaml'},\n",
       " 'bigbench_disambiguation_qa_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/disambiguation_qa.yaml'},\n",
       " 'bigbench_timedial_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/timedial.yaml'},\n",
       " 'bigbench_empirical_judgments_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/empirical_judgments.yaml'},\n",
       " 'bigbench_simple_ethical_questions_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_ethical_questions.yaml'},\n",
       " 'bigbench_formal_fallacies_syllogisms_negation_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/formal_fallacies_syllogisms_negation.yaml'},\n",
       " 'bigbench_arithmetic_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/arithmetic.yaml'},\n",
       " 'bigbench_unit_conversion_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/unit_conversion.yaml'},\n",
       " 'bigbench_analogical_similarity_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/analogical_similarity.yaml'},\n",
       " 'bigbench_simple_text_editing_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_text_editing.yaml'},\n",
       " 'bigbench_play_dialog_same_or_different_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/play_dialog_same_or_different.yaml'},\n",
       " 'bigbench_cause_and_effect_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/cause_and_effect.yaml'},\n",
       " 'bigbench_entailed_polarity_hindi_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/entailed_polarity_hindi.yaml'},\n",
       " 'bigbench_simple_arithmetic_multiple_targets_json_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_arithmetic_multiple_targets_json.yaml'},\n",
       " 'bigbench_general_knowledge_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/general_knowledge.yaml'},\n",
       " 'bigbench_simp_turing_concept_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simp_turing_concept.yaml'},\n",
       " 'bigbench_scientific_press_release_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/scientific_press_release.yaml'},\n",
       " 'bigbench_tense_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/tense.yaml'},\n",
       " 'bigbench_operators_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/operators.yaml'},\n",
       " 'bigbench_periodic_elements_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/periodic_elements.yaml'},\n",
       " 'bigbench_international_phonetic_alphabet_transliterate_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/international_phonetic_alphabet_transliterate.yaml'},\n",
       " 'bigbench_strange_stories_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/strange_stories.yaml'},\n",
       " 'bigbench_unit_interpretation_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/unit_interpretation.yaml'},\n",
       " 'bigbench_auto_debugging_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/auto_debugging.yaml'},\n",
       " 'bigbench_question_selection_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/question_selection.yaml'},\n",
       " 'bigbench_known_unknowns_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/known_unknowns.yaml'},\n",
       " 'bigbench_matrixshapes_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/matrixshapes.yaml'},\n",
       " 'bigbench_understanding_fables_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/understanding_fables.yaml'},\n",
       " 'bigbench_dark_humor_detection_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/dark_humor_detection.yaml'},\n",
       " 'bigbench_emojis_emotion_prediction_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/emojis_emotion_prediction.yaml'},\n",
       " 'bigbench_phrase_relatedness_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/phrase_relatedness.yaml'},\n",
       " 'bigbench_undo_permutation_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/undo_permutation.yaml'},\n",
       " 'bigbench_code_line_description_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/code_line_description.yaml'},\n",
       " 'bigbench_date_understanding_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/date_understanding.yaml'},\n",
       " 'bigbench_simple_arithmetic_json_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/simple_arithmetic_json.yaml'},\n",
       " 'bigbench_persian_idioms_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/persian_idioms.yaml'},\n",
       " 'bigbench_checkmate_in_one_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/checkmate_in_one.yaml'},\n",
       " 'bigbench_misconceptions_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/misconceptions.yaml'},\n",
       " 'bigbench_language_games_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/language_games.yaml'},\n",
       " 'bigbench_conlang_translation_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/conlang_translation.yaml'},\n",
       " 'bigbench_novel_concepts_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/novel_concepts.yaml'},\n",
       " 'bigbench_english_proverbs_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/english_proverbs.yaml'},\n",
       " 'bigbench_riddle_sense_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/riddle_sense.yaml'},\n",
       " 'bigbench_winowhy_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/winowhy.yaml'},\n",
       " 'bigbench_semantic_parsing_in_context_sparc_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/semantic_parsing_in_context_sparc.yaml'},\n",
       " 'bigbench_physics_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/physics.yaml'},\n",
       " 'bigbench_fact_checker_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/fact_checker.yaml'},\n",
       " 'bigbench_discourse_marker_prediction_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/discourse_marker_prediction.yaml'},\n",
       " 'bigbench_identify_odd_metaphor_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/identify_odd_metaphor.yaml'},\n",
       " 'bigbench_snarks_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/snarks.yaml'},\n",
       " 'bigbench_swedish_to_german_proverbs_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/swedish_to_german_proverbs.yaml'},\n",
       " 'bigbench_hindi_question_answering_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/hindi_question_answering.yaml'},\n",
       " 'bigbench_symbol_interpretation_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/symbol_interpretation.yaml'},\n",
       " 'bigbench_codenames_generate_until': {'type': 'task',\n",
       "  'yaml_path': '/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/lm_eval/tasks/bigbench/generate_until/codenames.yaml'},\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lm_eval\n",
    "lm_eval.tasks.TaskManager().initialize_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b69bf1-6e59-4f3f-a524-adcf02b7d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0190868e96e4a92af38e73487df1f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b0b9791d704e69bbf4f402381fcc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01960d721df41e5b6de5846a10306f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8899eb0d6b8a4925a4f33ebf0fafa00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fdb88faa814fbabc6e9db7c1cb9cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13230f262b9d4c36865330fe8ea50bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e60fda3100942659568e6a0038936d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8159211d57124eb6a6b7b9f19bef441e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a12f320f21f4a5f8e676ebcf20fb63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717baf96bf814ffd88a298f1db422a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b00f301d14546d79e0022c762c92a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d259a81777c941a3aac368cf76d6d024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7341ba086d486392e5ca533c376633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3b0726e10c4b5ca67bd06f531f8380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571cd93d52a94a7e97a7c2dde01b4020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17260332233643cf936e60e4aac130c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f322c7895bea4523a39623c0b675fbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56081bdeffa421c9c66881bc415d27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f5b3b9648c423cace94cd2bfe68913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f9ff637faf49e0b7296a358a78c1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c60d8f289644ffeafda7b346a31bb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8adf68d8b0436283514451d03a688a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de772a5341ca47bfa74a7b48e5dcc009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39747e7a2b054b04935614e6ccc0de44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f7867a593b45babb4bcd3a4d4dee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7726cbfa85444299408a6e05735f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e5a8ecd7774c558f1a980354d76452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378119ec89fc4251b4be44a92e94e5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0a7cfcec99488b95b4047ad1d87606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6d3970b620463cbbd9fd955aa6e442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5758eb80eb354e4cbbf2e5d1941859b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce7215bcec446e1b44bcdfc032632c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f08a6cbd58f4ac0ae1a63239c10e32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640c7e81392640eaae11c9e4c29ac8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ada6dfdc5944d3d98927d0919f88164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec4aba3fd234314b2903e617802999f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69564e52bfbc47049f8527883ca3ab35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215cb9f627ee4202bb32e1ae4b29ac40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dd82d49f9e4451ad1768491bf9b6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cffad61b864848bd2464fc5ffb28ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85c58b9ae964ae7a0e6452f8dd19ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62981a7cd9ad401f9fb9147a7a554903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71e4661874347edadc7049e3d0d2ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f66c98eb9e640278a501f42d3f85396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2b924242f24013935a0c154dc28fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c636f429d4df3981f3695fe483be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029a2c157cdd44d48ffb72f5f50d899d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598718dee2d7475a8c1365abac2a85dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92582af6b65a400d8a7d3626062003bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ab079f0a1c4f36a4f171c90ae30471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8bcb7147ff4ec687c5c7bdbb6c9fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2775037f8c4418a9a71614ad5b24560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f22f8f7efa14a6985c8779c7a9c4b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c63861ef03c40a8917a5826c623688e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be39026d5d56435f83a6a343a85fb259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c8cd41e3f9437e95b4089eb75e3a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07014fc934fb420ab3376d38ce86da22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528eae751b1848b0806c5e85b65f24a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa881f4442964ebc9aa6b31fa8e77c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dacd4b1b07436fb815bfb7a4da41a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cd715b29ec41f89da968c0e78b489d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41fb8550944431d84c996fe3c0830dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bf520fce9243119a09589f27d65a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1face5d5b124690b796e69f37a861d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd701560bbd4876b1304c78e684be48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fb94a20a4a4636bb292994f44ec69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b0c2c5bfed4d2b9e358bda5b98e656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1af8d659994857a3d4897048c7c92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9b5ee96cfb41979b13ff2a47755005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aae92cb5dc6427b97e50e410a2ccada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087801c3880f43138ea65323c75a75a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22944947f894562b88a7fe00d7b03c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b59941575764625963f79769b9001c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9bae5a3cf947e6be24250645473da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfd208cfefc46aa9a5f8e6c1bd71043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abc7c7f86484bd58873600296c9b773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af4da8bf2bf458fb52c15dd1d28232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5ed4b943874a45a93d3b94ff0da077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf7d609fcd14fb986d217a749ebcdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a92bfcf03414f9465c0ff22b939f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4873f532bdf7446b856bdb1fe554b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a3cd01d07f44c6bc1d30ae7c67a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e532a08a6b4d328181e8a1c9f857b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39c6e5da0184d8aaf3555387df1b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50908087e2d640bbbdef568b988d876e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8939d3e9174964ba83bfc975480873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a8e8c2a0c042d78070578a955ff540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2ca31d09a84ae0b228cf972e38b52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34f2de8f21a41ac903265796d9df75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bb1efcc1194a3c827ef07555850981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d5864a8bbc465fa927ce451376f1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c064c100384f6c941e5e066fbfcd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee22cc2d4084706b0506c8f835ab70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b5ae2eae89421ab201ffe907db8d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b0f21e19814cccaf9e485deb6a8cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096e0f80f1cd46a381e827b666b92479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d664efdc16f9473ca87c1030c2d5cd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fcfcf4f23e40fe933dd878f29236bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b89386bd9d4fd08b111384f94e37d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b92a82886447e2b1afcff28506ee50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d95dd64e3f493e9bc4b856770eb414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71acbd49aeb8491280076ed754e3fbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df6ca6f01a945deb17f551990f9564c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76759b5f3f1245d8a6fcbd6edbf05722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24e28f657114e929a173ebd4c6be45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7994e827ec694230b01717a8d89e4ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143ad67c316c4f08965f1c45ea111266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c6fbf766a64698b9199cbec15a867a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa40da3d50aa453e8e52c1f36283a8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4bc9cc36af48efba593ef50ff63a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef58d5ef080f4674a833c374295a6e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3217cb9f744eda96e5f4df979f7db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae8236bcb93431186d9a36b535a5830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884e5634716c401388b7e1c39e49bd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3433837092cc4b899df1e977a8b0ef65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30db5dc47714ba28d679b562ed3a1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ad412feb40442eac006600560f0b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf251cba30f4c68a8f52f2fa3ab5a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d777c5c2175b4403aa51476c8bc46417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f0642c299c4dc8a0e0436faccd10df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc2bada0a804d1dbd67506d5e7fa056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74284f453af34ef7be0728220d811273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab1c3bcac364a37ae026d21dd01c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7981b4a8934b49a629fa0cb54190cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8acc7a160e74b6983d09227592720b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35a27f6150b4f8183e47b8954ba9a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec89c2338964a8fbe7bf7bb052bf56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1e79d56e5f4a9fb5c1f5a4b03b08ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1ebf3215234e6aac061333527a8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7f2c04593c4061878b289b394ea7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c87f8b256f44e7da498accbfc18fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ccbd4173904e048facc38aa032ec09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e7ba8917c84eb5af70d59849d922bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e71c19849044bcd88f5728c4b0c711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb653fcb2fc144b3b2e64dfe5873941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4a6d4dc777428f902bd5a9b2bcb72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59f0fabae0348f3bab119f0a2ceb7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64c63a5e2a64348a51d689206761fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de198d4dea04443aa6fd16f46e979773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b352ae1cb3744ebb2c1ef43dfa18a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca61df1088b0479ca91ea556299faf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f41663e3d0b40649120cdeaf6e954f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8714b806754f42838aa35c3049a0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406d1553a89f46719566275a59a0d002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabba9c403f4424c9976ef989eeef3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cea8b671aac49dd9d7cba4d4621b6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cbfe866abe4eedbebefd746a2ff945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e0f0befdf4ddcba169efbecdfaca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8d5cafe03b46cf8bd04db65db4873a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b61640b03b40f5b12faff7a07b3261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47dd9e11108422486e9b5f60bcbde51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a19429dd4ac4dd29efb61cae90a2d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c1622831fa43679d5980ba034b3b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32ff4c958ac43daaa0d5a4f07ee3bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f96a407ba5b4b5dad8d014517c26e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb3b54918424d82bd5b739ef12a0d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486e2a3ab50845d0b2159646fb93ffbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7940db6a964db3afa1456fff0fad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5866fe5f2b14f94a0c9a3adc747bd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796190b8961f40439a1b0588d7eb06b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f6788c56ec411da08edb56ebea5ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b6c04a12a848d6bbcdbf23f28204c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e792dbd7f4901a76ae5d356cdb075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76eaf330b50241af9a05dfe190db4bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a63b7257824961b7a9b04ddc9b3635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8601e3c4e004179a7326095220d8501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5757b4af5ad452cb49ea9e20ef60f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cde8c63b2794ee9b9a96082f2fec020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e552d1b17eb465fad8d121586623117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2b93772e944596bddfaf09685c702a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72f83eb44f4458aac1e2f41f41e4253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d0468a57542a4af8b4e05aacde954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38dcfbab8a34ed2b60c88ddecc53b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e2256f14164d0380943f4e9ee91e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_dict = lm_eval.tasks.get_task_dict('mmlu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90977a8-e8bc-4c0f-aaab-62113f1fe6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05:11:11:38,109 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
      "\n",
      "  0%|          | 0/171 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 40/171 [00:00<00:00, 399.28it/s]\u001b[A\n",
      " 55%|█████▍    | 94/171 [00:00<00:00, 481.86it/s]\u001b[A\n",
      "100%|██████████| 171/171 [00:00<00:00, 486.91it/s]\u001b[A\n",
      "2024-04-05:11:11:39,765 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "\n",
      "  0%|          | 0/163 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 56/163 [00:00<00:00, 557.90it/s]\u001b[A\n",
      "100%|██████████| 163/163 [00:00<00:00, 554.95it/s]\u001b[A\n",
      "2024-04-05:11:11:40,128 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "\n",
      "  0%|          | 0/895 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▋         | 57/895 [00:00<00:01, 564.41it/s]\u001b[A\n",
      " 13%|█▎        | 114/895 [00:00<00:01, 557.15it/s]\u001b[A\n",
      " 19%|█▉        | 170/895 [00:00<00:01, 556.12it/s]\u001b[A\n",
      " 25%|██▌       | 227/895 [00:00<00:01, 560.08it/s]\u001b[A\n",
      " 32%|███▏      | 284/895 [00:00<00:01, 556.67it/s]\u001b[A\n",
      " 38%|███▊      | 340/895 [00:00<00:00, 555.47it/s]\u001b[A\n",
      " 44%|████▍     | 396/895 [00:00<00:00, 555.21it/s]\u001b[A\n",
      " 51%|█████     | 452/895 [00:00<00:00, 555.22it/s]\u001b[A\n",
      " 57%|█████▋    | 508/895 [00:00<00:00, 554.42it/s]\u001b[A\n",
      " 63%|██████▎   | 564/895 [00:01<00:00, 554.55it/s]\u001b[A\n",
      " 69%|██████▉   | 621/895 [00:01<00:00, 557.10it/s]\u001b[A\n",
      " 76%|███████▌  | 677/895 [00:01<00:00, 557.01it/s]\u001b[A\n",
      " 82%|████████▏ | 733/895 [00:01<00:00, 557.67it/s]\u001b[A\n",
      " 88%|████████▊ | 789/895 [00:01<00:00, 555.50it/s]\u001b[A\n",
      "100%|██████████| 895/895 [00:01<00:00, 556.11it/s]\u001b[A\n",
      "2024-04-05:11:11:41,991 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
      "\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]\u001b[A\n",
      " 19%|█▊        | 58/311 [00:00<00:00, 573.81it/s]\u001b[A\n",
      " 37%|███▋      | 116/311 [00:00<00:00, 564.14it/s]\u001b[A\n",
      " 56%|█████▌    | 173/311 [00:00<00:00, 563.73it/s]\u001b[A\n",
      " 74%|███████▍  | 230/311 [00:00<00:00, 560.06it/s]\u001b[A\n",
      "100%|██████████| 311/311 [00:00<00:00, 557.90it/s]\u001b[A\n",
      "2024-04-05:11:11:42,646 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 55/237 [00:00<00:00, 547.05it/s]\u001b[A\n",
      " 47%|████▋     | 111/237 [00:00<00:00, 550.73it/s]\u001b[A\n",
      " 70%|███████   | 167/237 [00:00<00:00, 552.90it/s]\u001b[A\n",
      "100%|██████████| 237/237 [00:00<00:00, 551.47it/s]\u001b[A\n",
      "2024-04-05:11:11:43,239 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
      "\n",
      "  0%|          | 0/1534 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 58/1534 [00:00<00:02, 576.28it/s]\u001b[A\n",
      "  8%|▊         | 116/1534 [00:00<00:02, 566.68it/s]\u001b[A\n",
      " 11%|█▏        | 173/1534 [00:00<00:02, 561.34it/s]\u001b[A\n",
      " 15%|█▍        | 230/1534 [00:00<00:02, 561.31it/s]\u001b[A\n",
      " 19%|█▊        | 287/1534 [00:00<00:02, 560.76it/s]\u001b[A\n",
      " 22%|██▏       | 344/1534 [00:00<00:02, 561.14it/s]\u001b[A\n",
      " 26%|██▌       | 401/1534 [00:00<00:02, 561.05it/s]\u001b[A\n",
      " 30%|██▉       | 458/1534 [00:00<00:01, 558.62it/s]\u001b[A\n",
      " 34%|███▎      | 514/1534 [00:00<00:01, 557.82it/s]\u001b[A\n",
      " 37%|███▋      | 571/1534 [00:01<00:01, 560.49it/s]\u001b[A\n",
      " 41%|████      | 628/1534 [00:01<00:01, 562.26it/s]\u001b[A\n",
      " 45%|████▍     | 687/1534 [00:01<00:01, 567.80it/s]\u001b[A\n",
      " 49%|████▊     | 744/1534 [00:01<00:01, 561.99it/s]\u001b[A\n",
      " 52%|█████▏    | 801/1534 [00:01<00:01, 558.25it/s]\u001b[A\n",
      " 56%|█████▌    | 858/1534 [00:01<00:01, 560.24it/s]\u001b[A\n",
      " 60%|█████▉    | 915/1534 [00:01<00:01, 559.83it/s]\u001b[A\n",
      " 63%|██████▎   | 971/1534 [00:01<00:01, 559.37it/s]\u001b[A\n",
      " 67%|██████▋   | 1028/1534 [00:01<00:00, 561.52it/s]\u001b[A\n",
      " 71%|███████   | 1085/1534 [00:01<00:00, 563.27it/s]\u001b[A\n",
      " 74%|███████▍  | 1142/1534 [00:02<00:00, 564.43it/s]\u001b[A\n",
      " 78%|███████▊  | 1199/1534 [00:02<00:00, 563.85it/s]\u001b[A\n",
      " 82%|████████▏ | 1256/1534 [00:02<00:00, 562.13it/s]\u001b[A\n",
      " 86%|████████▌ | 1313/1534 [00:02<00:00, 559.83it/s]\u001b[A\n",
      " 89%|████████▉ | 1370/1534 [00:02<00:00, 561.63it/s]\u001b[A\n",
      " 93%|█████████▎| 1427/1534 [00:02<00:00, 559.47it/s]\u001b[A\n",
      "100%|██████████| 1534/1534 [00:02<00:00, 561.01it/s]\u001b[A\n",
      "2024-04-05:11:11:46,424 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 108/108 [00:00<00:00, 555.81it/s][A\n",
      "2024-04-05:11:11:46,713 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "\n",
      "  0%|          | 0/346 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▋        | 57/346 [00:00<00:00, 563.06it/s]\u001b[A\n",
      " 33%|███▎      | 114/346 [00:00<00:00, 562.91it/s]\u001b[A\n",
      " 49%|████▉     | 171/346 [00:00<00:00, 558.38it/s]\u001b[A\n",
      " 66%|██████▌   | 228/346 [00:00<00:00, 560.06it/s]\u001b[A\n",
      " 82%|████████▏ | 285/346 [00:00<00:00, 560.39it/s]\u001b[A\n",
      "100%|██████████| 346/346 [00:00<00:00, 557.31it/s]\u001b[A\n",
      "2024-04-05:11:11:47,480 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "\n",
      "  0%|          | 0/204 [00:00<?, ?it/s]\u001b[A\n",
      " 27%|██▋       | 56/204 [00:00<00:00, 558.15it/s]\u001b[A\n",
      " 55%|█████▍    | 112/204 [00:00<00:00, 558.98it/s]\u001b[A\n",
      "100%|██████████| 204/204 [00:00<00:00, 556.88it/s]\u001b[A\n",
      "2024-04-05:11:11:47,964 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
      " 47%|████▋     | 57/121 [00:00<00:00, 562.10it/s]\u001b[A\n",
      "100%|██████████| 121/121 [00:00<00:00, 546.74it/s]\u001b[A\n",
      "2024-04-05:11:11:48,255 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
      "\n",
      "  0%|          | 0/126 [00:00<?, ?it/s]\u001b[A\n",
      " 46%|████▌     | 58/126 [00:00<00:00, 573.46it/s]\u001b[A\n",
      "100%|██████████| 126/126 [00:00<00:00, 555.21it/s]\u001b[A\n",
      "2024-04-05:11:11:48,551 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
      "\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|█▊        | 57/324 [00:00<00:00, 565.35it/s]\u001b[A\n",
      " 35%|███▌      | 114/324 [00:00<00:00, 556.98it/s]\u001b[A\n",
      " 53%|█████▎    | 171/324 [00:00<00:00, 560.57it/s]\u001b[A\n",
      " 70%|███████   | 228/324 [00:00<00:00, 560.35it/s]\u001b[A\n",
      "100%|██████████| 324/324 [00:00<00:00, 556.79it/s]\u001b[A\n",
      "2024-04-05:11:11:49,209 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "\n",
      "  0%|          | 0/165 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 56/165 [00:00<00:00, 557.67it/s]\u001b[A\n",
      "100%|██████████| 165/165 [00:00<00:00, 556.90it/s]\u001b[A\n",
      "2024-04-05:11:11:49,606 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "\n",
      "  0%|          | 0/198 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▉       | 58/198 [00:00<00:00, 570.32it/s]\u001b[A\n",
      " 59%|█████▊    | 116/198 [00:00<00:00, 562.03it/s]\u001b[A\n",
      "100%|██████████| 198/198 [00:00<00:00, 556.44it/s]\u001b[A\n",
      "2024-04-05:11:11:50,019 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
      "\n",
      "  0%|          | 0/245 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 57/245 [00:00<00:00, 562.31it/s]\u001b[A\n",
      " 47%|████▋     | 114/245 [00:00<00:00, 561.04it/s]\u001b[A\n",
      " 70%|██████▉   | 171/245 [00:00<00:00, 558.56it/s]\u001b[A\n",
      "100%|██████████| 245/245 [00:00<00:00, 555.89it/s]\u001b[A\n",
      "2024-04-05:11:11:50,568 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 560.68it/s][A\n",
      "2024-04-05:11:11:50,786 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
      "\n",
      "  0%|          | 0/201 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▉       | 58/201 [00:00<00:00, 575.82it/s]\u001b[A\n",
      " 58%|█████▊    | 116/201 [00:00<00:00, 565.83it/s]\u001b[A\n",
      "100%|██████████| 201/201 [00:00<00:00, 559.98it/s]\u001b[A\n",
      "2024-04-05:11:11:51,232 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "\n",
      "  0%|          | 0/390 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▍        | 57/390 [00:00<00:00, 561.94it/s]\u001b[A\n",
      " 29%|██▉       | 114/390 [00:00<00:00, 557.85it/s]\u001b[A\n",
      " 44%|████▎     | 170/390 [00:00<00:00, 545.64it/s]\u001b[A\n",
      " 58%|█████▊    | 225/390 [00:00<00:00, 545.80it/s]\u001b[A\n",
      " 72%|███████▏  | 281/390 [00:00<00:00, 548.53it/s]\u001b[A\n",
      "100%|██████████| 390/390 [00:00<00:00, 552.83it/s]\u001b[A\n",
      "2024-04-05:11:11:52,017 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "\n",
      "  0%|          | 0/131 [00:00<?, ?it/s]\u001b[A\n",
      " 44%|████▎     | 57/131 [00:00<00:00, 561.00it/s]\u001b[A\n",
      "100%|██████████| 131/131 [00:00<00:00, 552.97it/s]\u001b[A\n",
      "2024-04-05:11:11:52,283 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "\n",
      "  0%|          | 0/612 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 57/612 [00:00<00:00, 566.22it/s]\u001b[A\n",
      " 19%|█▊        | 114/612 [00:00<00:00, 560.92it/s]\u001b[A\n",
      " 28%|██▊       | 171/612 [00:00<00:00, 562.77it/s]\u001b[A\n",
      " 37%|███▋      | 228/612 [00:00<00:00, 565.53it/s]\u001b[A\n",
      " 47%|████▋     | 285/612 [00:00<00:00, 564.13it/s]\u001b[A\n",
      " 56%|█████▌    | 342/612 [00:00<00:00, 565.12it/s]\u001b[A\n",
      " 65%|██████▌   | 400/612 [00:00<00:00, 568.62it/s]\u001b[A\n",
      " 75%|███████▍  | 458/612 [00:00<00:00, 571.29it/s]\u001b[A\n",
      " 84%|████████▍ | 516/612 [00:00<00:00, 567.01it/s]\u001b[A\n",
      "100%|██████████| 612/612 [00:01<00:00, 564.63it/s]\u001b[A\n",
      "2024-04-05:11:11:53,533 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▉       | 56/193 [00:00<00:00, 558.16it/s]\u001b[A\n",
      " 59%|█████▊    | 113/193 [00:00<00:00, 561.51it/s]\u001b[A\n",
      "100%|██████████| 193/193 [00:00<00:00, 556.06it/s]\u001b[A\n",
      "2024-04-05:11:11:53,988 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
      "\n",
      "  0%|          | 0/114 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 57/114 [00:00<00:00, 562.58it/s]\u001b[A\n",
      "100%|██████████| 114/114 [00:00<00:00, 559.30it/s]\u001b[A\n",
      "2024-04-05:11:11:54,243 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "\n",
      "  0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      " 24%|██▍       | 58/238 [00:00<00:00, 579.48it/s]\u001b[A\n",
      " 49%|████▊     | 116/238 [00:00<00:00, 570.30it/s]\u001b[A\n",
      " 73%|███████▎  | 174/238 [00:00<00:00, 560.22it/s]\u001b[A\n",
      "100%|██████████| 238/238 [00:00<00:00, 555.72it/s]\u001b[A\n",
      "2024-04-05:11:11:54,712 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "\n",
      "  0%|          | 0/545 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 57/545 [00:00<00:00, 562.75it/s]\u001b[A\n",
      " 21%|██        | 114/545 [00:00<00:00, 557.97it/s]\u001b[A\n",
      " 31%|███       | 170/545 [00:00<00:00, 556.28it/s]\u001b[A\n",
      " 42%|████▏     | 227/545 [00:00<00:00, 558.59it/s]\u001b[A\n",
      " 52%|█████▏    | 284/545 [00:00<00:00, 559.97it/s]\u001b[A\n",
      " 62%|██████▏   | 340/545 [00:00<00:00, 558.09it/s]\u001b[A\n",
      " 73%|███████▎  | 396/545 [00:00<00:00, 557.34it/s]\u001b[A\n",
      " 83%|████████▎ | 453/545 [00:00<00:00, 558.51it/s]\u001b[A\n",
      "100%|██████████| 545/545 [00:00<00:00, 556.62it/s]\u001b[A\n",
      "2024-04-05:11:11:55,817 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
      "\n",
      "  0%|          | 0/110 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 110/110 [00:00<00:00, 565.38it/s][A\n",
      "2024-04-05:11:11:56,072 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 561.15it/s][A\n",
      "2024-04-05:11:11:56,356 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
      "\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 103/103 [00:00<00:00, 566.83it/s][A\n",
      "2024-04-05:11:11:56,593 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
      "\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 57/173 [00:00<00:00, 567.62it/s]\u001b[A\n",
      " 66%|██████▌   | 114/173 [00:00<00:00, 562.16it/s]\u001b[A\n",
      "100%|██████████| 173/173 [00:00<00:00, 556.28it/s]\u001b[A\n",
      "2024-04-05:11:11:56,954 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "\n",
      "  0%|          | 0/282 [00:00<?, ?it/s]\u001b[A\n",
      " 21%|██        | 59/282 [00:00<00:00, 580.38it/s]\u001b[A\n",
      " 42%|████▏     | 118/282 [00:00<00:00, 567.70it/s]\u001b[A\n",
      " 62%|██████▏   | 175/282 [00:00<00:00, 567.46it/s]\u001b[A\n",
      "100%|██████████| 282/282 [00:00<00:00, 564.23it/s]\u001b[A\n",
      "2024-04-05:11:11:57,517 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
      "\n",
      "  0%|          | 0/306 [00:00<?, ?it/s]\u001b[A\n",
      " 19%|█▉        | 58/306 [00:00<00:00, 577.60it/s]\u001b[A\n",
      " 38%|███▊      | 116/306 [00:00<00:00, 561.86it/s]\u001b[A\n",
      " 57%|█████▋    | 173/306 [00:00<00:00, 558.81it/s]\u001b[A\n",
      " 75%|███████▌  | 231/306 [00:00<00:00, 564.16it/s]\u001b[A\n",
      "100%|██████████| 306/306 [00:00<00:00, 559.32it/s]\u001b[A\n",
      "2024-04-05:11:11:58,141 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "\n",
      "  0%|          | 0/265 [00:00<?, ?it/s]\u001b[A\n",
      " 22%|██▏       | 57/265 [00:00<00:00, 564.91it/s]\u001b[A\n",
      " 43%|████▎     | 114/265 [00:00<00:00, 561.37it/s]\u001b[A\n",
      " 65%|██████▍   | 171/265 [00:00<00:00, 562.33it/s]\u001b[A\n",
      "100%|██████████| 265/265 [00:00<00:00, 564.27it/s]\u001b[A\n",
      "2024-04-05:11:11:58,697 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
      "\n",
      "  0%|          | 0/166 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 57/166 [00:00<00:00, 561.90it/s]\u001b[A\n",
      "Running loglikelihood requests:   9%|▉         | 5136/56168 [1:40:59<16:43:26,  1.18s/it]\n",
      "100%|██████████| 166/166 [00:07<00:00, 23.61it/s] \n",
      "2024-04-05:11:12:05,829 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 556.66it/s]\n",
      "2024-04-05:11:12:06,079 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:01<00:00, 563.95it/s]\n",
      "2024-04-05:11:12:07,618 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:00<00:00, 563.79it/s]\n",
      "2024-04-05:11:12:08,100 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:00<00:00, 566.42it/s]\n",
      "2024-04-05:11:12:08,574 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 571.48it/s]\n",
      "2024-04-05:11:12:08,802 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:00<00:00, 561.29it/s]\n",
      "2024-04-05:11:12:09,387 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:00<00:00, 565.24it/s]\n",
      "2024-04-05:11:12:09,685 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:00<00:00, 563.54it/s]\n",
      "2024-04-05:11:12:09,986 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:00<00:00, 566.01it/s]\n",
      "2024-04-05:11:12:10,412 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:00<00:00, 562.35it/s]\n",
      "2024-04-05:11:12:10,883 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:00<00:00, 554.22it/s]\n",
      "2024-04-05:11:12:11,305 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 557.74it/s]\n",
      "2024-04-05:11:12:11,531 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:00<00:00, 560.13it/s]\n",
      "2024-04-05:11:12:11,866 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 563.40it/s]\n",
      "2024-04-05:11:12:12,102 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 568.93it/s]\n",
      "2024-04-05:11:12:12,328 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:00<00:00, 569.24it/s]\n",
      "2024-04-05:11:12:12,565 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 566.79it/s]\n",
      "2024-04-05:11:12:12,821 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 567.98it/s]\n",
      "2024-04-05:11:12:13,050 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:00<00:00, 568.33it/s]\n",
      "2024-04-05:11:12:13,300 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:00<00:00, 565.79it/s]\n",
      "2024-04-05:11:12:13,900 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:00<00:00, 547.20it/s]\n",
      "2024-04-05:11:12:14,660 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:00<00:00, 549.30it/s]\n",
      "2024-04-05:11:12:15,435 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 562.23it/s]\n",
      "2024-04-05:11:12:15,653 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:00<00:00, 566.44it/s]\n",
      "2024-04-05:11:12:15,972 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:00<00:00, 568.16it/s]\n",
      "2024-04-05:11:12:16,394 INFO     [evaluator.py:362] Running loglikelihood requests\n",
      "Running loglikelihood requests:  98%|█████████▊| 54953/56168 [45:39<00:55, 21.98it/s]"
     ]
    }
   ],
   "source": [
    "eval_results = lm_eval.evaluate(\n",
    "        moe,\n",
    "        task_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bea3bb6c-be95-4d61-a3a0-6772c5b29282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('wikitext', {'word_perplexity,none': nan, 'word_perplexity_stderr,none': 'N/A', 'byte_perplexity,none': nan, 'byte_perplexity_stderr,none': 'N/A', 'bits_per_byte,none': nan, 'bits_per_byte_stderr,none': 'N/A', 'alias': 'wikitext'})])\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"results\"].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6e467c6-80e4-4818-a31a-a39d3024f3b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Config name is missing.\nPlease pick one among the available configs: ['wikitext-103-raw-v1', 'wikitext-103-v1', 'wikitext-2-raw-v1', 'wikitext-2-v1']\nExample of usage:\n\t`load_dataset('wikitext', 'wikitext-103-raw-v1')`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwikitext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/datasets/load.py:2556\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2552\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2556\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/datasets/load.py:2265\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2263\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 2265\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2279\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[0;32m/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/datasets/builder.py:371\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/user/vincent2013/myenv/lib/python3.10/site-packages/datasets/builder.py:577\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_kwargs:\n\u001b[1;32m    576\u001b[0m         example_of_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_dataset(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig name is missing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease pick one among the available configs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder_configs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExample of usage:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_of_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     builder_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Config name is missing.\nPlease pick one among the available configs: ['wikitext-103-raw-v1', 'wikitext-103-v1', 'wikitext-2-raw-v1', 'wikitext-2-v1']\nExample of usage:\n\t`load_dataset('wikitext', 'wikitext-103-raw-v1')`"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikitext\", 'wikitext-103-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9049c58f-0895-4832-9c23-c0d5e92c31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ppl_int4AWQ.txt\", 'w') as file:\n",
    "    file.write('The ppl for AWQ quantization is:')\n",
    "    for task, res in eval_results[\"results\"].items():\n",
    "        file.write(f\"{task}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987022dd-4333-4212-9bff-457cc811c10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
