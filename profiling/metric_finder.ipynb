{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9802c717-1342-4935-8180-fef8eb8f4a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102/2916776140.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002c4370-ef0e-4e07-8a42-eca691e27c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "q4_data_file = \"ncu_report_full_q4_2layers_utilization_full.csv\"\n",
    "q8_data_file = \"ncu_report_full_q8_2layers_utilization_full.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a835bb1e-1db7-49a1-9de8-dee2a330aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interested(col_name):\n",
    "    return True\n",
    "    \n",
    "def get_aggregated_stat(source_data_path):\n",
    "    print(\"=== Reading data:\", source_data_path)\n",
    "    source_data = pd.read_csv(source_data_path, thousands=',')\n",
    "    cols = source_data.columns\n",
    "    selected_cols = cols[[8]]\n",
    "    appending_cols = [col for col in cols[18:] if is_interested(col)]\n",
    "    print(\"Interested metrics in data file:\",len(appending_cols))\n",
    "    source_stat = source_data.loc[:,list(selected_cols)+list(appending_cols)]\n",
    "    print(source_stat.info())\n",
    "    # for col in source_stat.columns[:20]:\n",
    "    #     print(\"- \", source_stat[col].dtypes)\n",
    "    print(\"Data types:\", source_stat.iloc[:,:].dtypes)\n",
    "    # res = source_stat.iloc[:,:].groupby(['Demangled Name'], sort=True).mean()\n",
    "    print(\"=== End of Processing:\", source_data_path)\n",
    "    return source_stat\n",
    "    # return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e3ca71-c0ae-4d76-ab86-d2dc29fd01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿ID,Time,API Call ID,Estimated Speedup,\"Runtime Improvement\"\"\"\"(0)\",\"Issues Detected\"\"\"\"(850)\",Function Name,Mangled Name,Demangled Name,Process,Thread ID,Device Name,CUprogram,CUfunction,Grid Offset,Grid Size,Block Size,Grid Dimensions,gpc__cycles_elapsed.max [cycle],gpu__time_duration.sum [usecond],sm__throughput.avg.pct_of_peak_sustained_elapsed [%],gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed \n",
      "0,2024-Feb-13 13:21:25,20399,0.00,0.00,2,mul_mat_vec_q,_Z13mul_mat_vec_qILi32ELi4E10block_q4_0Li2EXadL_ZN43_INTERNAL_642294f9_12_ggml_cuda_cu_fe7a8db317vec_dot_q4_0_q8_1EPKvPK10block_q8_1RKiEEEvS3_S3_Pfii,\"void mul_mat_vec_q<(int)32, (int)4, block_q4_0, (int)2, &vec_dot_q4_0_q8_1>(const void *, const void *, float *, int, int)\",[206719] main,206719,NVIDIA GeForce \n"
     ]
    }
   ],
   "source": [
    "! head -n 2 ./ncu_report_full_q4_2layers_utilization.csv | awk '{for(i=1;i<=18;i++) printf \"%s \", $i; print \"\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67a9cee0-d000-4029-8779-b62664c1ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reading data: ncu_report_full_q4_2layers_utilization_full.csv\n",
      "Interested metrics in data file: 114393\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 114394 entries, Demangled Name to tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]\n",
      "dtypes: float64(55895), int64(58455), object(44)\n",
      "memory usage: 87.3+ MB\n",
      "None\n",
      "Data types: Demangled Name                                                           object\n",
      "gpc__cycles_elapsed.max [cycle]                                           int64\n",
      "gpu__time_duration.sum [usecond]                                        float64\n",
      "sm__throughput.avg.pct_of_peak_sustained_elapsed [%]                    float64\n",
      "gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed [%]    float64\n",
      "                                                                         ...   \n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]        float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]       float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]      float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]     float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]      float64\n",
      "Length: 114394, dtype: object\n",
      "=== End of Processing: ncu_report_full_q4_2layers_utilization_full.csv\n"
     ]
    }
   ],
   "source": [
    "q4_source_stat = get_aggregated_stat(q4_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07a8386-2d7d-43ca-976a-3db4a4e3edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "for col in q4_source_stat.columns[1:]:\n",
    "    if q4_source_stat[col].dtype == \"object\":\n",
    "        # print(col)\n",
    "        drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5a88132-ff97-474d-82f2-7895c7924f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_q4_source_stat = q4_source_stat.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75989e12-6fa9-45c0-8cc5-d7e7a2858b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_agg = selected_q4_source_stat.groupby(['Demangled Name'], sort=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1a999ca-48d8-4510-93f3-5d7aae9b00b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reading data: ncu_report_full_q8_2layers_utilization_full.csv\n",
      "Interested metrics in data file: 114393\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 114394 entries, Demangled Name to tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]\n",
      "dtypes: float64(56282), int64(58068), object(44)\n",
      "memory usage: 87.3+ MB\n",
      "None\n",
      "Data types: Demangled Name                                                           object\n",
      "gpc__cycles_elapsed.max [cycle]                                           int64\n",
      "gpu__time_duration.sum [usecond]                                        float64\n",
      "sm__throughput.avg.pct_of_peak_sustained_elapsed [%]                    float64\n",
      "gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed [%]    float64\n",
      "                                                                         ...   \n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]        float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]       float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]      float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]     float64\n",
      "tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]      float64\n",
      "Length: 114394, dtype: object\n",
      "=== End of Processing: ncu_report_full_q8_2layers_utilization_full.csv\n"
     ]
    }
   ],
   "source": [
    "q8_source_stat = get_aggregated_stat(q8_data_file)\n",
    "drop_cols = []\n",
    "for col in q8_source_stat.columns[1:]:\n",
    "    if q8_source_stat[col].dtype == \"object\":\n",
    "        # print(col)\n",
    "        drop_cols.append(col)\n",
    "selected_q8_source_stat = q8_source_stat.drop(drop_cols, axis=1)\n",
    "q8_agg = selected_q8_source_stat.groupby(['Demangled Name'], sort=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7a854d6-fe73-4dcb-8891-72d2d4b1f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.float_format = '{:.0f}'.format\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13fefa89-110b-440b-9ae3-23f09dbc1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21 entries, k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long) to void soft_max_f32<(bool)1, (int)64, (int)64>(const float *, const float *, float *, int, int, float)\n",
      "Columns: 114471 entries, c2clink__enabled_mask to tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]\n",
      "dtypes: float64(114471)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "diff = q8_agg.sub(q4_agg, fill_value=0.0)\n",
    "diff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f176d6fd-13e3-4098-b214-5b7694cfed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which col & row have any non-zero values:\n",
    "nonzero_diff = diff.loc[:,(diff!=0).any()].loc[(diff!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af8c09fd-df84-4308-a014-6d395c6cc07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device__attribute_architecture</th>\n",
       "      <th>device__attribute_async_engine_count</th>\n",
       "      <th>device__attribute_can_map_host_memory</th>\n",
       "      <th>device__attribute_can_tex2d_gather</th>\n",
       "      <th>device__attribute_can_use_64_bit_stream_mem_ops</th>\n",
       "      <th>device__attribute_can_use_host_pointer_for_registered_mem</th>\n",
       "      <th>device__attribute_can_use_stream_wait_value_nor</th>\n",
       "      <th>device__attribute_chip</th>\n",
       "      <th>device__attribute_clock_rate</th>\n",
       "      <th>device__attribute_compute_capability_major</th>\n",
       "      <th>...</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_elapsed.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demangled Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3,653.33</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3,653.33</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_sum_rows_f32(const float *, float *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>95,200.00</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>95,200.00</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantize_q8_1(const float *, void *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.89</td>\n",
       "      <td>276,986.76</td>\n",
       "      <td>1.89</td>\n",
       "      <td>276,986.76</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silu_f32(const float *, float *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-32,592.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-32,592.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turing_h1688gemm_256x64_ldg8_stages_32x1_tn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08</td>\n",
       "      <td>449,104.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>449,104.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;__half, float&gt;(const void *, T2 *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-27,536.00</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-27,536.00</td>\n",
       "      <td>6.21</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;float, __half&gt;(const void *, T2 *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>30,384.00</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>30,384.00</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.17</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f16&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>53,520.00</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>53,520.00</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f32&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>123,840.00</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>123,840.00</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void dequantize_mul_mat_vec&lt;(int)1, (int)1, &amp;convert_f16&gt;(const void *, const float *, float *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>162,528.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>162,528.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_argsort_f32_i32&lt;(ggml_sort_order)1&gt;(const float *, int *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.12</td>\n",
       "      <td>-53,504.00</td>\n",
       "      <td>15.12</td>\n",
       "      <td>-53,504.00</td>\n",
       "      <td>15.12</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_add, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>48,685.71</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>48,685.71</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_div, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>91,936.00</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>91,936.00</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_mul, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>3,163.90</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>3,163.90</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_get_rows_float&lt;float, float&gt;(const T1 *, const int *, T2 *, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-82,560.00</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-82,560.00</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)4, block_q4_0, (int)2, &amp;vec_dot_q4_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>-352.00</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-356.00</td>\n",
       "      <td>-1,800,000.00</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2,018.34</td>\n",
       "      <td>-161,485,589.33</td>\n",
       "      <td>-2,018.34</td>\n",
       "      <td>-161,485,589.33</td>\n",
       "      <td>-2,018.34</td>\n",
       "      <td>-595.31</td>\n",
       "      <td>-595.31</td>\n",
       "      <td>-595.31</td>\n",
       "      <td>-595.31</td>\n",
       "      <td>-938.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)8, block_q8_0, (int)2, &amp;vec_dot_q8_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.49</td>\n",
       "      <td>188,628,218.95</td>\n",
       "      <td>29.49</td>\n",
       "      <td>188,628,218.95</td>\n",
       "      <td>29.49</td>\n",
       "      <td>105.37</td>\n",
       "      <td>105.37</td>\n",
       "      <td>105.37</td>\n",
       "      <td>105.37</td>\n",
       "      <td>178.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rms_norm_f32&lt;(int)1024&gt;(const float *, float *, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-256,217.60</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-256,217.60</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rope&lt;float, (bool)1&gt;(const T1 *, T1 *, int, const int *, float, int, float, float, float, rope_corr_dims)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-38,928.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-38,928.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)0, (int)0&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.37</td>\n",
       "      <td>95,168.00</td>\n",
       "      <td>4.37</td>\n",
       "      <td>95,168.00</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)64, (int)64&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>70,912.00</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>70,912.00</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã 76198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    device__attribute_architecture  \\\n",
       "Demangled Name                                                                       \n",
       "k_compute_batched_ptrs(const __half *, const __...                            0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                   0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                0.00   \n",
       "silu_f32(const float *, float *, int)                                         0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                   0.00   \n",
       "void convert_unary<__half, float>(const void *,...                            0.00   \n",
       "void convert_unary<float, __half>(const void *,...                            0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                            0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                            0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                            0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                            0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                            0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                            0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                            0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                            0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                         -352.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                            0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                            0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                            0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                            0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                            0.00   \n",
       "\n",
       "                                                    device__attribute_async_engine_count  \\\n",
       "Demangled Name                                                                             \n",
       "k_compute_batched_ptrs(const __half *, const __...                                  0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                         0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                      0.00   \n",
       "silu_f32(const float *, float *, int)                                               0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                         0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                  0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                  0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                  0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                  0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                  0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                  0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                  0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                  0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                  0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                  0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                 -3.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                  0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                  0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                  0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                  0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                  0.00   \n",
       "\n",
       "                                                    device__attribute_can_map_host_memory  \\\n",
       "Demangled Name                                                                              \n",
       "k_compute_batched_ptrs(const __half *, const __...                                   0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                          0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                       0.00   \n",
       "silu_f32(const float *, float *, int)                                                0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                          0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                   0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                   0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                   0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                   0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                   0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                   0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                   0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                   0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                   0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                   0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                  -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                   0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                   0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                   0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                   0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                   0.00   \n",
       "\n",
       "                                                    device__attribute_can_tex2d_gather  \\\n",
       "Demangled Name                                                                           \n",
       "k_compute_batched_ptrs(const __half *, const __...                                0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                       0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                    0.00   \n",
       "silu_f32(const float *, float *, int)                                             0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                       0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                               -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                0.00   \n",
       "\n",
       "                                                    device__attribute_can_use_64_bit_stream_mem_ops  \\\n",
       "Demangled Name                                                                                        \n",
       "k_compute_batched_ptrs(const __half *, const __...                                             0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                    0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                 0.00   \n",
       "silu_f32(const float *, float *, int)                                                          0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                    0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                             0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                             0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                             0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                             0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                             0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                             0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                             0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                             0.00   \n",
       "\n",
       "                                                    device__attribute_can_use_host_pointer_for_registered_mem  \\\n",
       "Demangled Name                                                                                                  \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00           \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.00           \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.00           \n",
       "silu_f32(const float *, float *, int)                                                            0.00           \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.00           \n",
       "void convert_unary<__half, float>(const void *,...                                               0.00           \n",
       "void convert_unary<float, __half>(const void *,...                                               0.00           \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                               0.00           \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00           \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.00           \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                               0.00           \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.00           \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                               0.00           \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                               0.00           \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.00           \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00           \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.00           \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.00           \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00           \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.00           \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                               0.00           \n",
       "\n",
       "                                                    device__attribute_can_use_stream_wait_value_nor  \\\n",
       "Demangled Name                                                                                        \n",
       "k_compute_batched_ptrs(const __half *, const __...                                             0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                    0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                 0.00   \n",
       "silu_f32(const float *, float *, int)                                                          0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                    0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                             0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                             0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                             0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                             0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                             0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                             0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                             0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                             0.00   \n",
       "\n",
       "                                                    device__attribute_chip  \\\n",
       "Demangled Name                                                               \n",
       "k_compute_batched_ptrs(const __half *, const __...                    0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                           0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                        0.00   \n",
       "silu_f32(const float *, float *, int)                                 0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                           0.00   \n",
       "void convert_unary<__half, float>(const void *,...                    0.00   \n",
       "void convert_unary<float, __half>(const void *,...                    0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                    0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                    0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                    0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                    0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                    0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                    0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                    0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                    0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                 -356.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                    0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                    0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                    0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                    0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                    0.00   \n",
       "\n",
       "                                                    device__attribute_clock_rate  \\\n",
       "Demangled Name                                                                     \n",
       "k_compute_batched_ptrs(const __half *, const __...                          0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                 0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                              0.00   \n",
       "silu_f32(const float *, float *, int)                                       0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                 0.00   \n",
       "void convert_unary<__half, float>(const void *,...                          0.00   \n",
       "void convert_unary<float, __half>(const void *,...                          0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                          0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                          0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                          0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                          0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                          0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                          0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                          0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                          0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                 -1,800,000.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                          0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                          0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                          0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                          0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                          0.00   \n",
       "\n",
       "                                                    device__attribute_compute_capability_major  \\\n",
       "Demangled Name                                                                                   \n",
       "k_compute_batched_ptrs(const __half *, const __...                                        0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                               0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                            0.00   \n",
       "silu_f32(const float *, float *, int)                                                     0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                               0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                        0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                        0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                        0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                        0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                        0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                        0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                        0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                        0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                        0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                        0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                       -7.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                        0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                        0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                        0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                        0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                        0.00   \n",
       "\n",
       "                                                    ...  \\\n",
       "Demangled Name                                      ...   \n",
       "k_compute_batched_ptrs(const __half *, const __...  ...   \n",
       "k_sum_rows_f32(const float *, float *, int)         ...   \n",
       "quantize_q8_1(const float *, void *, int, int)      ...   \n",
       "silu_f32(const float *, float *, int)               ...   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn         ...   \n",
       "void convert_unary<__half, float>(const void *,...  ...   \n",
       "void convert_unary<float, __half>(const void *,...  ...   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...  ...   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...  ...   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...  ...   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...  ...   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...  ...   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...  ...   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...  ...   \n",
       "void k_get_rows_float<float, float>(const T1 *,...  ...   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...  ...   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...  ...   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...  ...   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...  ...   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...  ...   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...  ...   \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_elapsed.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                  \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               4.04                                           \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.23                                           \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   1.89                                           \n",
       "silu_f32(const float *, float *, int)                                                            0.40                                           \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      1.08                                           \n",
       "void convert_unary<__half, float>(const void *,...                                               6.21                                           \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.88                                           \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -2.09                                           \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -5.00                                           \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               2.65                                           \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              15.12                                           \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -2.54                                           \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -1.83                                           \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.78                                           \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               1.74                                           \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                          -2,018.34                                           \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                              29.49                                           \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.34                                           \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.34                                           \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               4.37                                           \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -2.30                                           \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame [warp]  \\\n",
       "Demangled Name                                                                                                             \n",
       "k_compute_batched_ptrs(const __half *, const __...                                           3,653.33                      \n",
       "k_sum_rows_f32(const float *, float *, int)                                                 95,200.00                      \n",
       "quantize_q8_1(const float *, void *, int, int)                                             276,986.76                      \n",
       "silu_f32(const float *, float *, int)                                                      -32,592.00                      \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                449,104.00                      \n",
       "void convert_unary<__half, float>(const void *,...                                         -27,536.00                      \n",
       "void convert_unary<float, __half>(const void *,...                                          30,384.00                      \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                          53,520.00                      \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                         123,840.00                      \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                         162,528.00                      \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                         -53,504.00                      \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                          48,685.71                      \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                          91,936.00                      \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                           3,163.90                      \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                         -82,560.00                      \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                    -161,485,589.33                      \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                     188,628,218.95                      \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                        -256,217.60                      \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                         -38,928.00                      \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                          95,168.00                      \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                          70,912.00                      \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               4.04                                         \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.23                                         \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   1.89                                         \n",
       "silu_f32(const float *, float *, int)                                                            0.40                                         \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      1.08                                         \n",
       "void convert_unary<__half, float>(const void *,...                                               6.21                                         \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.88                                         \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -2.09                                         \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -5.00                                         \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               2.65                                         \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              15.12                                         \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -2.54                                         \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -1.83                                         \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.78                                         \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               1.74                                         \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                          -2,018.34                                         \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                              29.49                                         \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.34                                         \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.34                                         \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               4.37                                         \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -2.30                                         \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region [warp]  \\\n",
       "Demangled Name                                                                                                              \n",
       "k_compute_batched_ptrs(const __half *, const __...                                           3,653.33                       \n",
       "k_sum_rows_f32(const float *, float *, int)                                                 95,200.00                       \n",
       "quantize_q8_1(const float *, void *, int, int)                                             276,986.76                       \n",
       "silu_f32(const float *, float *, int)                                                      -32,592.00                       \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                449,104.00                       \n",
       "void convert_unary<__half, float>(const void *,...                                         -27,536.00                       \n",
       "void convert_unary<float, __half>(const void *,...                                          30,384.00                       \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                          53,520.00                       \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                         123,840.00                       \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                         162,528.00                       \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                         -53,504.00                       \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                          48,685.71                       \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                          91,936.00                       \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                           3,163.90                       \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                         -82,560.00                       \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                    -161,485,589.33                       \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                     188,628,218.95                       \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                        -256,217.60                       \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                         -38,928.00                       \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                          95,168.00                       \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                          70,912.00                       \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                 \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               4.04                                          \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.23                                          \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   1.89                                          \n",
       "silu_f32(const float *, float *, int)                                                            0.40                                          \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      1.08                                          \n",
       "void convert_unary<__half, float>(const void *,...                                               6.21                                          \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.88                                          \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -2.09                                          \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -5.00                                          \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               2.65                                          \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              15.12                                          \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -2.54                                          \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -1.83                                          \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.78                                          \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               1.74                                          \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                          -2,018.34                                          \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                              29.49                                          \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.34                                          \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.34                                          \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               4.37                                          \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -2.30                                          \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]  \\\n",
       "Demangled Name                                                                                                         \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                  \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                  \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -6.99                  \n",
       "silu_f32(const float *, float *, int)                                                            5.37                  \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.28                  \n",
       "void convert_unary<__half, float>(const void *,...                                               2.23                  \n",
       "void convert_unary<float, __half>(const void *,...                                               4.17                  \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.47                  \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.51                  \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.58                  \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.03                  \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.47                  \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                  \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -3.36                  \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.29                  \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -595.31                  \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             105.37                  \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.50                  \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.08                  \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                  \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.28                  \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]  \\\n",
       "Demangled Name                                                                                                          \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -6.99                   \n",
       "silu_f32(const float *, float *, int)                                                            5.37                   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.28                   \n",
       "void convert_unary<__half, float>(const void *,...                                               2.23                   \n",
       "void convert_unary<float, __half>(const void *,...                                               4.17                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.47                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.51                   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.58                   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.03                   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.47                   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -3.36                   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.29                   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -595.31                   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             105.37                   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.50                   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.08                   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.28                   \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]  \\\n",
       "Demangled Name                                                                                                           \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                    \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                    \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -6.99                    \n",
       "silu_f32(const float *, float *, int)                                                            5.37                    \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.28                    \n",
       "void convert_unary<__half, float>(const void *,...                                               2.23                    \n",
       "void convert_unary<float, __half>(const void *,...                                               4.17                    \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.47                    \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.51                    \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.58                    \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.03                    \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.47                    \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                    \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -3.36                    \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.29                    \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -595.31                    \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             105.37                    \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.50                    \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.08                    \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                    \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.28                    \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]  \\\n",
       "Demangled Name                                                                                                            \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                     \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                     \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -6.99                     \n",
       "silu_f32(const float *, float *, int)                                                            5.37                     \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.28                     \n",
       "void convert_unary<__half, float>(const void *,...                                               2.23                     \n",
       "void convert_unary<float, __half>(const void *,...                                               4.17                     \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.47                     \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.51                     \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.58                     \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.03                     \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.47                     \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                     \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -3.36                     \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.29                     \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -595.31                     \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             105.37                     \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.50                     \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.08                     \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                     \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.28                     \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]  \n",
       "Demangled Name                                                                                                          \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.04                   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.00                   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                 -10.99                   \n",
       "silu_f32(const float *, float *, int)                                                            8.69                   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.36                   \n",
       "void convert_unary<__half, float>(const void *,...                                               3.88                   \n",
       "void convert_unary<float, __half>(const void *,...                                               6.76                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.79                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.61                   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.91                   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.04                   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.69                   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.02                   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -5.43                   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.49                   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -938.81                   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             178.09                   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.81                   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.12                   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.05                   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.53                   \n",
       "\n",
       "[21 rows x 76198 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "065a729b-46e3-471c-a708-3f3b49073ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics.txt\", \"w\") as f:\n",
    "    for col in nonzero_diff.columns[:-1]:\n",
    "        f.write(str(col))\n",
    "        f.write(\",\")\n",
    "    f.write(nonzero_diff.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "286dfa85-d515-4184-8883-d7efd045e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75998 75998\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "# Relative Percentage Difference (RPD)\n",
    "# https://en.wikipedia.org/wiki/Relative_change\n",
    "q4_q8_col = q4_agg.columns.intersection(q8_agg.columns)\n",
    "intersection = nonzero_diff.columns.intersection(q4_q8_col)\n",
    "selected_q4_agg_col = q4_agg.columns.intersection(intersection)\n",
    "selected_q8_agg_col = q8_agg.columns.intersection(intersection)\n",
    "\n",
    "\n",
    "print(len(selected_q4_agg_col), len(selected_q8_agg_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e0e17d9-0c11-4de4-9e20-0229e1d6d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gpu__time_end.avg [msecond]\" in list(q8_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cc0ed48-ce09-43b6-b2c5-bfa71c3b1382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gpu__time_end.avg [msecond]\" in list(nonzero_diff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57207d30-bb58-42c3-b128-f48163e3fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76198"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonzero_diff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1511c-d615-446b-8d1e-343378bda9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "057c1a3a-6383-4406-9d2f-1524a81c8d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu__time_end.avg [msecond]',\n",
       " 'gpu__time_end.max [msecond]',\n",
       " 'gpu__time_end.min [msecond]',\n",
       " 'gpu__time_end.sum [msecond]',\n",
       " 'gpu__time_start.avg [msecond]',\n",
       " 'gpu__time_start.max [msecond]',\n",
       " 'gpu__time_start.min [msecond]',\n",
       " 'gpu__time_start.sum [msecond]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.min [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.min [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.min [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.min [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.min [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.min [Mbyte]',\n",
       " 'lts__d_sectors_fill_sysmem.avg.per_second [sector/msecond]',\n",
       " 'lts__d_sectors_fill_sysmem.max.per_second [sector/usecond]',\n",
       " 'lts__d_sectors_fill_sysmem.sum.per_second [sector/usecond]',\n",
       " 'lts__t_requests_aperture_peer.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.min.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_aperture_sysmem_lookup_hit.avg.per_second [request/usecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.sum.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.sum.per_second [request/msecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.max.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.avg.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.max.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.min.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_op_membar.max.per_second [request/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.avg.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.max.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.sum.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_op_read.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'sm__inst_executed.avg.per_second [inst/usecond]',\n",
       " 'sm__inst_executed.min.per_second [inst/usecond]',\n",
       " 'sm__inst_issued.avg.per_second [inst/usecond]',\n",
       " 'sm__inst_issued.min.per_second [inst/usecond]',\n",
       " 'sm__pipe_tensor_cycles_active.min.per_second [cycle/second]',\n",
       " 'sm__pipe_tensor_op_hmma_cycles_active.min.per_second [cycle/second]',\n",
       " 'sm__sass_branch_targets.sum.per_second [/usecond]',\n",
       " 'sm__sass_branch_targets_threads_uniform.sum.per_second [/usecond]',\n",
       " 'sm__sass_data_bytes_mem_global.sum.per_second [Gbyte/second]',\n",
       " 'sm__sass_data_bytes_mem_global_op_ld.sum.per_second [Gbyte/second]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_inst_executed.avg.per_second [inst/usecond]',\n",
       " 'sm__sass_inst_executed.min.per_second [inst/usecond]',\n",
       " 'sm__sass_inst_executed_op_branch.sum.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_control_pred_on.avg.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_control_pred_on.min.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_conversion_pred_on.min.per_second [inst/nsecond]',\n",
       " 'sm__sass_thread_inst_executed_op_fmul_pred_on.min.per_second [inst/nsecond]',\n",
       " 'sm__sass_thread_inst_executed_op_misc_pred_on.min.per_second [inst/usecond]',\n",
       " 'sm__thread_inst_executed_pipe_xu_pred_on.min.per_second [inst/nsecond]',\n",
       " 'smsp__inst_executed_pipe_tensor.min.per_second [inst/usecond]',\n",
       " 'smsp__pcsamp_aggregated_passes [pass]\"\"(209)',\n",
       " 'smsp__pcsamp_interval\"\"(486)',\n",
       " 'smsp__pcsamp_interval_cycles [cycle]\"\"(100448)',\n",
       " 'smsp__sass_branch_targets.sum.per_second [/usecond]',\n",
       " 'smsp__sass_branch_targets_threads_uniform.sum.per_second [/usecond]',\n",
       " 'smsp__sass_data_bytes_mem_global.sum.per_second [Gbyte/second]',\n",
       " 'smsp__sass_data_bytes_mem_global_op_ld.sum.per_second [Gbyte/second]',\n",
       " 'smsp__sass_inst_executed_op_branch.sum.per_second [inst/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.avg.per_second [sector/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.max.per_second [sector/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.min.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.avg.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.max.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.min.per_second [sector/usecond]'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(nonzero_diff.columns) - set(selected_q4_agg_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07fc4968-628d-43aa-aeb5-81887f5de29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gpc__cycles_elapsed.max [cycle]', 'gpu__time_duration.sum [usecond]',\n",
       "       'sm__throughput.avg.pct_of_peak_sustained_elapsed [%]',\n",
       "       'gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed [%]',\n",
       "       'device__attribute_architecture',\n",
       "       'device__attribute_async_engine_count',\n",
       "       'device__attribute_can_map_host_memory',\n",
       "       'device__attribute_can_tex2d_gather',\n",
       "       'device__attribute_can_use_64_bit_stream_mem_ops',\n",
       "       'device__attribute_can_use_host_pointer_for_registered_mem',\n",
       "       ...\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.peak_sustained_elapsed.per_second [warp/nsecond]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame.per_second [warp/nsecond]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region.per_second [warp/nsecond]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]',\n",
       "       'tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]'],\n",
       "      dtype='object', length=76077)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_q4_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5954ba49-c493-428b-8e49-58b6f03465a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(list(nonzero_diff.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c099d33d-1162-4f86-9a27-9133dc7f2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_idx = [c for c in q4_agg.columns if c in intersection]\n",
    "q8_idx = [c for c in q8_agg.columns if c in intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "851270cb-0403-46d8-9a9e-a548d5a2ac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114350"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q4_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5603450-0a0d-4da3-83a8-fa9d8fbeb354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114350"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q8_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8a78793-1ec8-4b77-a333-599ec51e5be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76077"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q4_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "64161db2-b7a7-4b52-bc89-691dc01f494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76119"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q8_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42058b80-8137-4b27-a823-0e1ef2f13e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu__time_end.avg [msecond]',\n",
       " 'gpu__time_end.max [msecond]',\n",
       " 'gpu__time_end.min [msecond]',\n",
       " 'gpu__time_end.sum [msecond]',\n",
       " 'gpu__time_start.avg [msecond]',\n",
       " 'gpu__time_start.max [msecond]',\n",
       " 'gpu__time_start.min [msecond]',\n",
       " 'gpu__time_start.sum [msecond]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes.min [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_mem_lg_op_ld.min [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.avg [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.max [Mbyte]',\n",
       " 'l1tex__m_xbar2l1tex_read_bytes_pipe_lsu.min [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_lookup_miss.min [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_lookup_miss.min [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.avg [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.max [Mbyte]',\n",
       " 'l1tex__t_bytes_pipe_lsu_mem_global_op_ld_lookup_miss.min [Mbyte]',\n",
       " 'lts__d_sectors_fill_sysmem.avg.per_second [sector/msecond]',\n",
       " 'lts__d_sectors_fill_sysmem.max.per_second [sector/usecond]',\n",
       " 'lts__d_sectors_fill_sysmem.sum.per_second [sector/usecond]',\n",
       " 'lts__t_requests_aperture_peer.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.min.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_peer.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_aperture_sysmem_lookup_hit.avg.per_second [request/usecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_hit.sum.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.max.per_second [request/msecond]',\n",
       " 'lts__t_requests_aperture_sysmem_op_read_lookup_miss.sum.per_second [request/msecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.avg.per_second [request/msecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.max.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.avg.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.max.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.min.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_lookup_miss.sum.per_second [request/usecond]',\n",
       " 'lts__t_requests_srcnode_gpc_aperture_sysmem_op_membar.max.per_second [request/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_peer_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.avg.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.max.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_lookup_miss.sum.per_second [sector/msecond]',\n",
       " 'lts__t_sectors_aperture_sysmem_op_read.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.min.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar.sum.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.avg.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.max.per_second [sector/usecond]',\n",
       " 'lts__t_sectors_srcnode_gpc_aperture_sysmem_op_membar_lookup_hit.sum.per_second [sector/usecond]',\n",
       " 'sm__inst_executed.avg.per_second [inst/usecond]',\n",
       " 'sm__inst_executed.min.per_second [inst/usecond]',\n",
       " 'sm__inst_issued.avg.per_second [inst/usecond]',\n",
       " 'sm__inst_issued.min.per_second [inst/usecond]',\n",
       " 'sm__pipe_tensor_cycles_active.min.per_second [cycle/second]',\n",
       " 'sm__pipe_tensor_op_hmma_cycles_active.min.per_second [cycle/second]',\n",
       " 'sm__sass_branch_targets.sum.per_second [/usecond]',\n",
       " 'sm__sass_branch_targets_threads_uniform.sum.per_second [/usecond]',\n",
       " 'sm__sass_data_bytes_mem_global.sum.per_second [Gbyte/second]',\n",
       " 'sm__sass_data_bytes_mem_global_op_ld.sum.per_second [Gbyte/second]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_atom.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_ld.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_active [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_elapsed [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_frame [Gbyte]',\n",
       " 'sm__sass_data_bytes_mem_shared_op_st.sum.peak_sustained_region [Gbyte]',\n",
       " 'sm__sass_inst_executed.avg.per_second [inst/usecond]',\n",
       " 'sm__sass_inst_executed.min.per_second [inst/usecond]',\n",
       " 'sm__sass_inst_executed_op_branch.sum.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_control_pred_on.avg.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_control_pred_on.min.per_second [inst/usecond]',\n",
       " 'sm__sass_thread_inst_executed_op_conversion_pred_on.min.per_second [inst/nsecond]',\n",
       " 'sm__sass_thread_inst_executed_op_fmul_pred_on.min.per_second [inst/nsecond]',\n",
       " 'sm__sass_thread_inst_executed_op_misc_pred_on.min.per_second [inst/usecond]',\n",
       " 'sm__thread_inst_executed_pipe_xu_pred_on.min.per_second [inst/nsecond]',\n",
       " 'smsp__inst_executed_pipe_tensor.min.per_second [inst/usecond]',\n",
       " 'smsp__pcsamp_aggregated_passes [pass]\"\"(209)',\n",
       " 'smsp__pcsamp_interval\"\"(486)',\n",
       " 'smsp__pcsamp_interval_cycles [cycle]\"\"(100448)',\n",
       " 'smsp__sass_branch_targets.sum.per_second [/usecond]',\n",
       " 'smsp__sass_branch_targets_threads_uniform.sum.per_second [/usecond]',\n",
       " 'smsp__sass_data_bytes_mem_global.sum.per_second [Gbyte/second]',\n",
       " 'smsp__sass_data_bytes_mem_global_op_ld.sum.per_second [Gbyte/second]',\n",
       " 'smsp__sass_inst_executed_op_branch.sum.per_second [inst/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.avg.per_second [sector/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.max.per_second [sector/usecond]',\n",
       " 'smsp__sass_l1tex_t_sectors_pipe_lsu_mem_global_op_ld.min.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.avg.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.max.per_second [sector/usecond]',\n",
       " 'smsp__sass_sectors_mem_global.min.per_second [sector/usecond]'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(q8_idx) - set(q4_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12749d4f-167e-4ece-82d0-caefb850edf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gpu__time_end.avg [msecond]\" in q4_agg.columns # Reason: gpu__time_end.avg [usecond] vs gpu__time_end.avg [msecond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e07ca24-8973-4ccd-8d2c-99c71744c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_q4_agg = q4_agg[q4_idx]\n",
    "# selected_q8_agg = q8_agg[q8_idx]\n",
    "\n",
    "selected_q4_agg = q4_agg[selected_q4_agg_col]\n",
    "selected_q8_agg = q8_agg[selected_q8_agg_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db964d22-e234-442e-9657-fe027235934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21 entries, k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long) to void soft_max_f32<(bool)1, (int)64, (int)64>(const float *, const float *, float *, int, int, float)\n",
      "Columns: 75998 entries, gpc__cycles_elapsed.max [cycle] to tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]\n",
      "dtypes: float64(75998)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "selected_q4_agg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7646eb18-e99f-4463-ae13-0c20a742af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20 entries, k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long) to void soft_max_f32<(bool)1, (int)64, (int)64>(const float *, const float *, float *, int, int, float)\n",
      "Columns: 75998 entries, gpc__cycles_elapsed.max [cycle] to tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]\n",
      "dtypes: float64(75998)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "selected_q8_agg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ee07ee8-e0aa-4046-b393-5d3fc8a4558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nonzero_diff = nonzero_diff[intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "baac9d89-6264-4636-8f37-9484926397a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75998 75998 75998\n"
     ]
    }
   ],
   "source": [
    "print(len(selected_nonzero_diff.columns), len(selected_q4_agg.columns), len(selected_q8_agg.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7449aa3-0231-4018-8c4b-54746f64cd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device__attribute_architecture</th>\n",
       "      <th>device__attribute_async_engine_count</th>\n",
       "      <th>device__attribute_can_map_host_memory</th>\n",
       "      <th>device__attribute_can_tex2d_gather</th>\n",
       "      <th>device__attribute_can_use_64_bit_stream_mem_ops</th>\n",
       "      <th>device__attribute_can_use_host_pointer_for_registered_mem</th>\n",
       "      <th>device__attribute_can_use_stream_wait_value_nor</th>\n",
       "      <th>device__attribute_chip</th>\n",
       "      <th>device__attribute_clock_rate</th>\n",
       "      <th>device__attribute_compute_capability_major</th>\n",
       "      <th>...</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_elapsed.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region.per_second [warp/nsecond]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]</th>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demangled Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_sum_rows_f32(const float *, float *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantize_q8_1(const float *, void *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silu_f32(const float *, float *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turing_h1688gemm_256x64_ldg8_stages_32x1_tn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;__half, float&gt;(const void *, T2 *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;float, __half&gt;(const void *, T2 *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f16&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f32&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void dequantize_mul_mat_vec&lt;(int)1, (int)1, &amp;convert_f16&gt;(const void *, const float *, float *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_argsort_f32_i32&lt;(ggml_sort_order)1&gt;(const float *, int *, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_add, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_div, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_mul, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_get_rows_float&lt;float, float&gt;(const T1 *, const int *, T2 *, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)4, block_q4_0, (int)2, &amp;vec_dot_q4_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)8, block_q8_0, (int)2, &amp;vec_dot_q8_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rms_norm_f32&lt;(int)1024&gt;(const float *, float *, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rope&lt;float, (bool)1&gt;(const T1 *, T1 *, int, const int *, float, int, float, float, float, rope_corr_dims)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)0, (int)0&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)64, (int)64&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã 75998 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    device__attribute_architecture  \\\n",
       "Demangled Name                                                                       \n",
       "k_compute_batched_ptrs(const __half *, const __...                            0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                   0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                0.00   \n",
       "silu_f32(const float *, float *, int)                                         0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                   0.00   \n",
       "void convert_unary<__half, float>(const void *,...                            0.00   \n",
       "void convert_unary<float, __half>(const void *,...                            0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                            0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                            0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                            0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                            0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                            0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                            0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                            0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                            0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                           -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                            0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                            0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                            0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                            0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                            0.00   \n",
       "\n",
       "                                                    device__attribute_async_engine_count  \\\n",
       "Demangled Name                                                                             \n",
       "k_compute_batched_ptrs(const __half *, const __...                                  0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                         0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                      0.00   \n",
       "silu_f32(const float *, float *, int)                                               0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                         0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                  0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                  0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                  0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                  0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                  0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                  0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                  0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                  0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                  0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                  0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                 -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                  0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                  0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                  0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                  0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                  0.00   \n",
       "\n",
       "                                                    device__attribute_can_map_host_memory  \\\n",
       "Demangled Name                                                                              \n",
       "k_compute_batched_ptrs(const __half *, const __...                                   0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                          0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                       0.00   \n",
       "silu_f32(const float *, float *, int)                                                0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                          0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                   0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                   0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                   0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                   0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                   0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                   0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                   0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                   0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                   0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                   0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                  -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                   0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                   0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                   0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                   0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                   0.00   \n",
       "\n",
       "                                                    device__attribute_can_tex2d_gather  \\\n",
       "Demangled Name                                                                           \n",
       "k_compute_batched_ptrs(const __half *, const __...                                0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                       0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                    0.00   \n",
       "silu_f32(const float *, float *, int)                                             0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                       0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                               -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                0.00   \n",
       "\n",
       "                                                    device__attribute_can_use_64_bit_stream_mem_ops  \\\n",
       "Demangled Name                                                                                        \n",
       "k_compute_batched_ptrs(const __half *, const __...                                             0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                    0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                 0.00   \n",
       "silu_f32(const float *, float *, int)                                                          0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                    0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                             0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                             0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                             0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                             0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                             0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                             0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                             0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                             0.00   \n",
       "\n",
       "                                                    device__attribute_can_use_host_pointer_for_registered_mem  \\\n",
       "Demangled Name                                                                                                  \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00           \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.00           \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.00           \n",
       "silu_f32(const float *, float *, int)                                                            0.00           \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.00           \n",
       "void convert_unary<__half, float>(const void *,...                                               0.00           \n",
       "void convert_unary<float, __half>(const void *,...                                               0.00           \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                               0.00           \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00           \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.00           \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                               0.00           \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.00           \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                               0.00           \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                               0.00           \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.00           \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00           \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.00           \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.00           \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00           \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.00           \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                               0.00           \n",
       "\n",
       "                                                    device__attribute_can_use_stream_wait_value_nor  \\\n",
       "Demangled Name                                                                                        \n",
       "k_compute_batched_ptrs(const __half *, const __...                                             0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                    0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                 0.00   \n",
       "silu_f32(const float *, float *, int)                                                          0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                    0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                             0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                             0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                             0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                             0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                             0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                             0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                             0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                             0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                            -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                             0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                             0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                             0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                             0.00   \n",
       "\n",
       "                                                    device__attribute_chip  \\\n",
       "Demangled Name                                                               \n",
       "k_compute_batched_ptrs(const __half *, const __...                    0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                           0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                        0.00   \n",
       "silu_f32(const float *, float *, int)                                 0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                           0.00   \n",
       "void convert_unary<__half, float>(const void *,...                    0.00   \n",
       "void convert_unary<float, __half>(const void *,...                    0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                    0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                    0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                    0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                    0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                    0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                    0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                    0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                    0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                   -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                    0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                    0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                    0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                    0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                    0.00   \n",
       "\n",
       "                                                    device__attribute_clock_rate  \\\n",
       "Demangled Name                                                                     \n",
       "k_compute_batched_ptrs(const __half *, const __...                          0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                 0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                              0.00   \n",
       "silu_f32(const float *, float *, int)                                       0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                 0.00   \n",
       "void convert_unary<__half, float>(const void *,...                          0.00   \n",
       "void convert_unary<float, __half>(const void *,...                          0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                          0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                          0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                          0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                          0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                          0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                          0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                          0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                          0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                         -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                          0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                          0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                          0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                          0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                          0.00   \n",
       "\n",
       "                                                    device__attribute_compute_capability_major  \\\n",
       "Demangled Name                                                                                   \n",
       "k_compute_batched_ptrs(const __half *, const __...                                        0.00   \n",
       "k_sum_rows_f32(const float *, float *, int)                                               0.00   \n",
       "quantize_q8_1(const float *, void *, int, int)                                            0.00   \n",
       "silu_f32(const float *, float *, int)                                                     0.00   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                               0.00   \n",
       "void convert_unary<__half, float>(const void *,...                                        0.00   \n",
       "void convert_unary<float, __half>(const void *,...                                        0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                        0.00   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                        0.00   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                        0.00   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                        0.00   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                        0.00   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                        0.00   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                        0.00   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                        0.00   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                       -1.00   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                        0.00   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                        0.00   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                        0.00   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                        0.00   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                        0.00   \n",
       "\n",
       "                                                    ...  \\\n",
       "Demangled Name                                      ...   \n",
       "k_compute_batched_ptrs(const __half *, const __...  ...   \n",
       "k_sum_rows_f32(const float *, float *, int)         ...   \n",
       "quantize_q8_1(const float *, void *, int, int)      ...   \n",
       "silu_f32(const float *, float *, int)               ...   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn         ...   \n",
       "void convert_unary<__half, float>(const void *,...  ...   \n",
       "void convert_unary<float, __half>(const void *,...  ...   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...  ...   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...  ...   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...  ...   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...  ...   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...  ...   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...  ...   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...  ...   \n",
       "void k_get_rows_float<float, float>(const T1 *,...  ...   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...  ...   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...  ...   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...  ...   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...  ...   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...  ...   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...  ...   \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_elapsed.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                  \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00                                           \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.00                                           \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.00                                           \n",
       "silu_f32(const float *, float *, int)                                                            0.00                                           \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.00                                           \n",
       "void convert_unary<__half, float>(const void *,...                                               0.00                                           \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.00                                           \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.00                                           \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -0.00                                           \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.00                                           \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                               0.00                                           \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -0.00                                           \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.00                                           \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.00                                           \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.00                                           \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                                           \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.01                                           \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.00                                           \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.00                                           \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.00                                           \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                                           \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame [warp]  \\\n",
       "Demangled Name                                                                                                             \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00                      \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.01                      \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.03                      \n",
       "silu_f32(const float *, float *, int)                                                           -0.00                      \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.01                      \n",
       "void convert_unary<__half, float>(const void *,...                                              -0.00                      \n",
       "void convert_unary<float, __half>(const void *,...                                               0.00                      \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                               0.01                      \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.02                      \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.01                      \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.00                      \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.00                      \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                               0.01                      \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                               0.00                      \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                              -0.01                      \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                      \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.78                      \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.02                      \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.01                      \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.01                      \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                               0.01                      \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_frame.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00                                         \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.00                                         \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.00                                         \n",
       "silu_f32(const float *, float *, int)                                                            0.00                                         \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.00                                         \n",
       "void convert_unary<__half, float>(const void *,...                                               0.00                                         \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.00                                         \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.00                                         \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -0.00                                         \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.00                                         \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                               0.00                                         \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -0.00                                         \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.00                                         \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.00                                         \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.00                                         \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                                         \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.01                                         \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.00                                         \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.00                                         \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.00                                         \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                                         \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region [warp]  \\\n",
       "Demangled Name                                                                                                              \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00                       \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.01                       \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.03                       \n",
       "silu_f32(const float *, float *, int)                                                           -0.00                       \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.01                       \n",
       "void convert_unary<__half, float>(const void *,...                                              -0.00                       \n",
       "void convert_unary<float, __half>(const void *,...                                               0.00                       \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                               0.01                       \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.02                       \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.01                       \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.00                       \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.00                       \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                               0.01                       \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                               0.00                       \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                              -0.01                       \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                       \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.78                       \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.02                       \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.01                       \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.01                       \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                               0.01                       \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.peak_sustained_region.per_second [warp/nsecond]  \\\n",
       "Demangled Name                                                                                                                                 \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.00                                          \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.00                                          \n",
       "quantize_q8_1(const float *, void *, int, int)                                                   0.00                                          \n",
       "silu_f32(const float *, float *, int)                                                            0.00                                          \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                      0.00                                          \n",
       "void convert_unary<__half, float>(const void *,...                                               0.00                                          \n",
       "void convert_unary<float, __half>(const void *,...                                              -0.00                                          \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.00                                          \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                              -0.00                                          \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                               0.00                                          \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                               0.00                                          \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                              -0.00                                          \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.00                                          \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.00                                          \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.00                                          \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                                          \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.01                                          \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                              -0.00                                          \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                              -0.00                                          \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.00                                          \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                                          \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]  \\\n",
       "Demangled Name                                                                                                         \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                  \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                  \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -0.04                  \n",
       "silu_f32(const float *, float *, int)                                                            0.01                  \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.00                  \n",
       "void convert_unary<__half, float>(const void *,...                                               0.03                  \n",
       "void convert_unary<float, __half>(const void *,...                                               0.05                  \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.02                  \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00                  \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.04                  \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.02                  \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.01                  \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                  \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.02                  \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.03                  \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                  \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.10                  \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.01                  \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00                  \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                  \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                  \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]  \\\n",
       "Demangled Name                                                                                                          \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -0.04                   \n",
       "silu_f32(const float *, float *, int)                                                            0.01                   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.00                   \n",
       "void convert_unary<__half, float>(const void *,...                                               0.03                   \n",
       "void convert_unary<float, __half>(const void *,...                                               0.05                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.02                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00                   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.04                   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.02                   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.01                   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.02                   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.03                   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.10                   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.01                   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00                   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                   \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]  \\\n",
       "Demangled Name                                                                                                           \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                    \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                    \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -0.04                    \n",
       "silu_f32(const float *, float *, int)                                                            0.01                    \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.00                    \n",
       "void convert_unary<__half, float>(const void *,...                                               0.03                    \n",
       "void convert_unary<float, __half>(const void *,...                                               0.05                    \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.02                    \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00                    \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.04                    \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.02                    \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.01                    \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                    \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.02                    \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.03                    \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                    \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.10                    \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.01                    \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00                    \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                    \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                    \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]  \\\n",
       "Demangled Name                                                                                                            \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.02                     \n",
       "k_sum_rows_f32(const float *, float *, int)                                                     -0.01                     \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -0.04                     \n",
       "silu_f32(const float *, float *, int)                                                            0.01                     \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.00                     \n",
       "void convert_unary<__half, float>(const void *,...                                               0.03                     \n",
       "void convert_unary<float, __half>(const void *,...                                               0.05                     \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.02                     \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00                     \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.04                     \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.02                     \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.01                     \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                     \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.02                     \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.03                     \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                     \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.10                     \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.01                     \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00                     \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                     \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                     \n",
       "\n",
       "                                                    tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]  \n",
       "Demangled Name                                                                                                          \n",
       "k_compute_batched_ptrs(const __half *, const __...                                               0.03                   \n",
       "k_sum_rows_f32(const float *, float *, int)                                                      0.00                   \n",
       "quantize_q8_1(const float *, void *, int, int)                                                  -0.04                   \n",
       "silu_f32(const float *, float *, int)                                                            0.01                   \n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                     -0.00                   \n",
       "void convert_unary<__half, float>(const void *,...                                               0.03                   \n",
       "void convert_unary<float, __half>(const void *,...                                               0.05                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...                                              -0.02                   \n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...                                               0.00                   \n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...                                              -0.04                   \n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...                                              -0.02                   \n",
       "void k_bin_bcast<&op_add, float, float, float>(...                                               0.01                   \n",
       "void k_bin_bcast<&op_div, float, float, float>(...                                              -0.01                   \n",
       "void k_bin_bcast<&op_mul, float, float, float>(...                                              -0.02                   \n",
       "void k_get_rows_float<float, float>(const T1 *,...                                               0.03                   \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,...                                              -1.00                   \n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...                                               0.11                   \n",
       "void rms_norm_f32<(int)1024>(const float *, flo...                                               0.01                   \n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...                                               0.00                   \n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...                                               0.02                   \n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...                                              -0.00                   \n",
       "\n",
       "[21 rows x 75998 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1tex__data_pipe_lsu_wavefronts_mem_lg_cmd_write.max can < 0 (inflow and outflow) (Level 1 (L1)/Texture Cache, l1tex) LSU (Load Store Unit)\n",
    "\n",
    "stat = selected_nonzero_diff.div( abs(selected_q4_agg.add(selected_q8_agg, fill_value=0.0)), fill_value=0.0)\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c7ecf807-a949-474c-9ac5-b16f87169664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Which kernel function different the most?\n",
    "\n",
    "# stat[\"sort\"] = stat[\"\"]\n",
    "stat_kernel_fn = stat.sum(axis=1).to_frame()\n",
    "# stat.sum(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d22bbeb3-bc7a-44e3-8674-2c365f9630bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_kernel_fn[\"sort\"] = abs(stat_kernel_fn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "359a8225-f584-4c5f-b744-7d79b1fc8df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demangled Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)4, block_q4_0, (int)2, &amp;vec_dot_q4_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>-72,356.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void mul_mat_vec_q&lt;(int)32, (int)8, block_q8_0, (int)2, &amp;vec_dot_q8_0_q8_1&gt;(const void *, const void *, float *, int, int)</th>\n",
       "      <td>20,722.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_argsort_f32_i32&lt;(ggml_sort_order)1&gt;(const float *, int *, int)</th>\n",
       "      <td>2,803.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)0, (int)0&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>2,466.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long)</th>\n",
       "      <td>1,877.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f16&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>1,510.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turing_h1688gemm_256x64_ldg8_stages_32x1_tn</th>\n",
       "      <td>1,502.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;float, __half&gt;(const void *, T2 *, int)</th>\n",
       "      <td>1,395.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_sum_rows_f32(const float *, float *, int)</th>\n",
       "      <td>1,378.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_div, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>-1,111.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void soft_max_f32&lt;(bool)1, (int)64, (int)64&gt;(const float *, const float *, float *, int, int, float)</th>\n",
       "      <td>1,098.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silu_f32(const float *, float *, int)</th>\n",
       "      <td>919.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_add, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>768.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void convert_unary&lt;__half, float&gt;(const void *, T2 *, int)</th>\n",
       "      <td>664.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_get_rows_float&lt;float, float&gt;(const T1 *, const int *, T2 *, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)</th>\n",
       "      <td>-614.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void dequantize_mul_mat_vec&lt;(int)1, (int)1, &amp;convert_f16&gt;(const void *, const float *, float *, int, int)</th>\n",
       "      <td>532.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantize_q8_1(const float *, void *, int, int)</th>\n",
       "      <td>353.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void k_bin_bcast&lt;&amp;op_mul, float, float, float&gt;(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>333.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void cpy_f32_f16&lt;&amp;cpy_1_f32_f32&gt;(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)</th>\n",
       "      <td>-160.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rms_norm_f32&lt;(int)1024&gt;(const float *, float *, int, float)</th>\n",
       "      <td>-53.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void rope&lt;float, (bool)1&gt;(const T1 *, T1 *, int, const int *, float, int, float, float, float, rope_corr_dims)</th>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0\n",
       "Demangled Name                                               \n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0,... -72,356.00\n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0,...  20,722.45\n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(cons...   2,803.72\n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(cons...   2,466.43\n",
       "k_compute_batched_ptrs(const __half *, const __...   1,877.36\n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, ...   1,510.35\n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn          1,502.01\n",
       "void convert_unary<float, __half>(const void *,...   1,395.69\n",
       "k_sum_rows_f32(const float *, float *, int)          1,378.98\n",
       "void k_bin_bcast<&op_div, float, float, float>(...  -1,111.85\n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(co...   1,098.30\n",
       "silu_f32(const float *, float *, int)                  919.41\n",
       "void k_bin_bcast<&op_add, float, float, float>(...     768.78\n",
       "void convert_unary<__half, float>(const void *,...     664.93\n",
       "void k_get_rows_float<float, float>(const T1 *,...    -614.59\n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &co...     532.21\n",
       "quantize_q8_1(const float *, void *, int, int)         353.07\n",
       "void k_bin_bcast<&op_mul, float, float, float>(...     333.47\n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, ...    -160.89\n",
       "void rms_norm_f32<(int)1024>(const float *, flo...     -53.17\n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int...       3.65"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_kernel_fn.sort_values(by=\"sort\",ascending=False)[0].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0744a176-8c4c-4cc5-8e5f-b0733c0e448e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Demangled Name\n",
       "k_compute_batched_ptrs(const __half *, const __half *, char *, const void **, void **, long, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, long)            1,877.36\n",
       "k_sum_rows_f32(const float *, float *, int)                                                                                                                                                                               1,378.98\n",
       "quantize_q8_1(const float *, void *, int, int)                                                                                                                                                                              353.07\n",
       "silu_f32(const float *, float *, int)                                                                                                                                                                                       919.41\n",
       "turing_h1688gemm_256x64_ldg8_stages_32x1_tn                                                                                                                                                                               1,502.01\n",
       "void convert_unary<__half, float>(const void *, T2 *, int)                                                                                                                                                                  664.93\n",
       "void convert_unary<float, __half>(const void *, T2 *, int)                                                                                                                                                                1,395.69\n",
       "void cpy_f32_f16<&cpy_1_f32_f16>(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)                                                                                                             1,510.35\n",
       "void cpy_f32_f16<&cpy_1_f32_f32>(const char *, char *, int, int, int, int, int, int, int, int, int, int, int)                                                                                                              -160.89\n",
       "void dequantize_mul_mat_vec<(int)1, (int)1, &convert_f16>(const void *, const float *, float *, int, int)                                                                                                                   532.21\n",
       "void k_argsort_f32_i32<(ggml_sort_order)1>(const float *, int *, int)                                                                                                                                                     2,803.72\n",
       "void k_bin_bcast<&op_add, float, float, float>(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)                                                                          768.78\n",
       "void k_bin_bcast<&op_div, float, float, float>(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)                                                                       -1,111.85\n",
       "void k_bin_bcast<&op_mul, float, float, float>(const T2 *, const T3 *, T4 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int)                                                                          333.47\n",
       "void k_get_rows_float<float, float>(const T1 *, const int *, T2 *, long, long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)      -614.59\n",
       "void mul_mat_vec_q<(int)32, (int)4, block_q4_0, (int)2, &vec_dot_q4_0_q8_1>(const void *, const void *, float *, int, int)                                                                                              -72,356.00\n",
       "void mul_mat_vec_q<(int)32, (int)8, block_q8_0, (int)2, &vec_dot_q8_0_q8_1>(const void *, const void *, float *, int, int)                                                                                               20,722.45\n",
       "void rms_norm_f32<(int)1024>(const float *, float *, int, float)                                                                                                                                                            -53.17\n",
       "void rope<float, (bool)1>(const T1 *, T1 *, int, const int *, float, int, float, float, float, rope_corr_dims)                                                                                                                3.65\n",
       "void soft_max_f32<(bool)1, (int)0, (int)0>(const float *, const float *, float *, int, int, float)                                                                                                                        2,466.43\n",
       "void soft_max_f32<(bool)1, (int)64, (int)64>(const float *, const float *, float *, int, int, float)                                                                                                                      1,098.30\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat.sum(axis=1).to_frame()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a41aa7cc-78d9-40a6-8901-0913a698b3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l1tex__data_pipe_lsu_wavefronts_cmd_write.max                       93.35\n",
       "l1tex__data_pipe_lsu_wavefronts_mem_lg_cmd_write.max                93.34\n",
       "fbpa__dram_write_bytes.avg.pct_of_peak_sustained_active [%]         12.07\n",
       "fbpa__dram_write_sectors.sum.pct_of_peak_sustained_active [%]       12.07\n",
       "fbpa__dram_write_throughput.avg.pct_of_peak_sustained_active [%]    12.07\n",
       "fbpa__dram_write_throughput.sum.pct_of_peak_sustained_active [%]    12.07\n",
       "fbpa__dram_write_bytes.sum.pct_of_peak_sustained_active [%]         12.07\n",
       "fbpa__dram_write_sectors.avg.pct_of_peak_sustained_active [%]       12.07\n",
       "fbpa__dram_write_bytes.sum.per_cycle_active [byte/cycle]            12.06\n",
       "dram__sectors_write.sum.per_cycle_active [sector/cycle]             12.02\n",
       "fbpa__dram_write_bytes.sum.pct_of_peak_sustained_frame [%]          11.99\n",
       "fbpa__dram_write_sectors.avg.pct_of_peak_sustained_region [%]       11.99\n",
       "fbpa__dram_write_sectors.avg.pct_of_peak_sustained_frame [%]        11.99\n",
       "fbpa__dram_write_sectors.avg.pct_of_peak_sustained_elapsed [%]      11.99\n",
       "fbpa__dram_write_bytes.avg.pct_of_peak_sustained_region [%]         11.99\n",
       "fbpa__dram_write_bytes.sum.pct_of_peak_sustained_region [%]         11.99\n",
       "fbpa__dram_write_throughput.avg.pct_of_peak_sustained_region [%]    11.99\n",
       "fbpa__dram_write_throughput.sum.pct_of_peak_sustained_elapsed [%]   11.99\n",
       "fbpa__dram_write_throughput.sum.pct_of_peak_sustained_frame [%]     11.99\n",
       "fbpa__dram_write_bytes.avg.pct_of_peak_sustained_frame [%]          11.99\n",
       "fbpa__dram_write_bytes.avg.pct_of_peak_sustained_elapsed [%]        11.99\n",
       "fbpa__dram_write_bytes.sum.pct_of_peak_sustained_elapsed [%]        11.99\n",
       "fbpa__dram_write_throughput.sum.pct_of_peak_sustained_region [%]    11.99\n",
       "fbpa__dram_write_throughput.avg.pct_of_peak_sustained_elapsed [%]   11.99\n",
       "fbpa__dram_write_throughput.avg.pct_of_peak_sustained_frame [%]     11.99\n",
       "fbpa__dram_write_sectors.sum.pct_of_peak_sustained_elapsed [%]      11.99\n",
       "fbpa__dram_write_sectors.sum.pct_of_peak_sustained_frame [%]        11.99\n",
       "fbpa__dram_write_sectors.sum.pct_of_peak_sustained_region [%]       11.99\n",
       "dram__bytes_write.avg.per_second [Gbyte/second]                     11.97\n",
       "dram__cycles_active_write.sum.per_second [cycle/nsecond]            11.97\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Which metric is most representative?\n",
    "\n",
    "stat.sum().sort_values(ascending=False)[:30]\n",
    "\n",
    "# (Level 1 (L1)/Texture Cache, l1tex) LSU (Load Store Unit)\n",
    "\n",
    "#  https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html\n",
    "# shared_load_throughput\tl1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.per_second\n",
    "# shared_load_transactions\tl1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum\n",
    "# lg\tLocal/Global memory\n",
    "\n",
    "# fbpa\tThe FrameBuffer Partition is a memory controller which sits between the level 2 cache (LTC) and the DRAM. \n",
    "# dram\tDevice (main) memory, where the GPUs global and local memory resides.\n",
    "\n",
    "\n",
    "# Full Metrics Units:\n",
    "# https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b813b03a-92fb-4226-b2f7-9b2d2f545804",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.to_csv(\"./stat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "09852d07-697e-43ce-b5d9-374308f71e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.sum().sort_values(ascending=False).to_csv(\"./stat_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "688bc215-61dd-4e06-a2be-841caa1b098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = [\n",
    "    # \"Throughput\",\n",
    "    \"Tensor\",\n",
    "    \"inst_executed\",\n",
    "    \"integer_\",\n",
    "    \"int8\",\n",
    "    \"int4\",\n",
    "    \"fp16\",\n",
    "    \"fp32\",\n",
    "    \"fp64\",\n",
    "    \n",
    "]\n",
    "\n",
    "skip = [\n",
    "    \"fbpa\",\n",
    "    \"dram\",\n",
    "    \n",
    "]\n",
    "def in_kw(col):\n",
    "    for s in skip:\n",
    "        if s.lower() in col.lower():\n",
    "            return False\n",
    "    for k in kw:\n",
    "        if k.lower() in col.lower():\n",
    "            return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "492e1b90-998b-416b-8ecc-194a66bc5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_stat = stat.sum().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5dba1dc5-b490-4b50-bd78-143251f3bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>device__attribute_architecture</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device__attribute_async_engine_count</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device__attribute_can_map_host_memory</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device__attribute_can_tex2d_gather</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device__attribute_can_use_64_bit_stream_mem_ops</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_active [warp]</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_elapsed [warp]</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_frame [warp]</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_cycle_in_region [warp]</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpc__warps_active_shader_cs_realtime.sum.per_second [warp/nsecond]</th>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75998 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "device__attribute_architecture                     1.00\n",
       "device__attribute_async_engine_count               1.00\n",
       "device__attribute_can_map_host_memory              1.00\n",
       "device__attribute_can_tex2d_gather                 1.00\n",
       "device__attribute_can_use_64_bit_stream_mem_ops    1.00\n",
       "...                                                 ...\n",
       "tpc__warps_active_shader_cs_realtime.sum.per_cy... 1.44\n",
       "tpc__warps_active_shader_cs_realtime.sum.per_cy... 1.44\n",
       "tpc__warps_active_shader_cs_realtime.sum.per_cy... 1.44\n",
       "tpc__warps_active_shader_cs_realtime.sum.per_cy... 1.44\n",
       "tpc__warps_active_shader_cs_realtime.sum.per_se... 1.45\n",
       "\n",
       "[75998 rows x 1 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_stat # sum of all the kernel function calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "17e55438-4991-43c4-aafc-c11a9a776916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.per_cycle_active [inst/cycle]</th>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.per_second [cycle/usecond]</th>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.per_second [cycle/usecond]</th>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.per_second [inst/usecond]</th>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.per_cycle_elapsed [inst/cycle]</th>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.per_cycle_in_frame [inst/cycle]</th>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pred_off.min.per_cycle_in_region [inst/cycle]</th>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__thread_inst_executed_pipe_xu_pred_on.sum [inst]</th>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pipe_xu_pred_on.avg [inst]</th>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__thread_inst_executed_pipe_xu_pred_on.avg [inst]</th>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pipe_xu_pred_on.sum [inst]</th>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__thread_inst_executed_pipe_xu_pred_on.max [inst]</th>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__thread_inst_executed_pipe_xu_pred_on.max [inst]</th>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_lsu.avg.per_cycle_active [inst/cycle]</th>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__inst_executed_pipe_xu.max.per_cycle_elapsed [inst/cycle]</th>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__inst_executed_pipe_xu.max.per_cycle_in_frame [inst/cycle]</th>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__inst_executed_pipe_xu.max.per_cycle_in_region [inst/cycle]</th>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__thread_inst_executed_pipe_xu_pred_on.sum.per_second [inst/nsecond]</th>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 5.17\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 5.17\n",
       "smsp__thread_inst_executed_pred_off.min.pct_of_... 4.69\n",
       "smsp__thread_inst_executed_pred_off.min.per_cyc... 4.36\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 4.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 4.33\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 4.33\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 4.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 4.33\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 4.33\n",
       "smsp__pipe_tensor_cycles_active.max.per_second ... 4.07\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.per... 4.07\n",
       "smsp__thread_inst_executed_pred_off.min.per_sec... 3.73\n",
       "smsp__thread_inst_executed_pred_off.min.pct_of_... 3.68\n",
       "smsp__thread_inst_executed_pred_off.min.pct_of_... 3.68\n",
       "smsp__thread_inst_executed_pred_off.min.pct_of_... 3.68\n",
       "smsp__thread_inst_executed_pred_off.min.per_cyc... 3.67\n",
       "smsp__thread_inst_executed_pred_off.min.per_cyc... 3.67\n",
       "smsp__thread_inst_executed_pred_off.min.per_cyc... 3.67\n",
       "sm__thread_inst_executed_pipe_xu_pred_on.sum [i... 2.89\n",
       "smsp__thread_inst_executed_pipe_xu_pred_on.avg ... 2.89\n",
       "sm__thread_inst_executed_pipe_xu_pred_on.avg [i... 2.89\n",
       "smsp__thread_inst_executed_pipe_xu_pred_on.sum ... 2.89\n",
       "sm__thread_inst_executed_pipe_xu_pred_on.max [i... 2.80\n",
       "smsp__thread_inst_executed_pipe_xu_pred_on.max ... 2.80\n",
       "smsp__inst_executed_pipe_lsu.avg.per_cycle_acti... 2.76\n",
       "sm__inst_executed_pipe_xu.max.per_cycle_elapsed... 2.40\n",
       "sm__inst_executed_pipe_xu.max.per_cycle_in_fram... 2.40\n",
       "sm__inst_executed_pipe_xu.max.per_cycle_in_regi... 2.40\n",
       "sm__thread_inst_executed_pipe_xu_pred_on.sum.pe... 2.40"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_stat.loc[[c for c in metrics_stat.index if in_kw(c)]].sort_values(by=0, ascending=False)[:30]\n",
    "\n",
    "\n",
    "# **smsp** Each SM is partitioned into four processing blocks, called SM sub partitions. The\n",
    "# SM sub partitions are the primary processing elements on the SM. A sub partition\n",
    "# manages a fixed size pool of warps.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b38b26cf-9e87-4673-b2d3-25cbfda14974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat2 = selected_nonzero_diff.div( abs(selected_q4_agg.add(selected_q8_agg, fill_value=0.0)), fill_value=0.0)\n",
    "# stat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "10fadfcb-8447-41d2-94d6-e68dfe5e0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Stat, consider inflow and outflow (positives and negatives)\n",
    "metrics_stat = stat.sum().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "afdf6a76-edc6-45fc-895c-2dec030ac4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_op_hmma_cycles_active.max.per_second [cycle/usecond]</th>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__pipe_tensor_cycles_active.max.per_second [cycle/usecond]</th>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max [inst]</th>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max.per_second [inst/usecond]</th>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsp__inst_executed_pipe_tensor.max.pct_of_peak_sustained_active [%]</th>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.per_cycle_in_frame</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.per_cycle_elapsed</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.per_cycle_elapsed</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.per_cycle_in_frame</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.per_cycle_in_region</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.per_cycle_in_region</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.per_cycle_active</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.per_cycle_active</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.pct_of_peak_sustained_elapsed [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_op_hmma_cycles_active.min.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.pct_of_peak_sustained_region [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sm__pipe_tensor_cycles_active.min.pct_of_peak_sustained_frame [%]</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 3.17\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 3.17\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 2.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 2.33\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 2.33\n",
       "smsp__pipe_tensor_cycles_active.max.pct_of_peak... 2.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 2.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.pct... 2.33\n",
       "smsp__pipe_tensor_op_hmma_cycles_active.max.per... 2.07\n",
       "smsp__pipe_tensor_cycles_active.max.per_second ... 2.07\n",
       "smsp__inst_executed_pipe_tensor.max [inst]         2.05\n",
       "smsp__inst_executed_pipe_tensor.max.per_second ... 2.04\n",
       "smsp__inst_executed_pipe_tensor.max.pct_of_peak... 2.04\n",
       "smsp__inst_executed_pipe_tensor.max.pct_of_peak... 2.04\n",
       "smsp__inst_executed_pipe_tensor.max.pct_of_peak... 2.04\n",
       "smsp__inst_executed_pipe_tensor.max.pct_of_peak... 2.03\n",
       "sm__pipe_tensor_cycles_active.min.per_cycle_in_... 1.60\n",
       "sm__pipe_tensor_cycles_active.min.per_cycle_ela... 1.60\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.per_c... 1.60\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.per_c... 1.60\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.per_c... 1.60\n",
       "sm__pipe_tensor_cycles_active.min.per_cycle_in_... 1.60\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.per_c... 1.50\n",
       "sm__pipe_tensor_cycles_active.min.per_cycle_active 1.50\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.pct_o... 1.48\n",
       "sm__pipe_tensor_cycles_active.min.pct_of_peak_s... 1.48\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.pct_o... 1.48\n",
       "sm__pipe_tensor_op_hmma_cycles_active.min.pct_o... 1.48\n",
       "sm__pipe_tensor_cycles_active.min.pct_of_peak_s... 1.48\n",
       "sm__pipe_tensor_cycles_active.min.pct_of_peak_s... 1.48"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_stat.loc[[c for c in metrics_stat.index if in_kw(c)]].sort_values(by=0, ascending=False)[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee7c46-168d-4878-9283-90a5d32b1207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
